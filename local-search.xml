<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>AI时代的多模态列式存储——LanceDB技术概览</title>
    <link href="/2025/07/21/lance-overview/"/>
    <url>/2025/07/21/lance-overview/</url>
    
    <content type="html"><![CDATA[<blockquote><p><strong>特别说明：本文所讨论的技术设计均基于Lance v2和Lance v2.1</strong></p></blockquote><p>在<a href="https://ztorchan.com/2025/07/07/columnar-storage-overview/"><em>从Parquet到Arrow——列式存储概览</em></a>一文中，我们回顾了过去十余年主流的开源列式存储格式。正如前文所述，数据存储的发展始终顺应着上层应用I/O模式的变迁。近年来，随着AI技术的爆发式发展，我们迎来了比大数据时代还“大”的AI时代，对数据I/O的需求也随之发生深刻变革。这使得原有的列式存储方案在某些场景下面临新的挑战。LanceDB应运而生，旨在应对这些挑战。本文将对LanceDB进行技术概览，探讨AI时代数据I/O面临的新问题，以及LanceDB的解决之道。</p><span id="more"></span><h1 id="lancedb是什么">LanceDB是什么？</h1><!-- https://mp.weixin.qq.com/s/nerkvBtFo5BM68dacsq17A --><!-- https://blog.csdn.net/younger_china/article/details/125905449 --><p>LanceDB的愿景是<strong>为AI时代构建统一的数据湖平台，满足多模态数据的管理需求</strong>。随着AI时代的到来，图像、视频和音频等多模态数据的数据量及其访问需求急剧增长。然而，传统数据湖解决方案在高效管理这类数据时面临挑战，迫使相关企业不得不维护多个独立的数据系统，并通过构建复杂的数据交互链路来勉强支持多种模态数据的管理，效率低下。LanceDB正是在此背景下诞生，旨在弥补传统数据湖在多模态数据管理上的不足，为AI场景下的复杂数据提供统一高效的管理平台。</p><figure><img src="fig1-bigdata_framework_level.jpg" alt="" /><figcaption>图1 大数据框架层次</figcaption></figure><p>LanceDB构建在其开发的新型开源列式存储格式Lance之上，它高效管理多模态数据的能力正得益于Lance格式的针对性设计。如图1所示，Lance格式兼具了数据格式（Data Format）层和表格式（Table Format）层的特性，与传统Parquet/ORC数据格式和MetaStore/Iceberg表格式的单一层级功能有着本质区别。Lance格式不仅保持了高效扫描访问性能，还支持快速随机点查询。同时，它在添加新数据列时无需复制旧数据，实现了真正的Zero-cost Data Evolution特性。这些独特的特性和优势使Lance格式能够充分适应AI时代的数据负载需求，也支撑LanceDB成为当前领先的多模态数据湖平台解决方案。​</p><h1 id="ai工作负载的特点">AI工作负载的特点</h1><p>再次强调，存储设计必须基于上层负载的访问模式进行。在开始后续的技术探讨之前，让我们先分析一下现代AI工作负载的特征及其遇到的问题。​</p><h2 id="大量的点查询">大量的点查询</h2><p>​​点查询​​指单次请求仅访问少量数据行的查询操作。当借助二级索引执行此类查询时，目标数据行往往呈​​离散分布​​，不属于同一个Page​。对于AI工作负载来说，无论是训练阶段还是推理阶段，数据搜索都是常用且重要的过程。为此，LanceDB​​从设计之初即定位为一个支持多样化搜索的向量数据库​​，例如语义搜索（Semantic Search）与全文本搜索（Full Text Search, FST）是其支持的核心搜索方式。​​这些搜索过程在底层最终都会转化为点查询操作，可想而知点查询是LanceDB无可避免的主要查询方式​​。</p><figure><img src="fig2-point_lookups.png" alt="" /><figcaption>图2 列式存储点查询（以Parquet为例）</figcaption></figure><p>然而，传统 Parquet 格式在处理点查询时存在显著瓶颈，主要原因可归结为以下两方面：</p><ol type="1"><li><p>​<strong>​海量随机I/O带来的效率困境</strong>​​：​​点查询会触发大量​的随机I/O请求，这种​​访问模式对存储系统极不友好​​。​​尤其对于当前主流的、基于 S3 等云存储构建的数据湖架构而言，其有限的IOPS能力难以高效应对此类海量随机I/O负载。​​</p></li><li><p>​<strong>​缺乏“可切片性”导致的冗余读取</strong>​​：​​更深层次的原因在于，​​Parquet 的数据编码设计本身不具备“可切片性”​，即它无法单独提取并解码​​目标数据片段。为了成功解码所需数据，系统​​不得不读取目标数据所在的整个Page甚至Column Chunk​​。​​这种必须读取冗余大块数据的机制，在面对仅需少量数据的点查询时，必然会显著增加处理延迟和I/O开销。​</p></li></ol><h2 id="宽列">宽列</h2><p>传统的大数据工作负载通常处理的是结构相对简单、尺寸较小的数据列，例如整数、浮点数或长度有限的字符串等基础数据类型。即使是其中最大的字符串，其尺寸通常也处于可控范围。然而，当下以AI工作负载更关注图像、音频、视频等多模态数据。这些工作负载往往将多模态数据的语义嵌入向量（如4KB大小的<a href="https://openai.com/index/clip/">CLIP embeddings</a>）甚至是原始数据本身作为单独的列进行存储。这导致了“宽列”的形成。​</p><figure><img src="fig3-wide_columns.png" alt="" /><figcaption>图3 宽列</figcaption></figure><p>在传统的Parquet格式下，宽列的存在使得Row Group大小的设置面临两难困境：​​</p><ol type="1"><li>若​采用较小的Row Group Size以降低单个Row Group的数据量：​一方面，元数据开销必然增加，从而影响性能​；​​另一方面，与宽列关联的窄列数据量会变得极小，可能被放入远小于文件系统最佳读取尺寸的Page中，导致I/O效率低下。​​ ​​</li><li>若​维持较大的Row Group Size以避免上述问题：一方面，Parquet Writer在写入数据时需要消耗大量内存资源进行缓冲；​另一方面，由于当前主流Parquet Reader如pyarrow）以Row Group为并行单元处理数据，读取过程同样会占用大量内存。​</li></ol><h2 id="宽表">宽表</h2><figure><img src="fig4-wide_schemas.png" alt="" /><figcaption>图4 宽表</figcaption></figure><p>特征工程作为AI工程的核心环节，会从原始数据中提取大量特征（通常多达数千个）​​。这使得许多AI工作负载拥有​​极其宽泛的数据模式（Schema）​​，即数据表包含大量数据列。尽管Parquet等列式存储格式提供了强大的​​列投影功能以最小化数据读取量​​，但读取时​​仍需完整加载所有列的模式元数据​​。这种元数据加载​​在低延迟场景下会引入显著开销​​，​​无法满足性能要求​​；同时，在跨多个文件缓存此类元数据时，​​极易造成内存占用激增，严重制约系统性能​​。</p><!-- ## 元数据 --><h1 id="lance格式">Lance格式</h1><p>如前所述，Lance格式是支撑LanceDB高效管理和访问多模态数据的关键设计。它​融合了传统数据格式与表格式的特性，承担了这两个层级的任务，对这两个层级分别进行了针对性优化。​​​​本章将深入解析Lance在数据格式层和表格式层的关键优化设计。​</p><!-- https://blog.lancedb.com/lance-v2/ --><!-- https://blog.lancedb.com/file-readers-in-depth-parallelism-without-row-groups/ --><!-- https://blog.lancedb.com/lance-file-2-1-smaller-and-simpler/ --><!-- Lance: Efficient Random Access in Columnar Storage through Adaptive Structural Encodings --><!-- https://blog.lancedb.com/columnar-file-readers-in-depth-apis-and-fusion/ --><h2 id="lance数据格式摒弃row-group">Lance数据格式：摒弃Row Group</h2><p>传统的列式存储格式（如Parquet和ORC）均遵循PAX存储模型，在数据组织上引入了Row Group和Column Chunk的结构分层，同一Row Group内的每个Column Chunk都包含了相同行数的数据记录。而Lance数据格式的一项核心设计则在于摒弃了Row Group结构，从而获得更高的数据布局灵活性。</p><figure><img src="fig5-lance_data_format.png" alt="" /><figcaption>图5 Lance文件数据格式</figcaption></figure><p>Lance实际存储数据的是<code>.lance</code>文件。如图5所示，一个<code>.lance</code>文件主要由三部分组成:</p><ul><li><p><strong>Data Pages</strong>：存储实际的列数据。​​每个Page归属于一个特定的列，而每个列可以包含多个数据页。​​​​更进一步地，每个数据页由一系列Buffer构成。​</p></li><li><p><strong>Column Metadata</strong>：当前文件下的每个列均有一个Column Metadata来描述属于该列的元信息，例如每个Page所包含的数据行数及其每个Buffer的offser和size。</p></li><li><p><strong>Footer</strong>：包含描述整个文件的全局元信息，例如文件格式版本、总列数、Column Metadata区域的位置等。</p></li></ul><p>通过摒弃Row Group层级的限制，Lance数据格式实现了极高的数据布局灵活性：单个文件可以仅存储数据表的部分列（而非完整列集）；同一文件内不同列可以包含数量不同的Page；并且每个Page本身也可以包含不同行数的数据记录。这种设计的核心优势在于完美规避了传统格式中因宽列与窄列并存而引发的Row Group大小权衡难题，开发者仅需为每个列配置合适的Buffer大小即可。</p><p>此外，摒弃Row Group的设计也带来了其它的优化空间，我们将在后续章节中探讨。</p><h2 id="lance数据格式计算并行性与io并行性解耦">Lance数据格式：计算并行性与I/O并行性解耦</h2><p>顺应着摒弃Row Group的设计，Lance进一步将计算和I/O解耦，提高并行能力。</p><p>我们先来看看传统的列式存储读取过程，下面是整个流程抽象出的伪代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs C++">parallel <span class="hljs-keyword">for</span> row_group in file:<br>  # 以Row Group为单位并行计算<br>  arrays = []<br>  parallel <span class="hljs-keyword">for</span> column in row_group:<br>    # 以Column Chunk为单位并行I/O<br>    array = <span class="hljs-built_in">ArrayBuilder</span>()<br>    <span class="hljs-keyword">for</span> page in column:<br>      page = <span class="hljs-built_in">read_page</span>()<br>      array.<span class="hljs-built_in">extend</span>()<br>    arrays.<span class="hljs-built_in">append</span>(array)<br>  batch = <span class="hljs-built_in">RecordBatch</span>(arrays)<br>  yield batch<br></code></pre></td></tr></table></figure><p>实际实现可能更复杂（例如Page无法独立解码、预取机制等），但以上伪代码揭示了传统架构的两个关键特征：</p><ol type="1"><li><p>数据读取流程中的计算（这里特指解码过程）并行性和I/O并行性是紧密绑定的；</p></li><li><p>数据读取流程的并行度和上层应用设定的并行程度相关。例如，当上层应用设置了任务并行性度<span class="math inline">\(X\)</span>（通常和CPU核心数相关），此时<span class="math inline">\(X\)</span>就是对Row Group的访问并行度。同时涉及的数据列总共有<span class="math inline">\(Y\)</span>列，那么I/O并行度将为<span class="math inline">\(X \times Y\)</span>。</p></li></ol><p>同时，我们还需要认识到两个事实：</p><ol type="1"><li><p>硬盘的I/O并行度存在上限​​。当并发I/O请求数量​​低于​​该上限时，硬件性能​​无法被充分利用​​；而当并发请求数量​​超出​​该上限时，​​请求排队将导致平均I/O延迟上升​​。</p></li><li><p>由于不同列的数据类型各不相同，尺寸不一，存储相同行数的数据所需的Page数量在列与列之间也存在差异。</p></li></ol><p>于是，基于上述特征和事实，我们可以去发现传统列式存储读取数据时存在的问题。在后面的场景中，我们数据读取拆解为两个核心阶段：数据I/O和解码计算两个关键过程，其中解码计算按固定行数分批执行。</p><figure><img src="fig6-traditional_column_storage_read.png" alt="" /><figcaption>图6 传统列式存储数据读取顺序示例</figcaption></figure><p>图6给出了一个数据读取时I/O顺序的示例。假设此时以<span class="math inline">\(X\)</span>为3、<span class="math inline">\(Y\)</span>为3的并行度对数据发起访问，由于各列包含的Page数量不同，导致每一轮次发起的I/O请求数量存在差异。如图所示，第一轮I/O因请求数量超过硬盘并行处理能力上限而导致延迟上升；而在第三轮，则因请求数量不足造成硬件性能浪费。​</p><figure><img src="fig7-inefficient_io_decode.png" alt="" /><figcaption>图7 数据I/O和解码计算重叠不足导致效率低下</figcaption></figure><p>更为关键的是，解码计算的前提是已完成读取的Page包含了各列固定行数批次的数据。即便是最理想的情况，每列至少需要完成一个Page的I/O读取。这意味着在平均情况下，系统必须等<span class="math inline">\(X \times Y\)</span>（本例中为9）个I/O操作完成才能启动解码。如前所述，由于并发 I/O 请求过多导致的平均延迟大幅提升，会显著推迟解码计算的开始时间，造成 I/O 与计算的重叠不足，最终严重制约数据读取效率。​</p><figure><img src="fig8-efficient_io_decode.png" alt="" /><figcaption>图8 理想的数据I/O和解码计算重叠</figcaption></figure><figure><img src="fig9-lance_read.png" alt="" /><figcaption>图9 Lance数据读取顺序示例</figcaption></figure><p>​如图8所示，数据读取效率最优化的关键在于实现 I/O 操作与解码计算的最大化重叠。​而要实现这个，只需要按行号顺序访问各列对应的Page（同时控制并发I/O请求数），确保已读取的数据能最大程度地满足即时解码条件，从而实现最优效率。​于是，修改图6的数据读取顺序变为图9所示，以行号作为优先级，顺序读取各列Page即可。</p><figure><img src="fig10-lance_read_schedule.png" alt="" /><figcaption>图10 Lance数据读取过程中的数据I/O和解码计算调度</figcaption></figure><p>​​基于上述思路，Lance设计了如图10所示的数据读取调度机制：​​</p><ol type="1"><li><p>​调度线程（Scheduling Thread）​：根据查询任务和文件元数据，确定目标Page，生成对应的I/O请求并提交至I/O调度器，同时向解码线程发起解码请求。</p></li><li><p>​​I/O调度器（I/O Scheduler）：​​按行号顺序调度​​所有待读取的Page，并根据​​硬盘性能动态控制并发I/O请求数量​​。</p></li><li><p>​​解码线程（Decoder Thread）​​：​​接收已完成 I/O 的 Page 数据​​，执行解码计算任务。</p></li></ol><p>​​通过这种设计，Lance 实现了访问过程中数据I/O与解码计算的彻底解耦，有效解决了传统列式存储在数据访问过程中的性能瓶颈，显著提升了整体效率。​</p><h2 id="lance数据格式随机访问友好的结构编码">Lance数据格式：随机访问友好的结构编码</h2><p>前面提到，LanceDB的定位决定了其必然面临海量的点查询需求。这些点查询将会触发大量的随机I/O，对性能相当不友好。这个问题在面临复杂结构时将变得更为严重，例如<code>List&lt;string&gt;</code>类型列，<code>List</code>和<code>string</code>均为变长数据类型，嵌套使得该列的数据分布变得更为复杂，且还可能存在空值情况，这就为点查询引入了严重的寻址开销。</p><p>​​点查询的执行效率与数据格式的结构编码设计密切相关。结构编码决定了数据从逻辑表示到物理存储的映射规则。为深入理解这一关键机制，我们首先分析Parquet和Arrow的结构编码方案，对比二者在点查询场景下的数据访问差异（这部分内容在<a href="https://ztorchan.com/2025/07/07/columnar-storage-overview/">前一篇文章</a>中也曾提及）。​</p><figure><img src="fig11-parquet_structral_encode.jpg" alt="" /><figcaption>图11 Parquet结构编码</figcaption></figure><p>Parquet为嵌套结构体的每个叶子节点列独立维护一个Column Chunk，每个Column Chunk则进一步划分为多个Page。Page是数据压缩的基本单元，其内部包含：用于编码数据重复性与存在性的Repetition/Definition Level、描述数据项基本属性（如长度）的元信息，以及数据本身。每当对特定行发起访问时，Parquet通过Page Offset Index可快速定位目标行所在的Page，进而加载、解压该Page并读取其内部数据完成访问。​</p><p>Parquet的结构编码十分契合于点查询，但也存在几个问题：</p><ul><li><p>点查询会引入与Page大小等同的读放大。虽然Parquet并不实际为空值分配空间，且会将Page进行压缩存储，但Page的完整加载还是不可避免地引入了冗余数据读取。</p></li><li><p>面对较大尺寸的数据类型时，单个Page可容纳的数据行数减少，所需Page数量增加，随之直接提升Page Offset Index的内存开销。​</p></li><li><p>Page的压缩和解压缩也会引入CPU计算开销。</p></li></ul><figure><img src="fig12-arrow_structral_encode.jpg" alt="" /><figcaption>图12 Arrow结构编码</figcaption></figure><p>尽管Arrow的定位在于内存列式存储，但我们仍可以探究其结构编码应用于硬盘会发生什么。Arrow没有对数据进行细粒度的划分，并为空值分配物理空间，其通过直接的有效性位图和偏移量数组标识数据存在性与重复性（而非Parquet的Repetition/Definition Level）。以<code>List&lt;string&gt;</code>类型数据列为例（其布局如图12所示），读取单行数据至少触发5次独立的离散I/O操作，且这样的I/O次数会随着嵌套结构深度呈线性增长。​</p><p>该结构编码的优势在于消除了读放大问题，但代价是显著增加了I/O操作频次。在内存场景下，此类高频I/O不会成为主要瓶颈；然而当其应用于硬盘或云存储时，高频 I/O 将迅速耗尽底层存储的IOPS能力，形成严重的性能瓶颈。</p><p>为了结合上述两种编码结构的优势以更好地应对点查询，Lance为大尺寸数据类型和小尺寸数据类型分别设计了<strong>Full Zip编码</strong>和<strong>Mini-block编码</strong>，确保<strong>面对任意数据类型的查询都能在1次（定长数据类型）至2（变长数据类型）次I/O中完成数据读取</strong>。</p><figure><img src="fig13-full_zip.jpg" alt="" /><figcaption>图13 Full Zip编码</figcaption></figure><p>Full Zip编码专为大尺寸数据类型优化设计。为规避读放大问题，该编码摒弃了将多个数据项打包成Page的方式，而是按数据项粒度布局存储​。如图13所示，对于叶子列中的每个数据项，Full Zip编码将其 Repetition/Definition Level、数据项属性（如长度）及数据本身​连续存储于连续地址上​，我们可以将这样一组数据称为一个 Buffer。</p><p>由于任意数据列的类型和结构固定后，其Repetition/Definition Level的取值范围即被确定，因此Full Zip编码会将Buffer的Repetition/Definition Level通过bit pack编码压缩到1-4字节的固定长度。以<code>Struct&lt;List&lt;string&gt;&gt;</code>类型列为例，可以用低位3 bit表示Definition Level和高位1 bit表示Repetition level，共4 bit。图13展示了一个<code>['AB', 'C'], Null List, Null Struct, [Null], []</code>数据列基于Zip Full编码的实际存储布局。</p><p>上述数据布局设计对于定长数据类型而言已经可以实现在1次I/O内完成目标数据查询，因为此时Buffer是定长的，目标数据的地址偏移量可以直接计算得出。然而，该方案无法直接支持变长数据类型。为此，Full Zip编码还引入了一个Repetition Index数组存储所有数据项的地址偏移量，使得变长数据类型的点查询也仅需2次I/O便可完成。此外，扫描查询也可以通过计算（定长）或查询Repetition Index数组（变长）来获取目标范围来实现。</p><figure><img src="fig14-mini_block.jpg" alt="" /><figcaption>图14 Full Zip编码</figcaption></figure><p>Mini-block编码则专为小尺寸数据类型优化设计。对于小尺寸数据类型而言，适当的读放大是可以接受的，因此Mini-block 依旧采用分组存储策略，将数据划分为多个分组，我们称之为​​Chunk​​。每个Chunk同样包含了：Repetition/Definition Level、数据项属性（如长度）及数据本身。此外，Chunk头部还额外存储了该Chunk的数据项数量和总大小等统计信息。值得注意的是，这种结构设计与Parquet的Page结构高度相似，但Mini-block通常将Chuck大小控制在了4-8KB内（1-2个扇区大小），也将数据项个数控制在4096个以内，以避免过度读放大。</p><p>同样的，Mini-block也为维护了Repetition Index数组以快速确定目标数据在哪个Chunk内，以确保当嵌套结构内存在变长数据类型时依然能在2次I/O内完成对目标数据的读取。每个Chunk的Repetition Index包含N+1个非负整数，其中N是所需的最大随机访问嵌套级别。每个Chunk的Repetition Index由N+1个非负整数构成（N代表所需最大随机访问嵌套深度），例如对于<code>array[x][y]</code>访问模式需要维护3个整数：第一个整数记录该Chunk起始前已完成的顶层结构（数据行）数量；第二个整数记录该 Chunk起始前在当前顶层结构内已完成的二级结构数量；第三个整数记录该Chunk起始前在当前二级结构内已完成的三级结构数量。这听着有些抽象，图14给出了一个<code>List&lt;List&lt;string&gt;&gt;</code>列的例子。</p><figure><img src="fig15-struct_packing.png" alt="" /><figcaption>图15 Struct Packing编码</figcaption></figure><p>最后，Lance还给出了一种Struct Packing编码，它允许将部分列合并存储，从而转化为行存储模型。对于那些经常被一起访问的数据列，通过Struct Packing编码合并存储，可以有效降低访问过程中的I/O数据。</p><h2 id="lance表格式zero-cost-data-evolution">Lance表格式：Zero-cost Data Evolution</h2><p>在表格式层面，Lance依然借助摒弃Row Group所带来的数据布局灵活性，实现了Zero-cost Data Evolution。</p><figure><img src="fig16-table_growth.png" alt="" /><figcaption>图16 数据表的演化</figcaption></figure><p>在深入探讨该设计点之前，我们先来解释一下什么是数据表的演化。数据表在完成构建后并非是一成不变的，其结构会随着上层应用的运行而动态变化，发生表的垂直增长和水平增长：垂直增长就是数据行的增加，例如在发生订单交易后，我们需要往交易表里添加一行交易记录；水平增长则是数据列的增加，这在特征工程等场景中更为常见，例如为一张文本分析表新增“情绪倾向”的数据列。</p><figure><img src="fig17-horizontal_growth_with_default_value.png" alt="" /><figcaption>图17 数据表水平增长后旧列以默认值填充</figcaption></figure><p>问题发生在表的水平增长上。事实上，表结构的水平扩展并非新兴需求——长期运行的系统必然面临新增业务需求，例如电商平台推出下单返现活动时，需在交易表中新增“返现金额”列。由于历史交易记录无需该列数据，为其设置零值默认值是合理方案。在此场景下，理想方案应避免重写数据文件，仅需维护元数据并在查询旧数据时填充默认值。这正是Iceberg等传统表格式采用的标准方案。​</p><p>然而，AI工作负载对数据演化的要求远不止于此。其新增数据列的操作更为频繁，且通常旨在为所有历史数据添加特征描述（如特征向量）。在传统表格式下，由于Row Group必须包含完整列集，这迫使系统必须复制并重写所有数据文件。这一机制导致数据表演化开销巨大，在宽列存在的场景下更会进一步放大性能影响。​</p><figure><img src="fig18-zero_cost_data_evolution.png" alt="" /><figcaption>图18 Zero-cost Data Evolution</figcaption></figure><p>Lance则没有这个包袱了。摒弃Row Group的设计使其摆脱了单个文件必须包含所有数据列的束缚，从而可以采用创新的二维存储布局：将数据按行划分为多个Fragment，每个Fragment内的数据再按列组织为多个独立文件——每个文件包含固定行数的单列或多列数据。当新增数据列时，Lance无需复制或重写任何现有文件，只需单独创建对应的新文件，并可在必要时灵活合并或拆分这些数据文件。（从逻辑结构上看，Fragment和Row Group非常相似）</p><p>​<img src="fig19-zero_cost_data_deletion.png" alt="图19 轻量化的数据删除" /></p><p>更进一步地，Lance为数据行删除也进行了轻量化设计。它在每个Fragment内专门维护一个Deletion文件​​，用于标记每行数据的删除状态。通过这种设计，Lance在删除数据行时仅需更新元数据（Deletion文件），而无需修改实际的数据文件本身。​</p><!-- https://blog.lancedb.com/designing-a-table-format-for-ml-workloads/ --><h1 id="lance之上的lancedb">Lance之上的LanceDB</h1><!-- https://lancedb.github.io/lancedb/ --><p>再简单介绍一下LanceDB。</p><p>​<img src="fig20-lancedb.png" alt="图20 LanceDB生态" /></p><p>LanceDB是基于Lance格式构建的开源向量数据库，其核心代码主要由Rust编写实现。Lance格式的设计在很大程度上解决了多模态数据存储、点查询随机访问和频繁表演化的效率问题，这使得LanceDB非常契合于当下AI工作负载的数据管理需求。同时，LanceDB为主流数据框架和SQL引擎提供广泛接入支持，便于集成现有数据生态系统。这些优势正推动LanceDB成为当下构建多模态数据湖的答案之一。​</p><p>​<img src="fig21-lancedb_storage_tradeoffs.png" alt="图21 LanceDB存储底座选择" /></p><p>同时，LanceDB也为各种形式的存储底座提供了支持，从高成本低延迟的本地SSD到低成本高延迟的S3云存储。广泛的存储底座选择足以满足各类场景的需要，给了用户充分考量权衡的空间。</p><p>​<img src="fig22-lancedb_vector_search.png" alt="图22 向量搜索" /></p><p>LanceDB也提供了包括向量搜索（KNN/ANN搜索）和FTS搜索在内的多种数据搜索能力，其中向量搜索作为AI时代核心的数据访问范式，也是是其关键优势所在。​</p>]]></content>
    
    
    <categories>
      
      <category>列式存储</category>
      
      <category>向量数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>列式存储</tag>
      
      <tag>Lance</tag>
      
      <tag>LanceDB</tag>
      
      <tag>AI存储</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从Parquet到Arrow——列式存储概览</title>
    <link href="/2025/07/07/columnar-storage-overview/"/>
    <url>/2025/07/07/columnar-storage-overview/</url>
    
    <content type="html"><![CDATA[<p>数据存储总是需要顺应上层应用的IO模式而发展的。进入大数据时代的数十年里，OLAP分析性系统逐渐替代OLTP事务型系统成为了当下主流的数据系统，对OLAP更为友好的列式存储也随之成为研究热点得以野蛮发展。本文以存储模型的发展出发，简述列式存储设计的关键点，并着重介绍当下主流的开源列式存储格式，为读者提供一张全局视图。</p><span id="more"></span><h1 id="存储模型的发展">存储模型的发展</h1><p>对于人们的日常生活生产来说，二维表是最直观的数据管理方式。以公司职员管理为例子，下面一张简单的二维表就能实现我们对职员管理的增删改查需求。</p><figure><img src="fig1-2D_table.jpg" alt="" /><figcaption>图1 二维表</figcaption></figure><p>但和我们对数据的直观认知逻辑不同，数据的存储是一维的，也即存储地址是单一维度线性延申的。因此，如何把二维的数据存储到一维的空间中也成为了一个值得探讨的问题。</p><h2 id="nsm模型">NSM模型</h2><p>NSM（N-ary Storage Model）存储模型​​，即我们常说的​​行存储​​，其核心思想是<strong>将数据按​​条目（行）为单位连续存储​</strong>​。如下图所示，表格中的每一行数据作为一个完整单元，被依次存入NSM Page中，而同一行内不同列的数据则存储在相邻的物理地址上。NSM Page的尾部通常会构建索引结构​​，以实现对每条数据的高效定位。这种存储模型高度契合我们的直觉认知。</p><figure><img src="fig2-NSM.jpg" alt="" /><figcaption>图2 NSM存储模型</figcaption></figure><p>NSM模型将同一行的数据组织在一起，具有以下显著优点：</p><ul><li>单行数据的物理连续性使插入和删除操作性能更高</li><li>对<code>SELECT * from ...</code>之类的完整条目查询更加友好，无需进行数据重建</li></ul><p>但该模型也存在其固有缺点：</p><ul><li>当仅需部分列时仍需读取整行数据，造成严重的读放大和缓存低效</li><li>同一行往往存在不同的数据类型，数据压缩效率低下</li></ul><p>传统的数据系统主要面向OLTP场景，它们更注重数据操作的实时性、高并发以及ACID事务保证，例如银行业务、票务业务、订单业务等等。由于OLTP系统常常进行完整数据条目的增加、删除和查询，因此NSM模型天然适合OLTP场景。</p><h2 id="dsm模型">DSM模型</h2><p>随着大数据时代的到来，OLAP场景需求逐渐显现并迅速增长，这类分析型系统更关注海量数据的快速聚合与分析能力，典型应用包括商业智能、数据仓库、报表统计等。由于OLAP系统通常需要对大型数据集进行复杂的多维度分析，往往只涉及部分列的计算和聚合，这使得NSM行存储模型难以满足海量数据的吞吐需求。</p><p>DSM（Decomposition Storage Model）模型与NSM模型相反，其核心思想是<strong>将数据按列而非按行组织存储，每个列单独形成存储单元</strong>。如下图，在NSM模型下，同一列的所有数据值连续存储在相邻物理地址，而同一行的不同列数据则分散存储在不同的Page中，每个列单元维护专属的访问结构和元数据信息。</p><figure><img src="fig3-DSM.jpg" alt="" /><figcaption>图3 DSM存储模型</figcaption></figure><p>这样的数据组织带来了与NSM模型截然相反的优缺点，其优点在于：</p><ul><li>当查询仅涉及部分列时可实现"列裁剪"式读取，避免无关列的I/O开销，同时提高缓存效率</li><li>同一列的数据大多为统一数据类型，进行数据压缩时能得到更高的压缩效率</li><li>批量处理同列数据时能充分发挥现代CPU的SIMD指令集并行计算能力</li></ul><p>反之，其缺点在于：</p><ul><li>对完整条目的点查询需要从多个列单元收集数据并重建完整行，引入重组开销</li><li>事务性写入需要更新多个分散的存储区域，引入大量随机小I/O</li><li>频繁更新的场景还会引发列存储的"压缩抖动"问题</li></ul><p>由于OLAP场景多数操作是对部分特定列的海量查询操作，因此DSM模型更契合于OLAP分析型系统。</p><h2 id="pax模型">PAX模型</h2><p>NSM模型和DSM模型相互对立，各有优劣，分别适应于极端的OLTP和OLAP场景。但现实系统往往需要兼顾两种场景，因此催生了PAX（Partition Attributes Across）模型的诞生。PAX模型的核心思想是，<strong>先对数据条目按行进行分组，划分到不同的存储区域，再将同一分组内的数据按列组织存储</strong>。</p><p>如下图所示，PAX模型的存储结构采用两级分区设计。它首先将数据条目按行进行了划分，使同一组的数据条目存储在同一个PAX Page中。进一步地，PAX Page被划分为了多个minipage，分别对应于不同的列。类似于DSM模型，每一列的数据分别被放置在不同的minipage中，使得它们仍然存放在连续地址上。</p><figure><img src="fig4-PAX.jpg" alt="" /><figcaption>图4 PAX存储模型</figcaption></figure><p>PAX模型是对NSM模型和DSM模型一种折中设计，这使得它有效结合了二者的优势：</p><ul><li>面对特定列进行扫描查询时，系统只需要顺序访问每一个PAX Page的对应minipage，从而提高缓存效率</li><li>同一数据条目的各列数据处在同一个PAX Page中，保持了局部性。在面对完整条目的查询时，避免了数据重建过程中的跨页访问</li><li>数据条目的增加和删除所需进行的数据写入发生在同一个PAX Page，缓解了过程中的随机小I/O问题</li></ul><h1 id="parquetorc磁盘列式存储">Parquet/ORC——磁盘列式存储</h1><p>经过前文对NSM、DSM、PAX三种存储模型的简要分析，我们已建立起列式存储的基础认知框架。本章就当前主流的两种开源列式存储格式——Apache Parquet与Apache ORC，通过多维度对比探究其架构设计理念、实现原理及核心优势特性。</p><p>先将二者的文件格式示意图摆出来，接下来我们对其中的细节一一探讨。</p><figure><img src="fig5-parquet_orc_format.jpg" alt="" /><figcaption>图5 Parquet和ORC的文件格式</figcaption></figure><h2 id="存储格式">存储格式</h2><p>Apache Parquet和Apache ORC的存储格式本质上都基于PAX模型构建，严格来说并非纯列式存储，而是行列混合的存储架构。正因这种同源设计，它们在存储结构上存在诸多相似之处。为了清晰理解，我们明确两个核心概念：PAX模型中划分出的数据条目分组称为​​行组（Row Group，上章图中红蓝色方块）​​，而行组内每列数据对应的物理存储单元称为​​列块（Column Chunk，上章图中红色方块）​​。对应到Parquet和ORC中的概念如下表所示：</p><style>.center-table {  display: table;  margin-left: auto;  margin-right: auto;}</style><div class="center-table"><table><thead><tr class="header"><th style="text-align: center;"></th><th style="text-align: center;"><strong>Row Group</strong></th><th style="text-align: center;"><strong>Column Chunk</strong></th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><strong>Parquet</strong></td><td style="text-align: center;">Row Group</td><td style="text-align: center;">Column Chunk</td></tr><tr class="even"><td style="text-align: center;"><strong>ORC</strong></td><td style="text-align: center;">Stripe</td><td style="text-align: center;">Row Column</td></tr></tbody></table></div><p>从图5中，我们可以看出二者的设计在大体上是相似的。Footer中包含了文件级别（例如表结构等）和Row Group级别（例如偏移和Zone Map统计等）的元数据，它作为文件访问的起点，为下一步的数据检索提供了指引。多个Row Group组成了文件的主体数据区，每个Row Group内部遵循PAX模型的设计原理，通过Column Chunk对列数据进行物理组织。对于Parquet而言，Column Chunk还会进一步划分为多个Page，作为压缩单元（后续章节提及）。</p><p>尽管在存储格式上如此相似，二者在对如何划分Row Group采取了不同的选择：</p><ul><li><p>Parquet基于行数来确定Row Group的大小，以此确保单个Row Group有足够多行数据来支持高效的向量查询，但在内存开销上却不可控（因为Column Chunk是I/O单元，更大的Row Group也意味着更大的Column Chunk）</p></li><li><p>ORC使用了固定物理存储大小的Row Group以控制内存开销，但当遇到宽表场景（单行含数万列）时，单个Row Group内的有效行数大幅减少，反而降低了批处理效率。</p></li></ul><h2 id="过滤器">过滤器</h2><p>过滤器是实现高效查询的核心机制，它通过判断目标数据在特定存储单元中的存在性，避免不必要的I/O操作。</p><p>最常用的过滤器有两种：（1）<strong>​​Zone Map</strong>​​：它存储了指定存储单元的关键统计指标——最大值、最小值和数据条目总数，通过判断目标值是否落在最小-最大区间内，即可高效预判该存储单元是否存在目标数据；（2）<strong>​​Bloom Filter</strong>​​：它是基于概率的位映射过滤器，以极小的存储空间代价存储了数据"指纹"。当查询特定键值时，通过多次哈希计算检测对应比特位状态，若存在未激活位则确认数据必然不存在，反之则有较大概率存在。</p><p>Parquet与ORC均支持​​至少两级的Zone Map统计​​：<strong>文件级别</strong>（文件中的每列数据一个Zone Map）和<strong>Row Group级别</strong>（<em>Row Group中的每个Column Chunk一个Zone Map）。（特别说明：虽然从实现逻辑看，Row Group级别的Zone Map严格对应Column Chunk粒度，但为遵循官方文档表述且配合图5的图示结构讲解，本文仍采用"Row Group级别"的通用描述以避免概念混淆。</em>）正如图5所示，这两个级别的Zone Map均处于Footer区域，以集中式布局实现高速检索。</p><p>进一步地，Parquet和ORC还为更小粒度的存储单元提供了Zone Map支持。Parquet支持构建Page级别的Zone Map，以存储更细粒度的统计信息。在2.9.0版本以前，Parquet将其离散地存储在每个Page的Page Header中，这导致了查询过程中会引发大量的随机小I/O，性能受限；为此，在2.9.0版本之后，Parquet提供了可选的Page Index，将Page级别的Zone Map集中存储在了Page Index区域中，解决了随机小I/O问题。ORC采用可配置行数的动态Zone Map（默认每10000行一个Zone Map），存储在了每个Row Group的Index区域中。</p><p>Bloom Filter是Parquet和ORC额外的可选过滤器。Parquet为每一个Column Chunk构建单独的Bloom Filter（采用了<a href="https://dl.acm.org/doi/10.1145/1498698.1594230">Split Block Bloom Filter</a>的优化实现），存储在了连续区域。ORC则提供了与Zone Map相同的可配置行数粒度Bloom Filter，同样存储在了每个Row Group的Index区域中。</p><h2 id="嵌套数据结构">嵌套数据结构</h2><figure><img src="fig6-nested_data_encoding.jpg" alt="" /><figcaption>图6 嵌套数据结构表示</figcaption></figure><p>相较于高度规范化的结构化数据，半结构化数据天生具备更强的灵活性，能够高效容纳各类信息表达，同时提供更高扩展性。为了支持半结构化数据构建，Parquet和ORC分别设计了不同的嵌套数据结构实现方案。</p><p>Parquet的嵌套数据结构基于<a href="https://dl.acm.org/doi/10.14778/1920841.1920886">Dremel</a>。如图6所示，Parquet仅仅将嵌套数据的叶子节点作为独立的数据列进行存储，并为每个数据值绑定两个整型参数：Repetition Level（R）和Definition Level（L）：</p><ul><li>Repetition Level表示当前数据值和前一个数据值在嵌套路径的重复深度（例如图中第一行数据中的tag列，b与其前面的a共享同一个tags，则R为1；而接下来的缺失值和c都与其前面的值属于不同的行，则R为0）</li><li>Definition Level则仅对缺失值有效，表示当前缺失数据最深的有值层级，也即数据缺失发生层级的前一层级（例如图中第二行数据，其name.first为缺失值，但name仍然存在，则D值为1）</li></ul><p>这两个参数通过编码重复类型（repeated）的层级变化与可选类型（optional）的空值状态，完整描述了复杂嵌套结构。基于这两个参数序列，Parquet得以通过一个有限状态机实现列式存储数据向原始半结构化数据的重构。</p><p>ORC的嵌套数据结构则更为直接。嵌套数据结构上的每一个叶子节点都会成为独立存储的数据列，并为两类特殊数据绑定标识。对于重复类型数据，额外存储整型数据标记列表项数量；对于可选类型数据，则维护布尔值标记其存在状态。</p><p>相较而言，由于Parquet的方案只需实际存储叶子节点的列数据，它能够在重构数据时减少读取的列，并且在嵌套结构较为复杂、层次较深的场景下，存储开销较小。但同时，由于Parquet为每个数据列都绑定了Reptition Level和Definition Level，在嵌套结构较简单的情况下，它的存储开销反而更高。</p><h2 id="数据压缩与编码">数据压缩与编码</h2><p>压缩（Compression）是降低存储成本的有效手段，其处理过程是完全​​数据类型无关​的​——所有数据均被视为原始字节流，因此无论何种文件格式都可利用压缩算法缩减体积。Parquet和ORC均提供压缩支持：先将数据​​按固定块尺寸（如256KB）分割​​，再对每个数据块​​独立应用压缩算法​​。二者均支持Snappy、LZO等多种算法，供用户根据场景​​在压缩比与（解）压缩速度之间权衡​​。但事实上，在列式存储场景下，压缩机制所带来的效益并不明显。</p><p>编码（Encoding）则是一种更轻量级的数据压缩方式，其算法执行与数据类型息息相关，往往能在多数数据类型一致的情况下，达成比通用压缩更优的综合效能（压缩率与处理速度的平衡）。这种特性与列式存储架构天然契合——由于同一列数据具有完全相同的类型且连续存储在物理相邻区域，编码机制能够在此场景中充分发挥其高效性。</p><p>Parquet默认会对所有数据列（无论数据类型）应用​​DICT编码​​。该编码在应对大尺寸数据类型（如长文本）及高重复值场景时能实现优异压缩率；随后Parquet会采用Bitpacking或RLE编码对生成的字典数据进行二次压缩，实现压缩效率的进一步优化。</p><p>ORC默认情况下只对字符串类型数据应用DICT编码。对于整数类型列和DICT编码所产生的字典，ORC采用了一种贪婪的编码选择机制：ORC根据序列长度情况，按照预设的规则从RLE、Delta Encoding和Bitpacking中选择其中一种进行数据编码。这样的机制有助于达成更高的数据压缩率，但解码速度也相应有所下降，并且可能会造成较多的存储碎片。</p><h1 id="arrow内存列式存储">Arrow——内存列式存储</h1><p>Apache Arrow于2016年2月17日正式成为Apache顶级项目，与聚焦磁盘存储的Parquet和ORC不同，Arrow是专为​​内存计算​而​设计，其愿景在于建立跨异构系统的​​零拷贝数据交换标准​​。本章将主要探究Arrow的设计目标、特性及其内存数据格式。</p><h2 id="目标与特性优势">目标与特性优势</h2><figure><img src="fig7-before_arrow.png" alt="" /><figcaption>图7 未使用Arrow的异构系统数据传输</figcaption></figure><p>在大数据生态中，数据工程作为复杂的系统工程，需要整合多源异构的数据输入与多样化的处理工具。当Spark、Pandas等异构计算系统需要访问不同来源、不同格式的数据并进行跨系统、跨语言交互时，由于缺乏统一的数据平台和标准，系统间数据共享必须经历序列化、传输、反序列化的三段式流程。这种繁琐的机制不仅显著增加计算负载，还因数据的拷贝和传输而显得极其低效。</p><figure><img src="fig8-after_arrow.png" alt="" /><figcaption>图8 使用Arrow的异构系统数据共享</figcaption></figure><p>在这样的背景下，Arrow应运而生，其旨在构建跨平台、跨语言的​​统一内存数据标准​​，通过规范化的内存列式数据结构实现异构系统间​​零拷贝数据共享​​，从根本上消除序列化/反序列化与数据传输的双重开销。与此同时，其硬件协同的设计适配现代CPU特性（如SIMD指令集与缓存预取），显著提升数据计算效能。</p><p>基于以上目标，Arrow的设计有着以下几点显著的特性和优势：</p><ul><li><p><strong>多语言生态支持​</strong>：Arrow提供多语言原生API（Python、Java、C++等），并与Pandas、Spark等生态深度集成。</p></li><li><p><strong>零拷贝数据交互</strong>：在多语言支持的基础上，Arrow实现了真正的​​语言无关内存标准化​​——在任何编程环境下，其内存数据布局保持完全一致的结构设计。这种统一的物理表示使多语言系统能​​直接共享内存数据​​（如Java程序无缝访问C++构建的Arrow对象），彻底免除序列化/反序列化操作。这在真正意义上实现了零拷贝的数据交互，不仅减少CPU开销，还大幅降低跨语言/跨框架交互的延迟，提升分布式计算效率。</p></li><li><p><strong>硬件高效</strong>：Arrow采用列式内存布局，将同一列数据连续存储，显著提升数据分析效率。列式布局结合现代硬件特性（如CPU缓存、向量化指令），加速数据密集型计算。</p></li><li><p><strong>与磁盘列式存储互补</strong>：Arrow并非与Parquet和ORC这类磁盘列式存储格式，它专注内存计算，与磁盘列式存储形成互补：磁盘列式存储优化磁盘存储压缩率，Arrow优化内存处理效率。二者结合可覆盖数据从存储到计算的全生命周期高性能需求。</p></li></ul><h2 id="面向内存的列式数据格式">面向内存的列式数据格式</h2><p>面向内存的列式数据格式是Arrow的重要组成部分之一，同时也是实现跨系统高效数据共享的基础。本节着重讲解Arrow的内存数据格式，包括定长类型数据格式、变长类型数据格式、列表数据格式、和结构体数据格式。</p><h3 id="定长类型数据格式">定长类型数据格式</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C++">type FixedColumn <span class="hljs-keyword">struct</span> &#123;<br>  data       []byte <span class="hljs-comment">// 数据</span><br>  length     <span class="hljs-type">int</span>    <span class="hljs-comment">// 数据长度</span><br>  nullCount  <span class="hljs-type">int</span>    <span class="hljs-comment">// 缺失值个数</span><br>  nullBitmap []byte <span class="hljs-comment">// 缺失值位图</span><br>&#125;<br></code></pre></td></tr></table></figure><p>定长数据类型的数据列可以由上述数据结构管理。<code>data</code>是一块连续内存空间，用于存储真正的数据，而<code>length</code>则表示了该列数据个数。为了支持可选类型数据，<code>nullCount</code>和<code>nullBitmap</code>则被引入用于标记缺失值。</p><p>例如，一个<code>int32</code>类型的数据列<code>[1, null, 2, 4, 8]</code>的内存格式如下：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs gherkin"><span class="hljs-symbol">*</span> Length: 5, NullCount: 1<br><span class="hljs-symbol">*</span> NullBitmap:<br><br>  |<span class="hljs-string"> Byte 0 (validity bitmap) </span>|<span class="hljs-string"> Bytes 1-63            </span>|<br>  |<span class="hljs-string">--------------------------</span>|<span class="hljs-string">-----------------------</span>|<br>  |<span class="hljs-string"> 00011101                 </span>|<span class="hljs-string"> 0 (padding)           </span>|<br><br><span class="hljs-symbol">*</span> Data:<br><br>  |<span class="hljs-string"> Bytes 0-3   </span>|<span class="hljs-string"> Bytes 4-7   </span>|<span class="hljs-string"> Bytes 8-11  </span>|<span class="hljs-string"> Bytes 12-15 </span>|<span class="hljs-string"> Bytes 16-19 </span>|<span class="hljs-string"> Bytes 20-63           </span>|<br>  |<span class="hljs-string">-------------</span>|<span class="hljs-string">-------------</span>|<span class="hljs-string">-------------</span>|<span class="hljs-string">-------------</span>|<span class="hljs-string">-------------</span>|<span class="hljs-string">-----------------------</span>|<br>  |<span class="hljs-string"> 1           </span>|<span class="hljs-string"> unspecified </span>|<span class="hljs-string"> 2           </span>|<span class="hljs-string"> 4           </span>|<span class="hljs-string"> 8           </span>|<span class="hljs-string"> unspecified (padding) </span>|<br></code></pre></td></tr></table></figure><p>值得注意的是，即使存在缺失值，Arrow定长类型数据格式也会保留其对应的物理内存空间。这种做法虽会增加内存占用，但其核心优势在于​​访问效率的极致优化​​——无需通过<code>nullBitMap</code>执行字段偏移量计算，确保任意字段的随机访问时间复杂度稳定为O(1)。相比内存资源的消耗，Arrow将​​数据访问性能​​置于更高优先级。</p><h3 id="变长类型数据格式">变长类型数据格式</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C++">type VarColumn <span class="hljs-keyword">struct</span> &#123;<br>  data       []byte   <span class="hljs-comment">// 数据</span><br>  offsets    []int64  <span class="hljs-comment">// 每个数据值的起始偏移</span><br>  length     <span class="hljs-type">int</span>      <span class="hljs-comment">// 数据长度</span><br>  nullCount  <span class="hljs-type">int</span>      <span class="hljs-comment">// 缺失值个数</span><br>  nullBitmap []byte   <span class="hljs-comment">// 缺失值位图</span><br>&#125;<br></code></pre></td></tr></table></figure><p>相较于定长数据，变长数据的存储额外引入了<code>offsets</code>用于表示每个数据值的起始偏移量，以此实现对变长数据的标识。每个数据值的长度则可以通过<code>offsets[i+1] - offsets[i]</code>得出。</p><p>例如，一个<code>string</code>类型的数据列<code>['joe', null, null, 'mark']</code>的内存格式如下：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs gherkin"><span class="hljs-symbol">*</span> Length: 4, NullCount: 2<br><span class="hljs-symbol">*</span> NullBitmap:<br><br>  |<span class="hljs-string"> Byte 0 (validity bitmap) </span>|<span class="hljs-string"> Bytes 1-63            </span>|<br>  |<span class="hljs-string">--------------------------</span>|<span class="hljs-string">-----------------------</span>|<br>  |<span class="hljs-string"> 00001001                 </span>|<span class="hljs-string"> 0 (padding)           </span>|<br><br><span class="hljs-symbol">*</span> Offsets:<br><br>  |<span class="hljs-string"> Bytes 0-19     </span>|<span class="hljs-string"> Bytes 20-63           </span>|<br>  |<span class="hljs-string">----------------</span>|<span class="hljs-string">-----------------------</span>|<br>  |<span class="hljs-string"> 0, 3, 3, 3, 7  </span>|<span class="hljs-string"> unspecified (padding) </span>|<br><br> <span class="hljs-symbol">*</span> Data:<br><br>  |<span class="hljs-string"> Bytes 0-6      </span>|<span class="hljs-string"> Bytes 7-63            </span>|<br>  |<span class="hljs-string">----------------</span>|<span class="hljs-string">-----------------------</span>|<br>  |<span class="hljs-string"> joemark        </span>|<span class="hljs-string"> unspecified (padding) </span>|<br></code></pre></td></tr></table></figure><h3 id="列表数据格式">列表数据格式</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C++">type List&lt;T&gt; <span class="hljs-keyword">struct</span> &#123;<br>  data       T        <span class="hljs-comment">// 数据</span><br>  offsets    []int64  <span class="hljs-comment">// 每个数据值的起始偏移</span><br>  length     <span class="hljs-type">int</span>      <span class="hljs-comment">// 数据长度</span><br>  nullCount  <span class="hljs-type">int</span>      <span class="hljs-comment">// 缺失值个数</span><br>  nullBitmap []byte   <span class="hljs-comment">// 缺失值位图</span><br>&#125;<br></code></pre></td></tr></table></figure><p>列表<code>List&lt;T&gt;</code>表示数据列的每个数据值都是一个<code>T</code>类型数据的列表，本质上是一种嵌套数据。与变长类型数据格式相似，唯一不同的是其<code>data</code>字段由单纯的真正数据变成了<code>T</code>。这是事实上是一次解包，也是嵌套发生所在。</p><p>例如，一个<code>List&lt;int8&gt;</code>的数据列<code>[[12, -7, 25], null, [0, -127, 127, 50], []]</code>的内存格式如下：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs gherkin"><span class="hljs-symbol">*</span> Length: 4, NullCount: 1<br><span class="hljs-symbol">*</span> NullBitmap:<br><br>  |<span class="hljs-string"> Byte 0 (validity bitmap) </span>|<span class="hljs-string"> Bytes 1-63            </span>|<br>  |<span class="hljs-string">--------------------------</span>|<span class="hljs-string">-----------------------</span>|<br>  |<span class="hljs-string"> 00001101                 </span>|<span class="hljs-string"> 0 (padding)           </span>|<br><br><span class="hljs-symbol">*</span> Offsets(int32)<br><br>  |<span class="hljs-string"> Bytes 0-3  </span>|<span class="hljs-string"> Bytes 4-7   </span>|<span class="hljs-string"> Bytes 8-11  </span>|<span class="hljs-string"> Bytes 12-15 </span>|<span class="hljs-string"> Bytes 16-19 </span>|<span class="hljs-string"> Bytes 20-63           </span>|<br>  |<span class="hljs-string">------------</span>|<span class="hljs-string">-------------</span>|<span class="hljs-string">-------------</span>|<span class="hljs-string">-------------</span>|<span class="hljs-string">-------------</span>|<span class="hljs-string">-----------------------</span>|<br>  |<span class="hljs-string"> 0          </span>|<span class="hljs-string"> 3           </span>|<span class="hljs-string"> 3           </span>|<span class="hljs-string"> 7           </span>|<span class="hljs-string"> 7           </span>|<span class="hljs-string"> unspecified (padding) </span>|<br><br><span class="hljs-symbol">*</span> Data (int8Array):<br>  <span class="hljs-symbol">*</span> Length: 7,  NullCount: 0<br>  <span class="hljs-symbol">*</span> NullBitmap: Not required<br>  <span class="hljs-symbol">*</span> Data (int8)<br><br>    |<span class="hljs-string"> Bytes 0-6                    </span>|<span class="hljs-string"> Bytes 7-63            </span>|<br>    |<span class="hljs-string">------------------------------</span>|<span class="hljs-string">-----------------------</span>|<br>    |<span class="hljs-string"> 12, -7, 25, 0, -127, 127, 50 </span>|<span class="hljs-string"> unspecified (padding) </span>|<br></code></pre></td></tr></table></figure><p>可以看到在<code>List&lt;int8&gt;</code>的<code>data</code>下存放的是<code>int8</code>定长类型的完整数据表示，它将原有的<code>List&lt;int8&gt;</code>所有数据进行了一次解包，构成了连续的<code>int8</code>数组。</p><p>进一步地，<code>List&lt;List&lt;int8&gt;&gt;</code>类型的<code>[[[1, 2], [3, 4]], [[5, 6, 7], null, [8]], [[9, 10]]]</code>的内存格式表示如下：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs gherkin"><span class="hljs-symbol">*</span> Length 3<br><span class="hljs-symbol">*</span> Nulls count: 0<br><span class="hljs-symbol">*</span> Validity bitmap buffer: Not required<br><span class="hljs-symbol">*</span> Offsets buffer (int32)<br><br>  |<span class="hljs-string"> Bytes 0-3  </span>|<span class="hljs-string"> Bytes 4-7  </span>|<span class="hljs-string"> Bytes 8-11 </span>|<span class="hljs-string"> Bytes 12-15 </span>|<span class="hljs-string"> Bytes 16-63           </span>|<br>  |<span class="hljs-string">------------</span>|<span class="hljs-string">------------</span>|<span class="hljs-string">------------</span>|<span class="hljs-string">-------------</span>|<span class="hljs-string">-----------------------</span>|<br>  |<span class="hljs-string"> 0          </span>|<span class="hljs-string">  2         </span>|<span class="hljs-string">  5         </span>|<span class="hljs-string">  6          </span>|<span class="hljs-string"> unspecified (padding) </span>|<br><br><span class="hljs-symbol">*</span> Values array (`List<span class="hljs-variable">&lt;Int8&gt;</span>`)<br>  <span class="hljs-symbol">*</span> Length: 6, Null count: 1<br>  <span class="hljs-symbol">*</span> Validity bitmap buffer:<br><br>    |<span class="hljs-string"> Byte 0 (validity bitmap) </span>|<span class="hljs-string"> Bytes 1-63  </span>|<br>    |<span class="hljs-string">--------------------------</span>|<span class="hljs-string">-------------</span>|<br>    |<span class="hljs-string"> 00110111                 </span>|<span class="hljs-string"> 0 (padding) </span>|<br><br>  <span class="hljs-symbol">*</span> Offsets buffer (int32)<br><br>    |<span class="hljs-string"> Bytes 0-27           </span>|<span class="hljs-string"> Bytes 28-63           </span>|<br>    |<span class="hljs-string">----------------------</span>|<span class="hljs-string">-----------------------</span>|<br>    |<span class="hljs-string"> 0, 2, 4, 7, 7, 8, 10 </span>|<span class="hljs-string"> unspecified (padding) </span>|<br><br>  <span class="hljs-symbol">*</span> Values array (Int8):<br>    <span class="hljs-symbol">*</span> Length: 10, Null count: 0<br>    <span class="hljs-symbol">*</span> Validity bitmap buffer: Not required<br><br>      |<span class="hljs-string"> Bytes 0-9                     </span>|<span class="hljs-string"> Bytes 10-63           </span>|<br>      |<span class="hljs-string">-------------------------------</span>|<span class="hljs-string">-----------------------</span>|<br>      |<span class="hljs-string"> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 </span>|<span class="hljs-string"> unspecified (padding) </span>|<br></code></pre></td></tr></table></figure><h3 id="结构体数据格式">结构体数据格式</h3><p>有了上述几种数据的基础表示，结构体数据格式只需要按照其具体定义进行相应的嵌套即可。</p><p>例如，<code>Struct&lt;VarBinary, Int32&gt;</code>的数据<code>[&#123;'joe', 1&#125;, &#123;null, 2&#125;, null, &#123;'mark', 4&#125;]</code>，包含了<code>['joe', null, 'alice', 'mark']</code>和<code>[1, 2, null, 4]</code>两个子列，其内存格式如下：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs gherkin"><span class="hljs-symbol">*</span> Length: 4, Null count: 1<br><span class="hljs-symbol">*</span> Validity bitmap buffer:<br><br>  |<span class="hljs-string"> Byte 0 (validity bitmap) </span>|<span class="hljs-string"> Bytes 1-63            </span>|<br>  |<span class="hljs-string">--------------------------</span>|<span class="hljs-string">-----------------------</span>|<br>  |<span class="hljs-string"> 00001011                 </span>|<span class="hljs-string"> 0 (padding)           </span>|<br><br><span class="hljs-symbol">*</span> Children arrays:<br>  <span class="hljs-symbol">*</span> field-0 array (`VarBinary`):<br>    <span class="hljs-symbol">*</span> Length: 4, Null count: 1<br>    <span class="hljs-symbol">*</span> Validity bitmap buffer:<br><br>      |<span class="hljs-string"> Byte 0 (validity bitmap) </span>|<span class="hljs-string"> Bytes 1-63            </span>|<br>      |<span class="hljs-string">--------------------------</span>|<span class="hljs-string">-----------------------</span>|<br>      |<span class="hljs-string"> 00001101                 </span>|<span class="hljs-string"> 0 (padding)           </span>|<br><br>    <span class="hljs-symbol">*</span> Offsets buffer:<br><br>      |<span class="hljs-string"> Bytes 0-19     </span>|<span class="hljs-string"> Bytes 20-63           </span>|<br>      |<span class="hljs-string">----------------</span>|<span class="hljs-string">-----------------------</span>|<br>      |<span class="hljs-string"> 0, 3, 3, 8, 12 </span>|<span class="hljs-string"> unspecified (padding) </span>|<br><br>     <span class="hljs-symbol">*</span> Value buffer:<br><br>      |<span class="hljs-string"> Bytes 0-11     </span>|<span class="hljs-string"> Bytes 12-63           </span>|<br>      |<span class="hljs-string">----------------</span>|<span class="hljs-string">-----------------------</span>|<br>      |<span class="hljs-string"> joealicemark   </span>|<span class="hljs-string"> unspecified (padding) </span>|<br><br>  <span class="hljs-symbol">*</span> field-1 array (int32 array):<br>    <span class="hljs-symbol">*</span> Length: 4, Null count: 1<br>    <span class="hljs-symbol">*</span> Validity bitmap buffer:<br><br>      |<span class="hljs-string"> Byte 0 (validity bitmap) </span>|<span class="hljs-string"> Bytes 1-63            </span>|<br>      |<span class="hljs-string">--------------------------</span>|<span class="hljs-string">-----------------------</span>|<br>      |<span class="hljs-string"> 00001011                 </span>|<span class="hljs-string"> 0 (padding)           </span>|<br><br>    <span class="hljs-symbol">*</span> Value Buffer:<br><br>      |<span class="hljs-string"> Bytes 0-3   </span>|<span class="hljs-string"> Bytes 4-7   </span>|<span class="hljs-string"> Bytes 8-11  </span>|<span class="hljs-string"> Bytes 12-15 </span>|<span class="hljs-string"> Bytes 16-63           </span>|<br>      |<span class="hljs-string">-------------</span>|<span class="hljs-string">-------------</span>|<span class="hljs-string">-------------</span>|<span class="hljs-string">-------------</span>|<span class="hljs-string">-----------------------</span>|<br>      |<span class="hljs-string"> 1           </span>|<span class="hljs-string"> 2           </span>|<span class="hljs-string"> unspecified </span>|<span class="hljs-string"> 4           </span>|<span class="hljs-string"> unspecified (padding) </span>|<br></code></pre></td></tr></table></figure><h1 id="参考文献">参考文献</h1><p><a href="https://dl.acm.org/doi/10.14778/3611479.3611507">A Deep Dive into Common Open Formats for Analytical DBMSs (VLDB`23)</a></p><p><a href="https://dl.acm.org/doi/10.14778/3626292.3626298">An Empirical Evaluation of Columnar Storage Formats (VLDB`23)</a></p><p><a href="https://parquet.apache.org/docs/overview/">Apache Parquet Documentation</a></p><p><a href="https://orc.apache.org/specification/ORCv1/">Apache ORC Specification v1</a></p><p><a href="https://arrow.apache.org/docs/format/index.html">Apache Arrow Specifications</a></p>]]></content>
    
    
    <categories>
      
      <category>列式存储</category>
      
    </categories>
    
    
    <tags>
      
      <tag>列式存储</tag>
      
      <tag>Parquet</tag>
      
      <tag>ORC</tag>
      
      <tag>Arrow</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读 | Ditto：An Elastic and Adaptive Memory-Disaggregated Caching System</title>
    <link href="/2025/06/01/readpaper-Ditto/"/>
    <url>/2025/06/01/readpaper-Ditto/</url>
    
    <content type="html"><![CDATA[<p>文章出自香港中文大学，华为云左鹏飞参与指导，发表于SOSP`23。这项研究是作者在华为云实习期间完成的，主要工作是设计了一种面向分离式内存架构的缓存系统。缓存可能是分离式内存这种大内存系统最具实用价值的应用方向了，在我看来这篇论文选题上具备比较高的实践价值。</p><span id="more"></span><p><em>Paper Link</em>: <a href="https://dl.acm.org/doi/10.1145/3600006.3613144">https://dl.acm.org/doi/10.1145/3600006.3613144</a></p><p><em>Open source</em>: <a href="https://github.com/dmemsys/Ditto">https://github.com/dmemsys/Ditto</a></p><h2 id="背景">背景</h2><p>Memcached和Redis这类内存缓存系统被广泛应用于云服务中，以在数据访问中降低延迟和提高吞吐率。但这类缓存系统一般构建和部署在CPU和内存紧密耦合的一体式服务器上，这使得它们在动态资源调整过程时面临两个问题：</p><ul><li><p><strong>资源低效</strong></p><p>一体式服务器架构下，硬件资源以CPU和内存紧密耦合的服务器节点为粒度进行分配。这不可避免地导致了资源浪费，例如，当仅仅是CPU或内存中的一类资源告急，服务器粒度的扩展还是会将另一类资源一同分配。</p></li><li><p><strong>资源调整耗时长</strong></p><p><img src="fig1-redis_performanceredis_when_adjusting_resources.jpg" /></p><p>缓存系统通常以数据分片的方式实现多节点的部署。在资源调整时，集群节点数量发生变更，数据就需要经历重分片和迁移过程。这就引入了数据的迁移开销，期间系统性能不可避免地会下降。</p></li></ul><p>分离式内存（DM）架构通过解耦CPU和内存资源解决上述问题。两类硬件资源解耦池化，分别形成计算节点（CN）构成的计算池和内存节点（MN）构成的内存池，二者通过CPU-bypass的高速网络（例如RDMA、CXL）互联，以实现更精细的资源分配，从而解决资源低效问题。此外，DM架构下所有CN都能直接寻址访问到所有MN的内存，因此资源调整不再需要数据迁移，只需要调整逻辑上的分配即可，由此避免了迁移开销和性能波动。</p><h2 id="挑战">挑战</h2><p>当然，不是直接将现有的缓存系统部署在DM上就完事大吉，面向DM构建缓存系统也有其挑战。</p><ul><li><p><strong>如何在client-centric模式下高效地执行缓存算法？</strong></p><p>现有的缓存系统大都是以服务器为中心（server-centric）的架构，也即，数据的访问和淘汰替换均由缓存服务器的CPU集中完成。但在DM架构下，缓存系统更应该被设计为以客户端为中心（client-centric）的架构，因为负责缓存数据的MN没有充足的CPU资源，需要CN上的客户端通过CPU-bypass的方式进行数据访问和缓存算法执行。此时，难题随之而来。</p><p>一来，缺乏了中央服务，客户端就要自主进行缓存对象热度信息的维护，但CN上的客户端各自运行，难以感知整个缓存系统各缓存对象的全局访问情况。</p><p>二来，缓存的构建通常需要维护特殊的数据结构（例如链表、堆）来反映缓存对象的优先级情况。但在DM架构下，这些数据结构需要面临所有CN上的客户端的并发访问，因而需要复杂的机制和频繁的网络往返（RTT）来保证正确的读写，效率严重受损。</p></li><li><p><strong>如何调整缓存算法以适应频繁动态变化的资源配置？</strong></p><p>缓存算法的缓存命中率与数据访问模式和缓存大小有着紧密的关联，不同的情况有着各自最优的缓存算法，但这二者又受到硬件资源分配调整的影响。</p><p><img src="fig2-hit_rate_different_client_portion.jpg" /></p><p>一来，DM上的缓存系统服务于大量的应用，每个应用各自表现出自己独特的访问模式，而整体系统的访问模式则是所有应用的访问模式的混合。因此，任意一个应用的计算资源受到调整时，都会影响整个系统的访问模式。</p><p><img src="fig3-hit_rate_different_cache_size.jpg" /></p><p>二来，内存资源的分配直接关系到缓存空间大小，而不同缓存大小下的最优缓存算法也是不同的，例如有些工作负载在低缓存空间时LRU更优，但在高缓存空间是LFU更优。</p><p>因此，DM上的缓存系统必须根据不断变化的资源配置动态选择最佳的缓存算法，以提高缓存命中率。</p></li></ul><p>文章就针对上述两个问题提出解决方案，设计了面向DM架构的缓存系统Ditto（Ditto其实就是神奇宝贝里的百变怪😛）。</p><h2 id="ditto设计">Ditto设计</h2><h3 id="架构概览">架构概览</h3><p><img src="fig4-Ditto_overview.jpg" /></p><p>在MN上，Ditto使用哈希表管理缓存对象，表内存储缓存对象的地址。在CN上，每个应用进程启动一个Ditto进程作为客户端，应用进程和Ditto之间通过本地共享内存进行交互以发起SET和GET操作。应用可以通过调整Ditto客户端进程的线程数和CPU核数来调整计算资源的分配。</p><p>GET操作流程<strong>：</strong>客户端首先通过一个RDMA_READ操作从哈希表中获取缓存对象地址，再通过一个RDMA_READ操作从对象地址读回缓存对象。</p><p>SET操作流程<strong>：</strong>客户端通过一个RDMA_READ操作读回缓存对象在哈希表中对应的slot，随后通过一个RDMA_WRITE操作将缓存对象写入新地址，最后通过一个RDMA_CAS操作在对应slot中修改的缓存地址。</p><h3 id="client-centric的缓存框架">Client-Centric的缓存框架</h3><p>针对于第一个挑战点，Ditto提出了Client-Centric的缓存框架。</p><p><strong>（1）缓存对象元数据及操作接口</strong></p><p>首先，Ditto为每个缓存对象维护一个元数据，用于记录访问信息，并为客户端提供了两个接口：<em>priority(Metadata)</em>用于根据元数据计算缓存优先级；<em>update(Metadata)</em>用于更新元数据。元数据的具体内容可以根据所需引入的缓存算法而定制，Table 1列举了多数缓存算法常用的缓存访问信息。</p><p><img src="table1-access_information.jpg" /></p><p>在此基础上，当使用LRU-K算法时，<em>update</em>和<em>pirority</em>可以实现如下：</p><p><img src="listing1-update_priority_LRUK.jpg" /></p><p>其次，Ditto采用了一种优先级评估采样的方式来选择来选择缓存驱逐对象。具体来说，每次执行缓存驱逐时，客户端将在所有缓存对象中随机采样K个对象，对其执行<em>pirority</em>函数计算优先级，并将其中优先级最低的缓存对象驱逐。由此，Ditto不必花费大量性能开销用于维护如链表、队列、堆等数据结构。</p><p>（事实上，当下Redis采用缓存淘汰方案也正是基于随机采样的缓存淘汰策略——NearlyLRU，其目的也同样是为了避免对复杂数据结构的维护开销，只需要一个哈希表即可实现缓存）</p><p><strong>（2）Sample-friendly哈希表</strong></p><p>如果将元数据和缓存对象一同在内存池中离散存储，无论是<em>priority</em>函数读元数据还是<em>update</em>函数写元数据，都需要多次RDMA操作来完成，这就容易系统吞吐率受限。</p><p><img src="fig5-sample_friendly_hash_table.jpg" /></p><p>为了减少RDMA操作次数，Ditto将元数据拆分，把不同缓存算法通用的缓存访问信息跟随索引一同存储在哈希表中（如Figure 7中的<em>insert_ts</em>、<em>last_ts</em>、<em>freq</em>），由此在<em>priority</em>和<em>update</em>过程中减少一次RDMA操作。</p><p>进一步地，Ditto还通过两个维度的分类来继续减少元数据维护过程中的RDMA操作次数（如Table 1示例）：</p><ul><li><p><strong>Global信息</strong>是需要所有客户端共同维护的访问信息（如<em>insert_ts</em>、<em>last_ts</em>、<em>freq</em>），它们需要被放入元数据中；<strong>Local信息</strong>则无需共同维护（如<em>latency</em>、<em>cost</em>），每个客户端根据自身情况得出即可，因为在同一集群下每个客户端得到这类信息的结果基本相同，无需放入元数据中进行维护，从而减少RDMA网络开销</p></li><li><p><strong>Stateless信息</strong>是通过覆盖写的方式进行更新的访问信息（如<em>insert_ts</em>、<em>last_ts</em>），因此可以将这类信息组织在连续地址上通过单个RDMA Write操作完成多个数据的更新；<strong>Stateful信息</strong>的更新则依赖于其历史值（如<em>freq</em>），只能逐个通过RDMA FAA操作更新。</p></li></ul><p>（个人这个设计点存在一定疑点。对于Stateless信息，它们往往不一起更新，比如<em>insert_ts和last_ts</em>更新的时机就不一致，那么这个设计点就没啥用。对于会被一起更新的多个Stateless信息，由于RDMA Write只能保证cacheline粒度的原子性，只用RDMA Write更新多个Stateless信息可能会存在不一致问题，这个设计点也派不上用场）</p><p><strong>（3）元数据更新缓存</strong></p><p>Ditto客户端会在本地维护一个缓存，用于合并对同一个缓存对象元数据的更新，延迟提交到内存节点。当因为元数据更新缓存满了或者更新次数超出阈值时，对元数据的更新才会合并更新到内存节点上，以此减少RDMA网络往返次数。</p><h3 id="分布式自适应缓存">分布式自适应缓存</h3><p>针对第二个挑战点，Ditto提出了分布式自适应缓存方案来应对DM上不断变化的工作负载和动态资源变更。</p><p><strong>（1）一体式服务器架构下的自适应缓存方案</strong></p><p><img src="fig6-adaptive_cache_on_monolithic_server.jpg" /></p><p>自适应缓存方案在一体式服务器架构下的缓存系统也有被应用。缓存服务同时执行多个缓存算法，各自维护缓存队列，称之为专家（Expert）。每个专家都分配了一个权重值，用于反应在当前工作负载的表现。当缓存淘汰发生时，其大体流程可以分为几个步骤（Figure 8）：</p><ol type="1"><li><p>每个专家根据自身算法分别给出一个淘汰候选对象；</p></li><li><p>根据各个专家的权重值，从候选对象中挑选出最终的淘汰对象（专家权重值越高，其给出的候选对象更容易被最终淘汰）；</p></li><li><p>淘汰对象的元数据被放入一个固定大小的FIFO队列，称为淘汰历史队列；</p></li><li><p>当后续访问发生缓存缺失时，判断缺失对象是否在淘汰历史队列中；</p></li><li><p>若缺失对象在淘汰历史队列，说明先前的驱逐选择不理想，相应降低对应专家的权重值。</p></li></ol><p>但DM架构下的缓存系统无法直接采用上述方案，因为此时FIFO淘汰历史队列和专家权重将会面临大量远程客户端的RDMA访问，为保证并发安全引入的同步机制将会造成巨大的性能开销。Ditto则针对这两个数据结构进行优化来解决问题。</p><p><strong>（2）轻量级淘汰历史</strong></p><p>Ditto通过嵌入历史信息和逻辑FIFO队列的方式避免了实际维护FIFO淘汰历史队列的性能开销。</p><p><img src="fig7-lightweight_history_entry.jpg" /></p><p>当一个缓存对象被淘汰时，Ditto会在哈希表中对应的元数据slot写入历史信息，从而将其转变为一个历史条目。具体而言如Figure 9，<em>size</em>字段将被设置为0xFF标记该slot为历史条目（为0则代表空slot）；<em>pointer</em>字段被写入一个唯一的历史ID；<em>insert_st</em>字段则用于存储专家位图expert_bmap，用于指示其是被哪个专家选出淘汰的。此外，<em>hash</em>字段用于存储缓存对象ID，它在缓存被插入时便被设置，直到从淘汰历史队列中彻底驱逐才会被修改。</p><p><img src="fig8-insert_evict_history_entry.jpg" /></p><p>有了上述历史信息嵌入，Ditto得以维护一个逻辑FIFO队列，而非实际物理结构。Ditto设置了一个6-bytes的全局历史计数器，与历史ID相对应。当客户端将一个缓存对象淘汰时，它通过RDMA_FAA操作从计数器中取得一个全局唯一的历史ID，写入<em>pointer</em>字段，该历史ID就代表了缓存对象在逻辑FIFO队列的位置；当客户端访问发生了缓存缺失，若其对应的元数据slot中<em>size</em>字段为0xFF，且<em>pointer</em>字段内的历史ID与当前计数器的差值小于预设的逻辑FIFO队列长度，则说明目标缓存对象在历史淘汰队列当中，随后根据<em>insert_st</em>字段内的expert_bmap调整对应专家权重。</p><p><strong>（3）延迟专家权重更新</strong></p><p>当一个缓存缺失对象在淘汰历史队列的第t位被发现时，其对应的专家权重将依据<span class="math inline">\(w_{E_{i}}=w_{E_{i}} \cdot e^{\lambda d^t}\)</span>调整，其中<span class="math inline">\(\lambda\)</span>是学习率，<span class="math inline">\(d^t\)</span>是惩罚项。显然这个过程无法通过RDMA_FAA或RDMA_CAS简单地实现，多个客户端之间需要同步机制进行正确的并发更新，这就引入了昂贵的同步开销。</p><p>为此，Ditto令客户端在本地缓存对专家权重的调整，并批量化地提交到处于MN的专家权重控制器，由它进行统一调整。</p><p><img src="fig9-lazy_weight_update_scheme.jpg" /></p><p>如Figure 12，客户端在本地维护了一个惩罚缓冲区。当发现缺失对象存在于缓存淘汰队列时，它将在惩罚缓冲区中暂存权重调整系数<span class="math inline">\(e^{\lambda d^t}\)</span>，以相乘的方式不断累积权重调整。直到一定的缓冲时间或调整次数后，客户端以RDMA-based RPC的方式将缓存的调整系数提交给MN的控制器，由它进行权重更新，随后返回最新的专家权重给客户端。</p><p>由此，Ditto通过中央集中更新的方式避免了复杂同步机制可能对吞吐率造成的影响，并且由于该计算过程较为简单，并不会为MN引入复杂的计算开销。</p><h2 id="实验测试">实验测试</h2><p>简单放几个比较重要的实验，更多的实验分析可以直接阅读原文获取。</p><p>文章将Ditto与Redis、CliqueMap（CM）以及Shard-LRU进实验对比，使用了YCSB测试负载和一些真实负载。从实验结果上看，Ditto的优势还是相对领先的。</p><p><img src="fig10-performance_on_ycsb.jpg" /></p><p><img src="fig11-performance_on_read_world.jpg" /></p><h2 id="总结和讨论">总结和讨论</h2><p>Ditto主要针对了DM架构下的缓存系统构建进行了探讨。</p><p>针对高效缓存算法执行的实现，Ditto选择了使用基于采样的缓存淘汰策略以避免复杂数据结构的维护，并通过优化缓存访问信息的布局来减少过程中RDMA网络操作的次数。</p><p>针对自适应缓存策略的实现，Ditto巧妙地通过全局计数器实现了逻辑FIFO队列，从而避免了实际物理结构的维护开销，并通过权重调整的批量化提交和中心化维护方案，避免了多客户端并发更新权重所导致的同步开销。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
      <tag>分离式内存</tag>
      
      <tag>缓存系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读 | Design Guidelines for Correct, Efficient, and Scalable Synchronization using One-Sided RDMA</title>
    <link href="/2024/01/30/readpaper-One-side-rdma-design-guidelines/"/>
    <url>/2024/01/30/readpaper-One-side-rdma-design-guidelines/</url>
    
    <content type="html"><![CDATA[<p>文章由达姆施塔特工业大学的TOBIAS ZIEGLER等人发表于SIGMOD'23，主要描述了如何利用one-sided RDMA来构建正确、高效且具有扩展性的同步机制。</p><span id="more"></span><p><em>Paper Link</em>: <a href="https://dl.acm.org/doi/10.1145/3589276">https://dl.acm.org/doi/10.1145/3589276</a><br /><em>Open Source</em>: <a href="https://github.com/DataManagementLab/RDMA_synchronization">https://github.com/DataManagementLab/RDMA_synchronization</a></p><p>尽管RDMA已经出现了二十多年，时至今日它仍然是构建高性能分布式系统强有力的工具。尤其是最近几年，学术界对它热情不减反增。这篇文章没有提出什么新颖的系统或者架构，它总结了一套利用one-sided RDMA设计高效正确同步机制的方法和准则。</p><p>作为一个没啥学术天赋的人，比起天马行空的新系统设计，我向来是更喜欢这类“经验总结”类型的文章，它能给我在系统工程实现上提供及时的指导。ATC'16也有一篇<a href="https://www.usenix.org/conference/atc16/technical-sessions/presentation/kalia">Design Guidelines for High Performance RDMA Systems</a>探讨了如何设计一个高性能的RDMA系统。存算分离、分离式内存等概念火热的今天，更高效的RDMA one-sided操作愈加受到青睐，因此这篇文章也更详细地针对one-sided RDMA进行讨论。</p><p>文章首先指出利用one-sided RDMA来构建正确、高效且具有扩展性的同步机制是非常困难的。现有的文章或多或少都在这方面设计犯了错误。例如有些文章的同步机制的正确性建立在RDMA操作完全遵守地址升序的顺序进行这一假设上。但是这个假设是错误的，RDMA标准中RDMA read操作并没有这一保证，这就可能发生无法检测的错误。文章里还做了相关实验证明了这一观点。</p><p>基于这个动机，文章开始详细介绍在RDMA one-sided场景下各类同步机制的设计。</p><h2 id="悲观同步机制">悲观同步机制</h2><figure><img src="fig1-exclusive_latch.jpg" alt="" /><figcaption>图1 RDMA实现悲观锁机制</figcaption></figure><p>为了避免对远程数据结构的并发修改，利用one-sided RDMA实现锁存器（latch）进而实现单边悲观控制是一个有效的手段。</p><p>现有的悲观锁模式大致可以分为<strong>独占锁</strong>和<strong>读写锁</strong>两种。以读写锁为例，典型的实现是在远程内存设置一个8字节的值：通过RDMA compare-and-swap（RDMA CAS）操作设置其中一个bit（通常是尾部bit）以获取写锁，而其它bit作为读锁计数器，通过RDMA fetch-and-add（RDMA FAA）操作进行添加来获取读锁。 图1就是一个典型的独占锁机制。</p><h3 id="rdma-atomic操作性能">RDMA atomic操作性能</h3><p>显而易见，悲观锁的实现高度依赖于RDMA atomics操作，在考虑如何优化悲观锁之前，需要先了解一下它们在各种情形下的性能。</p><h4 id="争用非争用下rdma-atomic性能">争用/非争用下RDMA atomic性能</h4><figure><img src="fig2-(un)contended_atomic_performance.jpg" alt="" /><figcaption>图2 争用/非争用下RDMA atomic性能对比</figcaption></figure><p>在某些高并发的工作负载下，不可避免地会出现对同一资源的高度争用，进而引发RDMA atomic对同一把锁的争用修改。那么争用对性能影响几何？图2展示了争用和非争用下RDMA CAS的吞吐率，作为参考也对RDMA READ进行了实验。可以看得出来争用对RDMA atomic操作的影响是非常大的，峰值吞吐率相差了25倍之多，可扩展性也差异巨大。（另外可以看到非争用RDMA CAS和RDMA READ在Worker超出256后也有所下降，这是由于QP数过多，需要维护的状态超出网卡内存导致的）</p><h4 id="步长与rdma-atomic性能">步长与RDMA atomic性能</h4><figure><img src="fig3-atomic_under_different_stride.jpg" alt="" /><figcaption>图3 各个锁间距在不同步长下的RDMA CAS性能</figcaption></figure><figure><img src="fig4-rnic_architecture.jpg" alt="" /><figcaption>图4 RNIC内部锁表</figcaption></figure><p>除了并发争用以外，一个容易忽视的因素也会影响RDMA atomic的性能——<strong>步长</strong>。先来看看实验结果，可以从图3看到随着锁的步长逐步上升，RDMA CAS的吞吐量在下降。神奇！这是为什么呢？虽然RNIC厂商没有公开其架构，但可以从实验中窥探一二。可能RNIC对RDMA atomic操作的实现是通过内部的一个物理锁表实现的。就像图4(a)展示的那样，锁表结构类似于一个Hash表，通过目标地址的后12 bit来定位表项。对于地址相隔4KB的RDMA atomic操作，即便目标地址实际不同，但由于其后12 bit相同，它们都被分配到同一个锁表表项争用同一把锁，在此产生争用冲突。由此才会出现随着步长增大，吞吐率下降的现象。文章在ConnectX-3、ConnectX-5、ConnectX-6 RNIC都发现了这一现象。</p><p>基于这个推测，要提高非争用下RDMA atomic操作的性能，就得尽可能避免在RNIC内的锁表冲突，也就是避免地址后12 bit相同。两种思路：</p><ul><li>类似于图4(b.Ⅱ)，在每一个锁前都添加一个8 bytes的填充。图4第二个实验验证了这种方法的有效性。<br /></li><li>类似于图4(b.Ⅲ)，将锁和数据分离，连续的锁的地址必然可以有效避免锁表冲突。</li></ul><h3 id="优化悲观锁">优化悲观锁</h3><p>有了前面一系列的发现与分析，我们可以开始优化悲观锁了。</p><figure><img src="fig5-exclusive_latch_optimizations.jpg" alt="" /><figcaption>图5 独占锁优化</figcaption></figure><p>图1所展示悲观锁机制中，所有的操作都是同步的。每个操作被调用后，都需要轮询CQ来等待操作完成。这当然是正确的，但同时也是低效而高延迟的。图5展示了对其的逐步优化：</p><ul><li><p><strong>Speculative Read（预测读）</strong>。预测读优化将不再等待CAS操作上锁返回，而是在通过CAS尝试上锁后离开进行Read操作，这样可以将Read的延迟隐藏。如果上锁成功，则进行后续的处理；如果上锁失败，则重复这个行为即可。在InfiniBand标准中，RDMA atomic保证在相同QP的后续RDMA操作前完成，因此这个优化不会带来错误。</p></li><li><p><strong>Write Combing（写合并）</strong>。类似的，写合并优化则是将Write操作与后续的CAS释放锁合并，以此来隐藏等待写操作完成造成的延迟。</p></li><li><p><strong>Asynchronous Unlatch（异步释放锁）</strong>。上一个优化中仍在有在等待释放锁的CAS，异步释放锁则在发出CAS后直接结束过程。但这也可能引发另一个问题：用于存放Write操作数据的缓冲区不能立刻被重用。因为在下一个操作进行时，上一操作的Write仍可能还没被完成，立刻重用缓冲区可能会导致数据被覆盖。一个典型的解决方法是，为每个QP配备多个写缓冲区，本次操作使用的写缓冲区等到下一个操作Read返回时才可重用。</p></li><li><p><strong>Write Unlatch（写释放锁）</strong>。由于单次RDMA Write是按地址顺序进行的，我们也可以将独占锁放置在数据的末尾，那么就可以直接通过Write释放锁了。但由于InfiniBand标准并不保证从不同的QP发出的RDMA操作相互之间的可见性和顺序保证，因此这个优化仅适用于通过RDMA CAS操作锁的情况，而不适用于RDMA FAA来操作锁的情况。具体的解释可以参考论文，这里不多赘述。</p></li></ul><h3 id="测试">测试</h3><p>针对上述的优化方式，文章进行了消融实验。实验中以<em>CAS-Read-Write-CAS</em>为一次写流程，<em>FAA-Read-FAA</em>为一次读流程。</p><figure><img src="fig6-latch_ablation_study_st.jpg" alt="" /><figcaption>图6 单线程锁优化消融实验</figcaption></figure><p>图6展示了单线程下各种优化对读写流程的影响。可以看得出来每个优化都是有效的。对写流程来说，异步释放锁带来了最大的性能提升，但写释放锁优化的作用微乎其微。对读流程来说，由于其操作数本身较少，因此初始性能较写流程更高，但随着优化增加，这个优势也逐渐消失。</p><figure><img src="fig7-latch_ablation_study_mt.jpg" alt="" /><figcaption>图7 多线程锁优化消融实验</figcaption></figure><p>图7则展示了多线程下各种优化对写流程的影响（其中<em>unsync</em>表示只有一个Read和一个Write，作为参考性能上界）。可以观察到，对于8 workers和32 workers的情况，当所有优化都用上后，其性能与<em>unsync</em>版本相当，这表示在这范围内优化带来了良好的扩展性。但是对于128 workers的情况，在使用上异步释放锁的优化后，性能反而下降了一大截。这可能是由于高并发的场景下，下一个写流程来的相当快，上一流程的异步释放锁还没结束，就开始了下一流程的获取锁。这意味着一个worker可能会获取两个锁。这就导致了频繁的冲突。</p><h2 id="乐观同步机制">乐观同步机制</h2><p>悲观同步机制在争用不强烈的情况下可以实现较高的扩展性。但在有些数据结构下，争用是不可避免的。比如B-树，它的根节点必然会被频繁地访问。即便大部分访问上的是读锁，但RDMA FAA的性能也会在这激烈的争用下大幅降低。在这种情况下，乐观同步机制是相当有必要的。</p><figure><img src="fig8-intuition_for_optimistic_synchronization.jpg" alt="" /><figcaption>图8 乐观同步机制的实现</figcaption></figure><h3 id="一个直觉上的乐观同步实现">一个直觉上的乐观同步实现</h3><p>要实现一个乐观同步机制，通常我们的第一反应是：<strong>读者乐观地直接读而后作验证，写者则需获取一个悲观锁避免写写冲突</strong>。读者必须在完成读之后进行检查，确保在读的过程中数据没有被修改。为了实现这种机制，其数据布局一般如图8(a.Ⅱ)所示，由一个独占锁、一个版本号和数据部分组成。读流程则如图8(b)所示，读者先通过一个RDMA Read读取整个数据，并检查独占锁是否已被获取。如果没有写者上独占锁，则发起第二次RDMA Read再一次获取版本号，并同第一次读到的版本号比对。若版本号一致，则成功读取。</p><h3 id="顺序性">顺序性</h3><p>前面谈到的方法看起来非常合理。但是，事实上这是<strong>错误的实现方式</strong>！</p><p>RDMA消息传递的数据传输顺序受到三方面的因素影响：（1）消息顺序；（2）单个消息内的数据包顺序；（3）DMA顺序。其中前两个顺序由InfiniBand和RoCE协议保证了其顺序性，但是最后的DMA顺序性并没有得到保证。也就是说，RDMA Read并不保证其地址顺序性（InfiniBand标准同样没给出承诺），RDMA操作在设计时并没有考虑对同一块内存的并发访问。此时，中间协议就显得尤为重要，例如PCIe。为了进一步理解RDMA Read的执行行为，是时候要理解<strong>PCIe协议</strong>和<strong>缓存一致性协议</strong>了。</p><figure><img src="fig9-hw_involved_in_rdma.jpg" alt="" /><figcaption>图9 RDMA的硬件栈</figcaption></figure><p>如图9所示，RDMA Read请求到达远端节点后，RNIC首先将请求发送给PCIe Controller，PCIe Controller从主机内存中获取请求的内存数据。接着数据就会通过PCIe传输给RNIC，并传回给请求者。RDMA请求会在过程中被转换为PCIe事务，由PCIe Root Complex处理。PCIe Root Complex对读请求的处理在cacheline的粒度上是一致的。一旦请求被发起，PCIe协议通过<em>completions</em>将数据传输到endpoint。</p><p>当读的数据超出给定值（64 Bytes），这个请求就会通过多个<em>completion</em>来完成。对这种情况，PCIe标准是这样描述的：</p><div class="note note-info">            <p>Memory Read Request serviced with multiple completions, the completions will be returned in address order.</p>          </div><p>这句描述只保证了<em>completion</em>的顺序，但并没有保证数据冲内存取回的顺序。并且事实上，PCI Express® Base Specification Revision 4.0里有作如下描述：</p><div class="note note-info">            <p>single Memory Read that requests multiple cachelines from host memory is permitted to fetch multiple cachelines concurrently</p>          </div><p>在这种读顺序性无法保证（幸运的是，PCIe标准保证了RDMA Write的地址顺序性）的情况下，前面所提出来的乐观同步实现就不能保证正确了。比如说，一个读者和写者同时访问了同一块数据：（1）读者先读了第二个cacheline；（2）写者修改数据；（3）写者释放锁并增加版本号；（4）读者读取第一个cacheline；（5）读者发起第二个RDMA Read再次获取版本号。在这种情况下，读者会认为数据没有被修改。由此便发生了错误。</p><h3 id="正确的乐观同步机制">正确的乐观同步机制</h3><p>有了上述分析，为了保证乐观同步机制的正确执行，我们必须依靠额外的机制。</p><figure><img src="fig10-correct_optimistic.jpg" alt="" /><figcaption>图10 乐观同步机制的正确实现</figcaption></figure><ul><li><p><strong>版本号（使用两次RDMA Read）</strong>。这个实现仍然沿用了图8(a.Ⅱ)的数据结构，但改变了读流程。如图10(a)，对版本号和数据的读取被拆分成了两次RDMA Read操作。第一次RDMA Read只读取独占锁和版本号，第二次RDMA Read才真正读取数据部分。顺序同步的两次RDMA Read成功避免了先前提到的PCIe乱序读取的问题，若第三次RDMA Read读取到的版本号同第一次读回的相同，则能保证在两次RDMA Read之间数据没有发生改变。但这种方法需要两次RDMA Read，性能低下。</p></li><li><p><strong>CRC校验和</strong>。这种实现依靠一个校验和来发现数据的不一致，其数据结构如图8(a.Ⅲ)所示。读流程中，通过一个RDMA Read读回整个数据并进行校验，如果有写者并发修改目标数据，那么校验就会失败。但是这种方式也有缺陷：（1）CRC校验和的计算开销比较大；（2）存在小概率的巧合，数据被修改但CRC校验仍然无误。</p></li><li><p><strong>FaRM cacheline版本</strong>。利用<a href="https://www.usenix.org/conference/nsdi14/technical-sessions/dragojevi%C4%87">FaRM</a>，我们可以进一步提升性能，对应的数据结构如图8(a.Ⅳ)所示。FaRM依靠缓存一致的DMA来检测单个RDMA是否一致，它在每个cacheline的开头都会存一个版本号。通过比较每个cacheline的版本号，我们就可以检查在读取过程中是否有并发修改进行。对于写者而言，它首先给数据项上锁，随后读取、修改、增加版本号，最后通过RDMA Write按地址顺序写回数据。</p></li></ul><h3 id="测试-1">测试</h3><figure><img src="fig11-optimistic_read_st.jpg" alt="" /><figcaption>图11 单线程下乐观读性能</figcaption></figure><p>首先来看单线程下各种乐观同步机制的读性能。图11展示了实验结果，其中“broken”代表的是只进行一次RDMA Read获取数据而不作任何校验的方式。</p><p>出乎意料的，尽管悲观机制需要进行三次消息传递（FAA-Read-FAA），而乐观机制仅需要两次（Read-Read），悲观同步机制比所有乐观读机制都要表现得更好。这可能是由于悲观机制可以充分利用异步释放锁的优化，而乐观机制则仍需要进行同步地校验数据一致。</p><p>然后是“broken”与正确的乐观读性能对比，从图11(b)可以更直观地观察它们之间的差距。FaRM方法下的乐观读性能是最接近“broken”的。但同时可以看出，CRC和FaRM方法都无法随着数据项的增大而保持其性能，因为随着数据项增大，CRC需要计算的字节数随着增大，FaRM需要校验的版本号数目也在增加，这带来额外的开销。而对于第一种版本号的方法，尽管需要进行三次RDMA Read，但其开销不会随着数据项增大而增大，在数据项较大的情况下它展现出了一定的优势。</p><figure><img src="fig12-read_only_write_only_optimistic_scalability.jpg" alt="" /><figcaption>图12 Read-only和Write-only下乐观机制的可扩展性</figcaption></figure><p>再来看看各种乐观机制的可扩展性。图12展示了在Read-only和Write-only下各种机制的峰值性能（数据项大小为256 Bytes）。</p><p>对于Read-only的情况，在Worker数量较少的情况下，悲观机制远远好于所有乐观机制，但随着Worker数目逐渐提升，乐观机制的峰值性能反超并领先了一大截。这其中的原因主要是随着Worker数提升，悲观机制的RDMA atomic操作冲突变得更频繁，造成了性能瓶颈。对于乐观机制，可以看到FaRM方法和CRC方法都十分接近“broken”，而版本号方法落后较为明显。</p><p>对于Write-only的情况，尽管读采用了乐观机制，写仍然要保持悲观。但由于此时读者的读流程都是乐观的，因此我们便可以采用RDMA Write而非RDMA CAS来释放锁（Write Unlatch优化）。可以看得出来，在这种情况下Write Unlatch优化表现出了极高的提升，大大提高了悲观写的可扩展性。</p><h2 id="结论">结论</h2><p>总的来说，这篇文章深度分析了现有基于RDMA one-sided操作的同步技术的一些设计误区，并且给出了正确的悲观和乐观同步机制的实现和优化，最后测试了各种实现的性能，总结出各自合适的使用场景。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RDMA</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读 | SingularFS：A Billion-Scale Distributed File System Using a Single Metadata Server</title>
    <link href="/2023/11/24/readpaper-SingularFS/"/>
    <url>/2023/11/24/readpaper-SingularFS/</url>
    
    <content type="html"><![CDATA[<p>这篇文章出自清华大学存储研究组（舒继武团队），探讨了可承载Billion级别分布式文件系统的元数据服务构建。文章发表在了ATC`23。</p><span id="more"></span><p><em>Paper Link</em>: <a href="https://www.usenix.org/conference/atc23/presentation/guo">https://www.usenix.org/conference/atc23/presentation/guo</a><br /><em>Open Source</em>: 未开源</p><p>文章的标题起得相当直白，利用单个元数据服务器支撑Billion级别的分布式文件系统。大规模的分布式文件系统（DFS）已经是现代数据中心最重要的基础设施之一，但想要用单个元数据服务支撑整个DFS还是相当困难的，现有的DFS都包含多个元数据服务器。而RDMA和持久性内存PM带来的硬件提升给了这个机会，无论是性能还是访问粒度上的提升都给元数据服务带来了很大的上升空间。</p><p>单单把硬件换了肯定是不够的，文章分析了现有的文件系统不足之处，得出了搭建高性能元数据服务的三个挑战：</p><figure><img src="fig1-existing_fs_analysis.jpg" alt="" /><figcaption>图1 现有文件系统性能分析</figcaption></figure><ul><li><p><strong>崩溃一致性的保障需要大量开销</strong>。现有文件系统一般使用写前日志（write-ahead-logging）或者日志型文件系统（log-structured-filesystem）来保证崩溃一致性。但它们各自也有缺点：写前日志方式需要两次写入数据，引入了写放大问题；日志型文件系统则是造成了繁重的垃圾回收任务。图1中，Ext4-DAX采用WAL方式保证崩溃一致性，InfiniFS和CephFS则依靠其底层存储的事务达成此目标，它们的吞吐率都比较低。NOVA采用了日志型文件系统，但在协调多节点并发更新时表现也不如人意。</p></li><li><p><strong>多节点对共享目录并发操作时的锁争用，导致极低的性能和并行度</strong>。在同一共享目录下并发的<em>create</em>和<em>delete</em>操作需要同时修改共同的父目录dentry和inode，这就带来了严重的锁争用，使得性能大幅度降低（图1 b）。</p></li><li><p><strong>当前文件系统没有充分利用NUMA架构</strong>。NUMA感知的设计对于元数据服务的存储和处理来说是非常重要的。一方面，过往的工作表明远程PM访问在带宽和小粒度吞吐率上有着明显的下降，因此是否充分利用NUMA的局部性对发挥PM的性能有莫大的影响。另一方面，现有的文件系统无法在保持NUMA局部性的同时扩展到多NUMA节点上，这是由于它们的粗粒度分区策略。</p></li></ul><h1 id="singularfs">SingularFS</h1><p>针对前面提到的三点挑战，文章提出了针对性设计，并依此实现了SingularFS。</p><h2 id="总览">总览</h2><figure><img src="fig2-architecture.jpg" alt="" /><figcaption>图2 SingualrFS架构</figcaption></figure><p>SingularFS由客户端库和服务端组成。服务端在PM中存储文件系统元信息，客户端通过用户态库提供的类POSIX接口进行访问。服务端和客户端都配备了RDMA网卡进行通信。</p><figure><img src="fig3-md_in_kvstore.jpg" alt="" /><figcaption>图3 KV存储中的元数据</figcaption></figure><p>SingularFS采用通用的KV存储作为其存储后端，要求该KV存储能够执行<strong>单点查询</strong>和<strong>前缀匹配（范围查询）</strong>，同时需要保证单目标操作的原子性。</p><p>SingularFS将目录的Inode分为两部分：（1）<strong>时间戳元数据（timestamp metadata）</strong>，包括<em>atime</em>、<em>ctime</em>、<em>mtime</em>，它们的Key为&lt;<em>inode ID</em>&gt;；（2）<strong>访问元数据（access metadata）</strong>，包括除时间戳元数据以外的信息，它们的Key为&lt;<em>parent inode ID/name</em>&gt;。对于文件的Inode信息，它们的Key也为&lt;<em>parent inode ID/name</em>&gt;。</p><p>SingularFS并不直接维护目录项dentry，dentry的维护更新是融合进入Inode KV对的维护更新的，借助底层KV存储的前缀匹配范围查询，可以很容易获取目录项信息。例如客户端发起一次<em>readdir</em>调用查询Inode ID为1的目录下的目录项，那么服务端只需要在KV存储中以<em>1/</em>为前缀进行范围查询，便能查找到该目录下所有的文件和子目录。</p><h2 id="无日志元数据操作log-free-metadata-operations">无日志元数据操作（Log-free Metadata Operations）</h2><figure><img src="fig4-metadata_classification.jpg" alt="" /><figcaption>图4 元数据操作分类</figcaption></figure><p>为了解决崩溃一致性保障带来的大量开销，SingularFS设计了无日志同时保证崩溃一致性的元数据操作。</p><p>SingualrFS首先将元数据操作涉及到的元数据个数，将它们分为了三类，如图4所示。<em>open</em>、<em>close</em>等操作仅涉及目标Inode的修改，它们为<strong>单点操作（Single-node）</strong>。<em>mkdir</em>、<em>rmdir</em>等创建和删除操作涉及到目标Inode和父目录Inode的修改，为<strong>两点操作（Double-node）</strong>。而<em>rename</em>操作较为特殊，它要同时修改旧Inode、新Inode和它们各自的父目录Inode，因此它单独成一类。它们保证崩溃一致性的方式各自不同。</p><ul><li><p><strong>单点操作</strong>。单点操作由于只修改一个KV对，因此其崩溃一致性可以直接由底层KV存储保证。</p></li><li><p><strong>两点操作</strong>。两点操作的崩溃一致性保证是SingularFS的设计重点，它通过下面所述的<strong>有序元数据更新实现</strong>。</p></li><li><p><strong>Rename</strong>。Rename的崩溃一致性仍然由写前日志保证，由于Rename在文件系统实际使用中占比较少，这不会带来太大的性能影响。</p></li></ul><h3 id="有序元数据更新ordered-metadata-update">有序元数据更新（Ordered Metadata Update）</h3><p>SingularFS为文件Inode和目录访问信息添加了两个信息：<strong><em>btime</em>（创建时间）</strong>和<strong><em>detime</em>（删除时间）</strong>。由于两点操作会创建或删除Inode，并修改其父目录的<em>ctime</em>，那么可以观察到：</p><p><em>有一个目录Inode <span class="math inline">\(d\)</span>，对其任意一个子Inode <span class="math inline">\(c\)</span>，都应有<span class="math inline">\(d.ctime \geq max(c.btime, c.dtime)\)</span>。</em></p><p>基于这个观察，SingualrFS有序更新元数据来保证两点操作的崩溃一致性。</p><figure><img src="fig5-crash_consistency_of_double_node.jpg" alt="" /><figcaption>图5 两点操作的崩溃一致性保证</figcaption></figure><p>对于<strong>Inode创建</strong>操作，如图5（a）所示，一共分为两个步骤。先创建目标Inode并将其设置其<em>btime</em>，随后再将其父目录Inode的<em>ctime</em>和<em>mtime</em>设置为相同的值。若在这两步之间系统发生了崩溃，重启后可以发现子Inode的<em>btime</em>大于父目录Inode的<em>ctime</em>和<em>mtime</em>，那么便可以完成修复。</p><p>对于<strong>Inode删除</strong>操作，如图5（b）所示，一共分为三个步骤。首先设置目标Inode的<em>dtime</em>使其失效，其次设置父目录Inode的<em>ctime</em>和<em>mtime</em>为相同的值，最后在KV存储中删除目标Inode的KV对。若系统在第一和第二步之间崩溃，依然可以通过比较父目录Inode和子Inode的这几个时间戳发现错误；若在第二和第三步之间发生崩溃，则可以通过检查子Inode的<em>dtime</em>是否已被设置以发现应当被删除的Inode，并删除相应的KV对。</p><h2 id="分层并发控制hierachical-concurrency-control">分层并发控制（Hierachical Concurrency Control）</h2><p>分层并发控制的设计是为了解决多节点对共享目录并发操作时的低性能和并行度的问题。当多节点并发地对同一个共享目录下进行两点操作，会产生对父目录的<strong>目录项</strong>和<strong>时间戳</strong>两方面的写冲突。由于在SingularFS中，目录项是跟随子Inode的KV数据对一同变化的，目录项的写冲突问题自然而然就消失了，只剩下对时间戳的写冲突需要解决。</p><p>文章观察到两点操作仅仅只需要修改父目录Inode的<em>ctime</em>和<em>mtime</em>，一共16B大小。因此利用16B原子CAS操作可以实现无锁更新，基于此SingularFS设计了分层并发控制。</p><p>SingularFS首先将元数据操作分为了三类：<br />- <strong><em>update</em></strong>：只更新目标Inode的<em>ctime</em>和<em>mtime</em>的操作。<br />- <strong><em>writer</em></strong>：更新目标Inode其它信息的操作。<br />- <strong><em>reader</em></strong>：不更新目标Inode的只读操作。<br />例如，<em>create</em>/<em>delete</em>操作既是目标节点的<em>writer</em>，又是其父目录的<em>updater</em>。</p><figure><img src="fig6-hierarchical_concurrency_control_algorithm.jpg" alt="" /><figcaption>图6 分层并发控制算法</figcaption></figure><p>SingularFS为每一个Inode都添加了一把读写锁，并基于上述分类，设计了如图6的并发控制算法。</p><ul><li><p><strong><em>write</em>与其它操作同步</strong>。<em>writer</em>操作时会直接获取读写锁的写锁，以保证操作期间的独占访问；而<em>updater</em>和<em>reader</em>则会在操作前获取读锁。</p></li><li><p><strong><em>updater</em>与<em>updater</em>同步</strong>。<em>updater</em>操作仅仅修改Inode中的<em>ctime</em>和<em>mtime</em>，将它们放置在连续地址上共16B大小，因此可以使用<span class="math inline">\(cmpxchg16b\)</span>做原子修改。具体而言，<em>updater</em>首先获取读锁，避免<em>writer</em>同时进行修改。接着，获取当前<em>ctime</em>和<em>mtime</em>的快照。若是当前快照的时间戳不小于传入的目标时间戳，那么说明已经有更近的操作完成了更新，可以直接结束；否则通过<span class="math inline">\(cmpxchg16b\)</span>尝试进行CAS原子修改，若是修改失败则重复这个过程。</p></li><li><p><strong><em>updater</em>与<em>reader</em>同步</strong>。可以观察到<em>ctime</em>的值是单调递增的，这具备了版本号的性质。基于此，SingularFS采用了OCC的机制达成<em>updater</em>和<em>reader</em>之间的同步。具体而言，在获取整个Inode数据的前后都获取一次<em>ctime</em>，并进行比较，只有当两个<em>ctime</em>值相等才视为成功读取。</p></li></ul><h2 id="混合inode分区hybrid-inode-partition">混合Inode分区（Hybrid Inode Partition）</h2><p>为了实现对NUMA架构的充分利用，SingularFS设计了混合Inode分区。</p><h3 id="numa间inode分区">NUMA间Inode分区</h3><p>文章观察到文件操作（file operation）占据所有元数据的大部分操作，因此SingularFS主要针对文件操作设计实现NUMA局部性。</p><p>对于单点操作，可以将每个元数据指定给特定的NUMA节点处理，以保持NUMA局部性。但是对于两点操作，例如<em>create</em>/<em>delete</em>，涉及到的两个Inode可能被分配到不同的NUMA节点，这就导致了需要跨NUMA处理。但是可以观察到，两点操作仅仅是修改了父目录Inode的<em>ctime</em>和<em>atime</em>，那么就有了解决方案。</p><p>正如最前面所介绍的，SingularFS将目录的Inode分为时间戳元数据和访问元数据两部分，分成两个KV数据对存储。那么，将<strong>父目录时间戳元数据、子目录访问元数据和子文件元数据</strong>共同分在一组，分配给一个NUMA节点进行处理，那么便可以保证两点操作的NUMA局部性。SingularFS将各个元数据按照上述方式分为多个组，使用一致性哈希的方式将各个组分配给NUMA节点，实现了操作的NUMA局部性。（笔者愚见：按照这种方式，如果某个目录下文件和子目录数量极多，反而造成NUMA节点负载不均衡，导致性能下降的风险。）</p><p>但是由于目录元数据被分成两部分存储，对某些需要同时访问修改目录时间戳元数据和目录访问元数据的操作而言，又会引入如何保证崩溃一致性的问题。对此，SingularFS通过确定的操作顺序达成目的：</p><ul><li><p><strong><em>mkdir</em>/<em>rmdir</em>操作</strong>。这两个操作涉及到三个KV数据对：目标目录访问元数据、目标目录时间戳元数据、父目录时间戳元数据。SingularFS保证先创建/修改目标目录访问元数据（注意<em>btime</em>和<em>dtime</em>包含在这里面），这样当崩溃发生时，系统重启后可以轻松根据访问元数据的信息进行恢复。</p></li><li><p><strong>目录的<em>set_permission</em>操作</strong>。这个操作涉及到两个KV数据对：目录的访问元数据和时间戳元数据。为了保证崩溃一致性，SingularFS扩展<em>btime</em>的含义至<strong>创建时间和最近<em>set_permission</em>时间的最大值</strong>。当执行<em>set_permission</em>，SingularFS首先修改访问元数据KV数据对（包括权限和<em>btime</em>），再修改时间戳元数据的<em>ctime</em>。当崩溃发生，系统重启后也可以根据<em>btime</em>和<em>ctime</em>的比较判断进行恢复。</p></li></ul><h3 id="numa内inode分区">NUMA内Inode分区</h3><p>这部分算是对前面设计的一点小优化。</p><p>前面提到，SingularFS并不直接维护目录项，而是通过底层KV存储的范围查找实现对目录项的查询，这就要求了底层KV存储是有序存储的。但是现有的基于B+树的KV存储往往有比较严重的锁争用问题，尤其是在范围查询的遍历过程和更新时的节点分裂过程。那为了尽可能缓解锁争用的问题，SingularFS在每个NUMA节点内创建了多个索引（多颗B+树），将每个元数据通过哈希算法分配到特定的一个索引去存储。这样，当进行单点查询，只需要在目标特定的那个索引上上锁；当进行范围查询，则需要对每个索引都进行查询，而后合并查询结果。</p><p>（笔者愚见：这个优化能起到多大作用得打个问号。）</p><p>另一个是对<em>rmdir</em>的优化。<em>rmdir</em>操作需要确定目标目录是否为空，对于SingularFS来说就是需要进行一次范围查询，这个开销比较大。文章通过给目录元数据添加一个表示子节点数量的<em>num_dents</em>变量来优化这个过程。这个变量的崩溃一致性也是比较好保证的，系统重启时进行一次范围查询便可以对这个值进行校正。同时，为了保证这个变量的并发安全，对它的修改都是采取了原子增减的方式。</p><h1 id="实验">实验</h1><p>老样子，直接看论文吧😋。</p><h1 id="总结">总结</h1><p>这篇文章提出了一个新的元数据服务SingularFS，以KV存储作为底层存储而实现。它以较低的开销实现了的崩溃一致性，并且通过分层控制方式降低了对共享目录的锁争用，提高了并发度。此外还针对NUMA架构做了设计，通过NUMA间和NUMA内的分组充分利用了NUMA架构，进一步提高性能。</p><p>不过这篇文章其实并没有给我一种耳目一新的感受。SingularFS的大部分性能保证和机制实现是依赖于其底层的KV存储的实现方式，这篇文章更多是描述零散细节的修修补补。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文件系统</tag>
      
      <tag>论文阅读</tag>
      
      <tag>元数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读 | SMART：A High-Performance Adaptive Radix Tree for Disaggregated Memory</title>
    <link href="/2023/09/23/readpaper-SMART/"/>
    <url>/2023/09/23/readpaper-SMART/</url>
    
    <content type="html"><![CDATA[<p>文章提出了一个适用于分离式内存架构的基数树。主要工作由复旦大学和华为云完成，发表于OSDI'23。</p><span id="more"></span><p><em>Paper Link</em>: <a href="https://www.usenix.org/conference/osdi23/presentation/luo">https://www.usenix.org/conference/osdi23/presentation/luo</a><br /><em>Open Source</em>: <a href="https://github.com/dmemsys/SMART">https://github.com/dmemsys/SMART</a></p><p>分离式内存（Disaggregated Memory，DM）最近几年发展得如火如荼，先前已经有不少研究探讨DM上的索引结构了。B+树作为使用最广的索引结构，自然已经有人研究过怎么将它适配于DM，比如说<a href="https://dl.acm.org/doi/abs/10.1145/3514221.3517824">Sherman</a>。</p><p>但是B+树也有它的问题：<strong>读写放大</strong>。这一点主要体现在对叶子节点的读写上，B+树的每个叶子节点保存了多个Key-Value（KV）对，运行在计算节点上的进程要搜索某一个Key时，得把整个叶子节点都读回来。假设一个叶子节点包含了32个KV对，那就有32倍的读放大。写放大也是一样的道理。尽管Sherman对B+树的写做了优化，解决了写放大问题，但读放大问题依然存在。读写放大问题在DM架构上的影响还是非常明显的，毕竟浪费的是网络带宽。文章就做了些实验比较Sherman和<a href="https://ieeexplore.ieee.org/document/6544812">ART</a>（SOTA基数树），总结了两个结论：</p><figure><img src="fig1-read_performances_of_Sherman_and_ART.jpg" alt="" /><figcaption>图1 Sherman和ART在YCSB</figcaption></figure><ul><li><p><strong>B+树的吞吐量受到了带宽的限制</strong>。这一点可以很容易从图1的(a)和(b)看出来，随着客户端数量上升，Sherman的吞吐量首先达到上限，ART的吞吐量上限是Sherman的两倍还多。而且单个叶子节点存放的KV对越多，Sherman的吞吐量越低。可能大伙觉得，多读回来的数据可以作为缓存啊，这不就把读放大问题完美解决。但是实验(c)显示，即使给到了600MB的缓存，吞吐量依然受限于网络带宽无法继续提升（文章没有做解释）。相反，ART的吞吐上限受制于RNIC的IOPS，比Sherman好很多。</p></li><li><p><strong>网络拥塞的提前发生加剧了B+树的延迟</strong>。在相同吞吐量下，由于读写放大，Sherman占用的网络带宽比ART高得多，这导致了网络拥塞提前发生。一旦网络拥塞发生，延迟就开始提高了。从实验(d)可以看出来，Sherman的P99延迟增长速度是相当快。</p></li></ul><p>基于这两个观察，文章就得出一个结论：<strong>比起B+树，基数树更适合用于DM架构</strong>。当然ART也不是完美的，要想将ART适配于DM架构，仍然有三个问题需要解决：</p><ul><li><p><strong>有锁并发控制导致写性能低下</strong>。现有的ART都使用了有锁并发控制来实现同步。但是在DM架构上，锁操作开销是很大的，每一次锁操作都是一次网络往返（RDMA_CAS）。而且，忙等待之类的锁冲突机制还会在上锁失败时不断重试，进一步加剧RNIC的IOPS浪费。一个可能的解决方案是设计无锁算法。但是无锁算法依赖于out-of-place的更新模式（只更新8字节地址保证更新的原子性）。但是这种更新模式又会导致计算节点本地缓存的频繁失效，造成缓存抖动问题。</p></li><li><p><strong>同节点客户端的重复I/O浪费RNIC的IOPS</strong>。前面有提到，ART能够突破B+树受到的带宽限制，但依然受限于RNIC的IOPS。IOPS吃紧的情况下，还是有浪费的情况。比如说，位于同一个计算节点的多个客户端，要读内存池的同一个KV对，每个客户端都会发起一个网络I/O，这种不必要的重复I/O就是对IOPS的严重浪费了。写也是同理。</p></li><li><p><strong>ART的结构特征加剧了计算端缓存失效问题</strong>。路径压缩和适应性节点（根据需要修改节点内指针数组长度）是ART降低内存开销重要的结构特征。但这就会引入ART内部节点父子关系的变化或节点类型变化等等问题，进而引入计算端缓存失效的可能性。如果没有合适的判别机制，可能会导致错误的数据访问。</p></li></ul><p>本文就针对前面提出的三点挑战，进行了针对性设计，提出了SMART，一个面向DM架构的高性能ART。</p><h1 id="smart">SMART</h1><p>SMART针对三点挑战，分别提出了三个设计来解决问题。</p><h2 id="层次化的art并发控制">层次化的ART并发控制</h2><figure><img src="fig2-data_structure_of_smart.JPG" alt="" /><figcaption>图2 SMART的内部节点和叶子节点</figcaption></figure><p>SMART的节点被分为<strong>内部节点（Internal Node）</strong>和<strong>叶子节点（Leaf Node）</strong>两种。所谓层次化的并发控制，意思就是内部节点采用无锁并发，而叶子节点采用有锁并发。</p><p>内部节点主要由三个部分组成。第一部分是Reverse Pointer，这里存储指向父节点的指针；第二部分是Header，存放了当前节点深度Depth、节点类型Type<sub>node</sub>（NODE_4/NODE_16/NODE_64/NODE_256）、压缩的Partial Key数组和当前数组大小Size<sub>array</sub>；第三部分就是Slot数组，保存了子节点的信息，每个Slot由对应Partial Key、是否为叶子节点的标记位Leaf、子节点类型Type<sub>node</sub>（若为内部节点）或子节点长度（若为叶子节点），以及48位地址组成。</p><p>叶子节点也由若干部分构成，包括指向父节点的Reverse Pointer，用于标记KV是否被删除的有效位Valid，校验和Checksum，固定长度的KV对，以及在尾部的锁Lock。</p><p>发现了么？SMART把内部节点的每一部分都设计为了8字节大小，这样就可以直接使用RDMA CAS操作直接原子地进行修改了，不用上锁。而对于叶子节点，仍然采用了锁机制。写者之间会直接用互斥锁进行同步，在写之前进行上锁；读者则采用乐观策略，将节点内容读回后通过校验和检查内容是否一致，不一致则重新读。此外，可以看到SMART将锁放置在了叶子节点的尾部，这样客户端就可以在写回数据的时候顺便释放锁了，因为RDMA保证了写的顺序性，释放锁时前面的数据一定已经完成修改了。</p><p>为了更好地展示SMART的各种操作，文章用图展示了对一颗ART树进行一系列操作的变换过程：</p><figure><img src="fig3-operations.jpg" alt="" /><figcaption>图3 SMART的一系列操作变化过程</figcaption></figure><h2 id="读委托写合并">读委托写合并</h2><p>这个机制用于解决同一计算节点上不同客户端对相同Key重复读的I/O浪费问题。</p><figure><img src="fig4-read_delegation.jpg" alt="" /><figcaption>图4 读委托</figcaption></figure><p>SMART客户端在读时会对Key计算一个哈希值，并且在尝试在本地对这个哈希值上锁，成功上锁的客户端就会开始执行正常的RDMA读流程，并且进入一个读时间窗口（Time Window）。如果上锁失败，则说明这个哈希值已经被其它客户端上锁了，这时候就会去比较被上锁的Key（也就是正在执行读的Key）究竟是不是同一个Key。如果不是同一个Key，那客户端就会直接进入正常的读流程，从内存池读回目标KV对；如果是同一个Key，那客户端就不会去内存池读，而是进入一个等待队列。持有锁的客户端在读回目标KV后，会将它分享给等待队列中的每一个客户端，从而就可以通过一次网络I/O完成多个读操作。</p><figure><img src="fig5-write_combining.jpg" alt="" /><figcaption>图5 写合并</figcaption></figure><p>写合并也是差不多的思路。成功拿到锁的客户端会维护一个写缓存（WCB），在写窗口期间，其它客户端对同一个Key的写都会转变成对WCB的写。和读委托稍微不同的是，写时间窗口在持有锁的客户端给目标叶子节点上锁后就结束了。在成功对叶子节点上锁后，持有锁的客户端就会将WCB内的值写入内存池，从而完成写操作。如此一来，多个客户端对同一Key的写也由一次网络I/O完成。</p><p>但是简单将读委托和写合并一起实施，也会有问题。例如A发起对K的读，B对K先写后读。A先从内存池读到K的旧值，但数据仍然还在网络通路上。随后B将新值写入内存池，然后发起读加入等待队列。A读的数据返回计算节点，分享给B，此时从B的视角看就是写入的新值没能成功读回，<strong>因果一致性遭到破坏</strong>。所以，为了让避免这种情况发生，SMART设计了一种机制，简单地来说，当读写并发的时候，如果写比读先完成（网络先返回），那当读数据返回时，只有写完成之前发起请求的读者可以被共享数据，其余读者需要自行发起网络请求读取新数据。（这一部分论文没有交代清楚，强烈建议看代码是怎么实现的）。</p><h2 id="art缓存">ART缓存</h2><figure><img src="fig6-art_cache.jpg" alt="" /><figcaption>图6 计算节点的ART缓存</figcaption></figure><p>SMART客户端会在本地节点也维护一棵ART缓存树，它的结构如图6所示。缓存树的叶子节点就是缓存条目，缓存了内存池中某个内部节点的信息：深度Depth、节点地址Node Address、以及它的子节点信息Slot数组（这里的Slot和前面提到的内存池的Slot结构一致）。那要怎么判断缓存是否还有效呢？文章分了三大缓存失效场景类型来讨论：</p><ul><li><p><strong>父子节点关系的变化</strong>。这种缓存失效类型一般发生在节点分裂。验证方法是根据缓存条目的目标Slot读回目标节点数据，然后比较读回数据中的Reverse Pointer和缓存条目的Node Address是否相同，即可判断缓存是否失效。</p></li><li><p><strong>节点类型发生变化</strong>。验证方式是，根据缓存条目的目标Slot读回目标节点数据，查看读回数据中的Type<sub>node</sub>和缓存中的Type<sub>node</sub>是否相同，即可判断缓存是否失效。</p></li><li><p><strong>节点是否删除</strong>。对于内部节点，验证读回的数据中Type<sub>node</sub>是否为NODE_0，判断节点是否已删除；对于叶子节点，验证读回数据中的Valid位，以判断节点是否已删除。</p></li></ul><h1 id="实验">实验</h1><p>直接看论文吧。</p><h1 id="结论">结论</h1><p>文章针对DM架构上B+树读写放大严重的问题，设计了适用于DM架构的基数树SMART。其中精心设计了树的节点数据结构，使得内部节点可以利用RDMA CAS操作实现无锁并发控制。同时为了保留对叶子节点的in-place-update更新模式，对叶子节点的更新仍然采用有锁并发控制，但是将锁放置在节点最后，利用RDMA更新的顺序保证，优化网络I/O次数。</p><p>比较亮眼的是读委托写合并机制，这个实打实降低了对热点Key访问的网络I/O次数，最重要的是这个机制对上层是透明的，可以移植在其它场景下，优化网络I/O。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
      <tag>分离式内存</tag>
      
      <tag>基数树</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用brpc遇到的一些bug和解决方案</title>
    <link href="/2023/06/02/some-brpc-bugs-and-solutions/"/>
    <url>/2023/06/02/some-brpc-bugs-and-solutions/</url>
    
    <content type="html"><![CDATA[<p>这篇文章记录一下在使用<a href="https://github.com/apache/brpc/">brpc</a>的时候遇到的bug以及解决方案，长期更新。</p><span id="more"></span><h2 id="流式rpc遇到pure-virtual-method-called错误">流式RPC遇到"pure virtual method called"错误</h2><p><a href="https://brpc.apache.org/zh/docs/client/streaming-rpc/">流式RPC</a>的使用需要继承<code>brpc::StreamInputHandler</code>，并且实现它的三个纯虚函数，如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">StreamReciver</span> : <span class="hljs-keyword">public</span> brpc::StreamInputHandler &#123;<br><span class="hljs-keyword">public</span>:<br>  <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">on_received_messages</span><span class="hljs-params">(brpc::StreamId id, </span></span><br><span class="hljs-params"><span class="hljs-function">                           butil::IOBuf *<span class="hljs-type">const</span> messages[], </span></span><br><span class="hljs-params"><span class="hljs-function">                           <span class="hljs-type">size_t</span> size)</span> </span>&#123;<br>    <span class="hljs-comment">// 当接收到消息时，调用该方法处理消息</span><br>  &#125;<br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">on_idle_timeout</span><span class="hljs-params">(brpc::StreamId id)</span> </span>&#123;<br>    <span class="hljs-comment">// 当超时未接收到消息时，调用该方法处理</span><br>  &#125;<br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">on_closed</span><span class="hljs-params">(brpc::StreamId id)</span> </span>&#123;<br>    <span class="hljs-comment">// 关闭stream以后，调用该方法处理</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在有些应用场景中，<code>StreamReceiver</code>可能并不长，在完成一次流式传输以后就立刻析构了，代码结构类似于：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">/* 流式传输前 */</span><br><br>&#123;<br>  brpc::StreamId sd;<br>  brpc::StreamOptions stream_options;<br>  StreamReciver stream_recevier;      <span class="hljs-comment">// StreamReceiver实例化</span><br>  stream_options.handler = &amp;stream_recevier;<br>  <span class="hljs-keyword">if</span>(brpc::<span class="hljs-built_in">StreamCreate</span>(&amp;sd, cntl, &amp;stream_options) != <span class="hljs-number">0</span>) &#123; <br>    ... ... <span class="hljs-comment">// 错误处理</span><br>  &#125;<br>  stub-&gt;<span class="hljs-built_in">StreamMethod</span>(&amp;cntl, &amp;request, &amp;response, <span class="hljs-literal">NULL</span>);<br>  <br>  ...... <span class="hljs-comment">// 数据传输</span><br><br>  brpc::<span class="hljs-built_in">StreamClose</span>(sd);  <span class="hljs-comment">// 传输结束，关闭stream</span><br>&#125;<br><br><span class="hljs-comment">/*流式传输后*/</span><br></code></pre></td></tr></table></figure><p>这样的代码结构里，<code>stream_recevier</code>的生命周期仅限于中括号内部，一旦运行退出中括号，它就被析构了。但是前面有说到<code>StreamReciver::on_closed</code>方法会在stream被关闭以后调用，而<code>brpc::StreamClose(sd)</code>不会等到<code>StreamReciver::on_close</code>被调用才返回。因此，有可能出现<code>stream_recevier</code>先被析构，而后<code>on_close</code>被调用的情况，此时虚函数表找到的就是<code>brpc::StreamInputHandler</code>这个基类的<code>on_close</code>了，是一个纯虚函数，从而引发了"pure virtual method called"的错误。</p><h3 id="解决方案">解决方案</h3><p>首先，理所当然的解决方案当然是避免这种代码结构，可以让<code>StreamReciver</code>作为brpc Service的成员变量，生命周期和服务一致。</p><p>但是，有时候不可避免地会出现这种代码结构，例如不同的情况下需要构造不同的<code>StreamReciver</code>，在准备建立stream时才构造，完成传输后立刻销毁。我对于这种情况的对策是给<code>StreamReciver</code>加一个<code>close_</code>的成员变量，并在<code>on_close</code>方法内将其置为<code>true</code>。关闭stream以后，轮询<code>close_</code>，判断<code>on_close</code>方法是否已经被调用，确认被调用后再退出。具体如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">StreamReciver</span> : <span class="hljs-keyword">public</span> brpc::StreamInputHandler &#123;<br><span class="hljs-keyword">public</span>:<br>  <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">on_received_messages</span><span class="hljs-params">(brpc::StreamId id, </span></span><br><span class="hljs-params"><span class="hljs-function">                           butil::IOBuf *<span class="hljs-type">const</span> messages[], </span></span><br><span class="hljs-params"><span class="hljs-function">                           <span class="hljs-type">size_t</span> size)</span> </span>&#123;&#125;<br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">on_idle_timeout</span><span class="hljs-params">(brpc::StreamId id)</span> </span>&#123;&#125;<br>  <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">on_closed</span><span class="hljs-params">(brpc::StreamId id)</span> </span>&#123; close_ = <span class="hljs-literal">true</span>; &#125;<br>  <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">is_close</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">return</span> close_; &#125;<br><br><span class="hljs-keyword">private</span>:<br>  <span class="hljs-type">bool</span> close_ = <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">/* 流式传输前 */</span><br><br>&#123;<br>  ...... <br>  brpc::<span class="hljs-built_in">StreamClose</span>(sd); <span class="hljs-comment">// 关闭stream</span><br>  <span class="hljs-keyword">while</span>(!stream_recevier) &#123;<br>    std::this_thread::<span class="hljs-built_in">sleep_for</span>(std::chrono::<span class="hljs-built_in">milliseconds</span>(<span class="hljs-number">100</span>));<br>  &#125;<br>&#125;<br><br><span class="hljs-comment">/*流式传输后*/</span><br></code></pre></td></tr></table></figure><p>这样就可以确保<code>on_close</code>方法在<code>stream_recevier</code>被析构前得到调用，避免纯虚函数调用错误。</p><h2 id="流式rpc遇到fail-to-parse-response-from-xxxxxxxx-by-streaming_rpc-at-client-side错误">流式RPC遇到"Fail to parse response from xxxx:xxxx by streaming_rpc at client-side"错误</h2><p>这个问题在brpc的<a href="https://github.com/apache/brpc/issues/392">issue#392</a>有被讨论到，具体原因不明，可能是普通RPC和流式RPC混用同一个连接导致的。</p><h3 id="解决方案-1">解决方案</h3><p>目前的解决方案是客户端创建<code>brpc::Channel</code>时，将<code>brpc::ChannelOptions</code>的<code>connection_type</code>设置为<code>"pooled"</code>，如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C++">brpc::Channel channel;<br>brpc::ChannelOptions options;<br>options.connection_type = <span class="hljs-string">&quot;pooled&quot;</span>;<br><span class="hljs-keyword">if</span>(channel.<span class="hljs-built_in">Init</span>(server_ep, &amp;options) != <span class="hljs-number">0</span>) &#123;<br>  <span class="hljs-comment">// 错误处理</span><br>&#125;<br></code></pre></td></tr></table></figure><p>按照这样修改代码后，暂时没遇到错误了，但是不确保是不是真的解决了问题。</p>]]></content>
    
    
    <categories>
      
      <category>杂货</category>
      
    </categories>
    
    
    <tags>
      
      <tag>brpc</tag>
      
      <tag>bug</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>单机部署K3s</title>
    <link href="/2023/05/07/single-node-k3s-install/"/>
    <url>/2023/05/07/single-node-k3s-install/</url>
    
    <content type="html"><![CDATA[<p>最近发现自己对同网段多主机的实验环境需求越来越高了，服务器嘛多了租不起，实验室主机嘛大家共用的不太放得开手脚，虚拟机嘛数量起来有点吃不消，那还是在自己的服务器上部署容器编排平台吧。</p><span id="more"></span><p>单节点没有过多的要求，而且租的服务器没有太多的资源（2核2G），所以就不选择用<a href="https://kubernetes.io/">K8s</a>了，<a href="https://k3s.io/">K3s</a>更轻量简单。</p><p>文章简单记录一下自己安装部署和配置的流程。</p><blockquote><p><strong>本次安装环境：</strong><br />* 腾讯云轻量级服务器2核+2G<br />* 操作系统Ubuntu Server 22.04 LTS 64bit, 内核Linux 5.15.0-56-generic<br />* 目标版本：1.25.9</p></blockquote><h2 id="docker">Docker</h2><p>K3s包含并且默认<a href="https://containerd.io/">containerd</a>作为容器运行时，但是就我的体验来说docker还是更好用一些，K3s也提供了使用Docker作为容器运行时的<a href="https://docs.k3s.io/zh/advanced#%E4%BD%BF%E7%94%A8-docker-%E4%BD%9C%E4%B8%BA%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6">安装方法</a>。所以在安装K3s前先安装一下Docker Engine，参考<a href="https://docs.docker.com/engine/install/">官方文档</a>。</p><h3 id="清理旧版本">清理旧版本</h3><p>安装Docker前先卸载清理一下旧版本。不管过去有没有安装过docker，先执行下面的步骤清理一下准没错。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 1. 删除Docker Engine，CLI，container以及Docker Compose Package</span><br>$ sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin docker-ce-rootless-extras<br><span class="hljs-comment"># 2. 删除所有镜像，容器和存储卷</span><br>$ sudo <span class="hljs-built_in">rm</span> -rf /var/lib/docker<br>$ sudo <span class="hljs-built_in">rm</span> -rf /var/lib/containerd<br></code></pre></td></tr></table></figure><h3 id="设置apt仓库">设置apt仓库</h3><p>在一台新机器上直接使用<code>apt</code>安装docker，一般是找不到的。在安装之前先设置一下apt仓库。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 1. 更新apt，安装一些包允许apt通过https使用库</span><br>$ sudo apt-get update<br>$ sudo apt-get install ca-certificates curl gnupg<br><br><span class="hljs-comment"># 2. 添加Docker官方GPG key</span><br>$ sudo install -m 0755 -d /etc/apt/keyrings<br>$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg<br>$ sudo <span class="hljs-built_in">chmod</span> a+r /etc/apt/keyrings/docker.gpg<br><br><span class="hljs-comment"># 3. 设置apt库</span><br>$ <span class="hljs-built_in">echo</span> \<br>  <span class="hljs-string">&quot;deb [arch=&quot;</span>$(dpkg --print-architecture)<span class="hljs-string">&quot; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \</span><br><span class="hljs-string">  &quot;</span>$(. /etc/os-release &amp;&amp; <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$VERSION_CODENAME</span>&quot;</span>)<span class="hljs-string">&quot; stable&quot;</span> | \<br>  sudo <span class="hljs-built_in">tee</span> /etc/apt/sources.list.d/docker.list &gt; /dev/null<br></code></pre></td></tr></table></figure><h3 id="安装docker-engine">安装Docker Engine</h3><p>完成上面的设置以后，就可以通过<code>apt</code>安装Docker Engine了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin<br></code></pre></td></tr></table></figure><h3 id="验证">验证</h3><p>完成安装了以后，可以验证一下Docker Engine确实成功安装了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ sudo docker run hello-world<br><br>latest: Pulling from library/hello-world<br>719385e32844: Pull complete<br>Digest: sha256:9eabfcf6034695c4f6208296be9090b0a3487e20fb6a5cb056525242621cf73d<br>Status: Downloaded newer image <span class="hljs-keyword">for</span> hello-world:latest<br><br>Hello from Docker!<br>This message shows that your installation appears to be working correctly.<br><br>To generate this message, Docker took the following steps:<br> 1. The Docker client contacted the Docker daemon.<br> 2. The Docker daemon pulled the <span class="hljs-string">&quot;hello-world&quot;</span> image from the Docker Hub.<br>    (amd64)<br> 3. The Docker daemon created a new container from that image <span class="hljs-built_in">which</span> runs the<br>    executable that produces the output you are currently reading.<br> 4. The Docker daemon streamed that output to the Docker client, <span class="hljs-built_in">which</span> sent it<br>    to your terminal.<br><br>To try something more ambitious, you can run an Ubuntu container with:<br> $ docker run -it ubuntu bash<br><br>Share images, automate workflows, and more with a free Docker ID:<br> https://hub.docker.com/<br><br>For more examples and ideas, visit:<br> https://docs.docker.com/get-started/<br><br></code></pre></td></tr></table></figure><p>出现上面的结果那就说明安装成功了，Docker拉取了hello-world的镜像并且拉起了一个容器。然后可以把容器和镜像给删了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ sudo docker ps -a             <span class="hljs-comment"># 找到hello-world容器的id</span><br>$ sudo docker <span class="hljs-built_in">rm</span> &#123;容器<span class="hljs-built_in">id</span>&#125;       <span class="hljs-comment"># 删除容器</span><br>$ sudo docker rmi hello-world   <span class="hljs-comment"># 删除镜像</span><br></code></pre></td></tr></table></figure><h2 id="k3s">K3s</h2><h3 id="安装">安装</h3><p>K3s的安装流程很简单，就一条命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ sudo curl -sfL https://get.k3s.io | sh -s - --docker    <span class="hljs-comment"># 这里的docker就是设置以Docker作为容器运行时</span><br></code></pre></td></tr></table></figure><p>国内因为网络原因，更推荐下面的命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ sudo curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -s - --docker<br></code></pre></td></tr></table></figure><h3 id="验证-1">验证</h3><p>等安装完成以后，小等一会儿，验证一下安装成功。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 1. 确认集群可用</span><br>$ sudo k3s kubectl get pods --all-namespaces<br>NAMESPACE     NAME                                     READY   STATUS      RESTARTS   AGE<br>kube-system   local-path-provisioner-6d59f47c7-lncxn   1/1     Running     0          51s<br>kube-system   metrics-server-7566d596c8-9tnck          1/1     Running     0          51s<br>kube-system   helm-install-traefik-mbkn9               0/1     Completed   1          51s<br>kube-system   coredns-8655855d6-rtbnb                  1/1     Running     0          51s<br>kube-system   svclb-traefik-jbmvl                      2/2     Running     0          43s<br>kube-system   traefik-758cd5fc85-2wz97                 1/1     Running     0          43s<br><br><span class="hljs-comment"># 2. 确认docker容器在运行</span><br>$ sudo docker ps<br>CONTAINER ID        IMAGE                     COMMAND                  CREATED              STATUS              PORTS               NAMES<br>3e4d34729602        897ce3c5fc8f              <span class="hljs-string">&quot;entry&quot;</span>                  About a minute ago   Up About a minute                       k8s_lb-port-443_svclb-traefik-jbmvl_kube-system_d46f10c6-073f-4c7e-8d7a-8e7ac18f9cb0_0<br>bffdc9d7a65f        rancher/klipper-lb        <span class="hljs-string">&quot;entry&quot;</span>                  About a minute ago   Up About a minute                       k8s_lb-port-80_svclb-traefik-jbmvl_kube-system_d46f10c6-073f-4c7e-8d7a-8e7ac18f9cb0_0<br>436b85c5e38d        rancher/library-traefik   <span class="hljs-string">&quot;/traefik --configfi…&quot;</span>   About a minute ago   Up About a minute                       k8s_traefik_traefik-758cd5fc85-2wz97_kube-system_07abe831-ffd6-4206-bfa1-7c9ca4fb39e7_0<br>de8fded06188        rancher/pause:3.1         <span class="hljs-string">&quot;/pause&quot;</span>                 About a minute ago   Up About a minute                       k8s_POD_svclb-traefik-jbmvl_kube-system_d46f10c6-073f-4c7e-8d7a-8e7ac18f9cb0_0<br>7c6a30aeeb2f        rancher/pause:3.1         <span class="hljs-string">&quot;/pause&quot;</span>                 About a minute ago   Up About a minute                       k8s_POD_traefik-758cd5fc85-2wz97_kube-system_07abe831-ffd6-4206-bfa1-7c9ca4fb39e7_0<br>ae6c58cab4a7        9d12f9848b99              <span class="hljs-string">&quot;local-path-provisio…&quot;</span>   About a minute ago   Up About a minute                       k8s_local-path-provisioner_local-path-provisioner-6d59f47c7-lncxn_kube-system_2dbd22bf-6ad9-4bea-a73d-620c90a6c1c1_0<br>be1450e1a11e        9dd718864ce6              <span class="hljs-string">&quot;/metrics-server&quot;</span>        About a minute ago   Up About a minute                       k8s_metrics-server_metrics-server-7566d596c8-9tnck_kube-system_031e74b5-e9ef-47ef-a88d-fbf3f726cbc6_0<br>4454d14e4d3f        c4d3d16fe508              <span class="hljs-string">&quot;/coredns -conf /etc…&quot;</span>   About a minute ago   Up About a minute                       k8s_coredns_coredns-8655855d6-rtbnb_kube-system_d05725df-4fb1-410a-8e82-2b1c8278a6a1_0<br>c3675b87f96c        rancher/pause:3.1         <span class="hljs-string">&quot;/pause&quot;</span>                 About a minute ago   Up About a minute                       k8s_POD_coredns-8655855d6-rtbnb_kube-system_d05725df-4fb1-410a-8e82-2b1c8278a6a1_0<br>4b1fddbe6ca6        rancher/pause:3.1         <span class="hljs-string">&quot;/pause&quot;</span>                 About a minute ago   Up About a minute                       k8s_POD_local-path-provisioner-6d59f47c7-lncxn_kube-system_2dbd22bf-6ad9-4bea-a73d-620c90a6c1c1_0<br>64d3517d4a95        rancher/pause:3.1         <span class="hljs-string">&quot;/pause&quot;</span><br><br><span class="hljs-comment"># 3. 可以确认一下运行时为docker，看最后一项CONTAINER-RUNTIME有docker字样</span><br>$ sudo k3s kubectl get nodes -o wide<br></code></pre></td></tr></table></figure><p>完成上面的基础验证以后，拉起一个nginx deployment确认可用。复制下面的内容，创建一个yaml配置文件<code>nginx-deployment.yml</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs bash">apiVersion: apps/v1<br>kind: Deployment<br>metadata:<br>  name: nginx-deployment<br>  labels:<br>    app: nginx<br>spec:<br>  replicas: 1<br>  selector:<br>    matchLabels:<br>      app: nginx<br>  template:<br>    metadata:<br>      labels:<br>        app: nginx<br>    spec:<br>      containers:<br>      - name: nginx<br>        image: nginx:1.7.9<br></code></pre></td></tr></table></figure><p>根据配置文件创建一个deployment，并且检查。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建deployment</span><br>$ sudo k3s kubectl apply -f nginx-deployment.yaml<br>deployment.apps/nginx-deployment created<br><br><span class="hljs-comment"># 查看deployment</span><br>$ sudo k3s kubectl get deployments<br>NAME               READY   UP-TO-DATE   AVAILABLE   AGE<br>nginx-deployment   1/1     1            1           51s<br><br><span class="hljs-comment"># 查看pod</span><br>$ sudo k3s kubectl get pods<br>NAME                                READY   STATUS    RESTARTS   AGE<br>nginx-deployment-699bfcdcb6-sr8km   1/1     Running   0          2m9s<br></code></pre></td></tr></table></figure><p>然后就可以删掉了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ sudo k3s kubectl delete deployment nginx-deployment   <span class="hljs-comment"># 删除deployment</span><br>deployment.apps <span class="hljs-string">&quot;nginx-deployment&quot;</span> deleted<br><br>$ sudo docker rmi nginx:1.7.9<br>Untagged: nginx:1.7.9<br>Untagged: nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451<br>Deleted: sha256:84581e99d807a703c9c03bd1a31cd9621815155ac72a7365fd02311264512656<br>Deleted: sha256:3b35ce69ff9691cd5c266a827dd889c05666135401756e559e8bbe1ac8e7dfdb<br>Deleted: sha256:62811140b8ff89fb0ce776cbcc7551b2d8f227065d2af585f1bad07fb07ee307<br>Deleted: sha256:5e76e0bf4a65fe60ef18c3987da04bb78e297ffd5da6302d6368050821673dab<br>Deleted: sha256:0df46e0bdc7aef79a9bb22a779e2cc2cc03132327e995fa1ce9d05ecb30707d9<br>Deleted: sha256:d9e4c3db5e337b04945ced14b6e4b19774425b6a705a9eabf8c5d92d37cb809e<br>Deleted: sha256:04fa8e2d74d03247eea2e02d13c962341c3832ad86d0e0504eaa9c92d79cf07c<br>Deleted: sha256:eaf3cdc8309a378b8fc3d8843c6b06048cf78219059ac9ee63633413c37347cb<br>Deleted: sha256:c1cba39a97737492375aa079d6a8ab5b66e6420a8a6be8b3ada5694fe59d090b<br>Deleted: sha256:25f33d51678a93ea9a1c83986cfe226739b4b4423fb0dfd7c0d9e71af6a2dc6b<br>Deleted: sha256:d4ce9897969d842636a8fc2bcb6affc61b6b187a53743f49ef2e365e6a6b5182<br>Deleted: sha256:7e4ec45a1110399ad13faabf18a0b00c461563da1d8598273b8c2def8a13daf0<br>Deleted: sha256:86a499023e872dce3634702c42802664f1e25011b8c48abfcdedf0f87ea33751<br>Deleted: sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef<br><br></code></pre></td></tr></table></figure><p>到此，以Docker为容器运行时的K3s就完成安装了。</p><h2 id="kuboard">Kuboard</h2><h3 id="运行kuboard服务">运行Kuboard服务</h3><p><a href="https://kuboard.cn/">Kuboard</a>是类似于DashBoard的K8s多集群管理界面，但是他比DashBoard好用多了，K3s也是能用的。具体部署流程参考<a href="https://kuboard.cn/install/v3/install-built-in.html#%E9%83%A8%E7%BD%B2%E8%AE%A1%E5%88%92">文档</a>。</p><p>虽然Kuboard可以运行在K8s或K3s集群内，但是为了结构清晰，还是根据官方的建议以独立运行在集群外的docker里了，创建一个脚本文件<code>kuboard-install.sh</code>，内容如下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ sudo docker run -d \<br>  --restart=unless-stopped \<br>  --name=kuboard \<br>  -p 10082:80/tcp \                           <span class="hljs-comment"># 我这里选择了映射到10082端口</span><br>  -p 10081:10081/tcp \<br>  -e KUBOARD_ENDPOINT=<span class="hljs-string">&quot;&#123;内网IP&#125;:80&quot;</span> \<br>  -e KUBOARD_AGENT_SERVER_TCP_PORT=<span class="hljs-string">&quot;10081&quot;</span> \<br>  -v /root/kuboard-data:/data \<br>  eipwork/kuboard:v3<br></code></pre></td></tr></table></figure><p>然后保存运行就可以了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ sudo <span class="hljs-built_in">chmod</span> +x ./kuboard-install.sh<br>$ sudo bash ./kuboard-install.sh<br></code></pre></td></tr></table></figure><h3 id="导入集群">导入集群</h3><p>等Kuboard容器运行起来了以后，就可以在浏览器通过<code>http://&#123;外网ip&#125;:10082</code>访问界面。</p><p><img src="Fig1.jpg" /></p><p>登录账号<code>admin</code>和密码<code>Kuboard123</code>。</p><p><img src="Fig2.jpg" /></p><p>点击添加集群，选择<code>.kubeconfig</code>方式连接。然后将<code>/etc/rancher/k3s/k3s.yaml</code>复制到配置文本框里。<strong>注意，内容里有一行<code>server: https://127.0.0.1:6443</code>，填到Kuboard以后确认前把<code>127.0.0.1</code>修改为你的内网地址</strong>。最后确认就完成集群导入了。</p><h2 id="dockerhub配置">DockerHub配置</h2><p>登录到自己在DockerHub的私有仓库。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ docker login -u 用户名 -p 密码<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>杂货</category>
      
    </categories>
    
    
    <tags>
      
      <tag>K8s</tag>
      
      <tag>K3s</tag>
      
      <tag>Docker</tag>
      
      <tag>容器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读 | Patronus：High-Performance and Protective Remote Memory</title>
    <link href="/2023/05/06/readpaper-Patronus/"/>
    <url>/2023/05/06/readpaper-Patronus/</url>
    
    <content type="html"><![CDATA[<p>这篇文章发表于FAST'23，是<a href="http://storage.cs.tsinghua.edu.cn/home-ch/">清华大学存储研究组</a>提出的工作。文章介绍了他们基于RDMA并通过软件协同设计实现的高性能且有保护的远程内存。</p><span id="more"></span><p><em>Paper Link</em>：<a href="https://www.usenix.org/conference/fast23/presentation/yan">https://www.usenix.org/conference/fast23/presentation/yan</a></p><h1 id="背景和动机">背景和动机</h1><p><strong>远程内存（Remote Memory, RM）架构</strong>是指将内存和CPU分离为两个独立的资源池（计算节点CN和内存节点MN）的架构，CN能够根据需要动态地从MN获得内存资源，这样的架构具有高内存利用率和高效内存共享的特点。得益于RDMA网络的广泛部署，它允许CN以one-side和低延迟的方式访问远程内存，目前许多数据中心都部署了RM架构。</p><p>但是实用的RM系统仍有一个需求未解决：<strong>远程内存保护（Remote Memory Protection）</strong>。不受保护的内存会面临非法访问的风险，可能导致数据损坏或泄漏。同时实现内存保护和高性能的RM系统是比较困难的，目前的RM系统都无保护地全部或以粗粒度暴露内存。</p><h1 id="设计目标">设计目标</h1><p>考虑到RM系统是作为基础设施建设的，它的性能决定了上层工作负载的性能上限。因此具备保护的RM系统的设计目标大体可以概括为以下三点：</p><p><strong><em>G#1</em></strong>：工作负载在峰值时会有大量的内存权限请求，因此系统必须要做到<strong>高性能低延迟</strong>，避免成为实际使用时的瓶颈。<br /><strong><em>G#2</em></strong>：客户端可能会在持有独占权限时发生故障，这会影响整个系统运行。因此，系统必须要能<strong>快速反应客户端故障</strong>。<br /><strong><em>G#3</em></strong>：非法访问会导致QP进入错误状态，而拒绝接收RDMA请求，无法继续工作。这种中断可能会给共享同一QP的其它客户端造成影响。因此，系统需要一种保证在<strong>非法访问发生下保持性能</strong>的机制。</p><h1 id="现存方案简述">现存方案简述</h1><figure><img src="Fig1-protection_releated_operations_latency.jpg" alt="" /><figcaption>Fig.1 RDMA各保护相关操作延迟</figcaption></figure><figure><img src="Table1-existing_solution.jpg" alt="" /><figcaption>Table1 现有保护比较</figcaption></figure><p>现有的RM系统保护方案大体可以分为如表格所示的几类：</p><ul><li><strong>Two-sided</strong>指的是在访问远程内存时完全使用RDMA的two-sided verbs，但这并不适用于RM架构，因为这需要超出内存节点所能提供的计算能力。<br /></li><li><strong>MR</strong>指的是完全使用RDMA的MR进行内存保护，具体而言是对每个权限请求都相应注册一块MR并公开给客户端。然而，MR相关操作开销巨大，延迟非常高（如Fig1），且会随着内存需求变大而提升，无法满足 <strong><em>G#1</em></strong> 。而且，MR也无法感知客户端故障和处理QP错误，因此也无法满足 <strong><em>G#2</em></strong> 和 <strong><em>G#3</em></strong> 。</li><li><strong>QP</strong>指的是基于QP进行内存保护，具体而言是通过设定QP到不同状态从而达到不同的权限限制。但是这样的方案只能达到以通道为粒度的内存保护，而无法做到字节粒度的保护，并且修改QP状态也需要极大开销（如Fig1），无法满足 <strong><em>G#1</em></strong> 。同样，这种方案也无法感知客户端故障和处理QP错误，因此也无法满足 <strong><em>G#2</em></strong> 和 <strong><em>G#3</em></strong> 。</li><li><strong>MW</strong>则提供了更快更灵活的bind操作，延迟极低且固定不变，满足了 <strong><em>G#1</em></strong> 。但它仍然无法满足 <strong><em>G#2</em></strong> 和 <strong><em>G#3</em></strong> ，因此需要软件协同设计满足这些机制。</li></ul><p>（如果对以上名词及其机制还没有足够了解，可以参考<a href="https://zhuanlan.zhihu.com/p/142175657">RDMA操作类型</a>、<a href="https://zhuanlan.zhihu.com/p/156975042">MR</a>、<a href="https://zhuanlan.zhihu.com/p/195757767">QP</a>、<a href="https://zhuanlan.zhihu.com/p/353590347">MW</a>）</p><h1 id="设计概览">设计概览</h1><p>文章提出了名为Patronus的高性能有保护的RM系统，设计思路可以概括如下：</p><ul><li>Patronus充分利用了RDMA的Memory Window（MW）机制减少OS内核和RNIC开销，而非直接使用开销极高的Memory Region（MR）机制，并协同软件设计进一步减少MW操作次数，以达成高性能的目标。</li><li>Patronus引入租约机制，用于快速反应客户端故障，避免故障客户端无法释放内存资源而阻塞系统。同时为了进一步节省内存池有限的计算资源，将租约信息在保证保护的前提下委托给客户端管理。</li><li>Patronus会让客户端和内存池准备额外的空闲QP，用于在QP进入错误状态时快速替换，从而隐藏中断，避免QP损坏带来的修复延迟。</li></ul><h1 id="系统设计">系统设计</h1><h2 id="接口">接口</h2><figure><img src="Table2-interface.jpg" alt="" /><figcaption>Table2 系统接口</figcaption></figure><p>Patronus系统的API如表2所示：</p><ul><li><strong>权限开始</strong> ：客户端获取内存权限可以分为两种情况。一种是通过 <em>allocate</em> 接口，分配一块新的内存；一种是通过 <em>acquire</em> 接口，尝试获取一块已知区域的内存访问权限。两个接口都会对MN发起RPC，MN相应绑定MW（bind）到分配好的或指定的内存区域上，随后返回权限凭证 <em>Perm</em> 给客户端。请求参数包括了访问模式（读/写）和所有权（共享/独占）以及期望时长。对于所有权冲突的请求，Patronus会延迟赋予权限。<br /></li><li><strong>权限延长</strong> ：客户端通过 <em>extend</em> 接口延长权限生命，在后文中会提到这是通过RDMA的one-sided verbs实现的。这样可以避免频繁重新获取同一区域的内存权限，提高效率。<br /></li><li><strong>权限结束</strong> ：权限会在租期到达的时候结束，也可以通过 <em>revoke</em> 接口显式地结束权限，这也是通过RPC实现的。无论是哪种情况，MN都会在结束权限时将对应的MW解绑（unbind）。<br /></li><li><strong>数据路径</strong> ：Patronus完全使用RDMA的one-sided verbs进行数据操作。</li></ul><h2 id="系统结构">系统结构</h2><figure><img src="Fig2-architecture.jpg" alt="" /><figcaption>Fig.2 系统结构</figcaption></figure><p>Patronus提供了一个CN上客户端使用的库和MN上运行的管理进程。在MN上，内存被分为了两部分：<strong>header</strong>池（≤0.02%）和<strong>buffer</strong>池。header是负载存放权限元数据的结构，buffer则是真正供客户端访问的内存。</p><figure><img src="Fig3-format_of_32B_header.jpg" alt="" /><figcaption>Fig.3 header格式</figcaption></figure><p>header的组成如Fig.3所示，它主要包括两方面信息：资源信息和租约信息。Patronus使用header的地址作为客户端访问MN上内存的凭证。</p><p>每当客户端调用接口获取权限时，管理进程会从header池里分配一个header，随后绑定<strong>两个</strong>MW到buffer和header上，绑定buffer自然是为了访问申请好的内存区域，绑定header则是为了后面会说到的CN协同租约延长。内存分配由不同object大小的slab分配器进行管理。为了检测快过期的权限，管理进程会定期轮询，找到到期的权限，并进行解绑回收操作。</p><h2 id="cn协同租约延长">CN协同租约延长</h2><p>一个朴素的租约延长方式是客户端通过RPC通知MN上的管理进程延长租期。但是，这会造成巨大的开销，MN上的计算资源很少，无法支持这种方式。因此，Patronus采用的是CN协同的方式进行租约延长。具体而言就是为header的lifetime字段也绑定上一个MW，将其暴露给客户端，这样客户端就可以通过RDMA的one-sided verb去修改MN上保存的租期，不会造成极大开销。</p><p>但是这样做又可能引入饥饿问题：客户端可以将lifetime设置得极大或者连续修改租期，使其长久掌握对应内存区域的所有权，从而阻塞其它客户端的请求。因此，Patronus设定了两个规则防止这种情况发生：<br />1. lifetime不能超出一个预定义的最大值，当管理进程发现已经超时的权限时，会将其强制失效。<br />2. 把客户端修改lifetime的操作从RDMA_WRITE换成RDMA_CAS，管理进程可以通过将lifetime置0来告知客户端无法再延长租期。</p><h2 id="降低开销">降低开销</h2><p>虽然MW相关操作的开销相较于MR相关操作已经有了显著降低，但是仍然不够。为了应对峰值请求，需要软件协同设计进一步降低开销。</p><h3 id="利用成对的相反操作">利用成对的相反操作</h3><figure><img src="Fig4-handover.jpg" alt="" /><figcaption>Fig.4 MW handover技术</figcaption></figure><p>系统每时每刻都会有内存分配和回收，相应不断有MW的绑定和解绑操作进行。理想状态下，MW的绑定和解绑操作各占一半。遵循这一经验事实，Patronus会合并每一对绑定和解绑操作变成一个重绑定操作（rebind）。</p><p>这一技术不会引入额外的代价。第一，管理进程不会为了合并操作而刻意等待，不会因此造成延迟；第二，客户端的请求本身会由RNIC进行batch，硬件支持下不会引入额外的batch开销，更应说handover充分利用了RNIC的这一特性。</p><h3 id="延迟解绑">延迟解绑</h3><p>对于那些被解除分配的内存区域，如果它不被马上重新使用的话，那么可以延迟解绑相应的MW。这样可以降低被错误访问从而造成错误状态引入的概率。header就是延迟解绑很好的对象，一般来说header池里有足够多的空闲header，因此header的重新使用需求不高，对header的解绑可以延迟；而如果buffer池内仍然有足够多的空闲内存空间，那么buffer的解绑也可以延迟。</p><h3 id="充分利用连续性">充分利用连续性</h3><p>可以观察到，如果两块内存区域地址连续并且有着共享相同的租期，那么两个MW可以合并为一个。直观地说，这种情况发生的概率似乎非常小，但是可以人为构造出来。在处理 <em>allocate</em> 请求时，管理进程会将header和buffer一同分配，也就是在buffer前多分配32B放置header。文章对 <strong><em>Perm</em></strong> 的编码设计特意将lifetime字段放在了末尾，这样它和buffer构成了连续的内存空间，使用一个MW绑定即可。</p><h2 id="非法访问隔离">非法访问隔离</h2><p>虽然在MW的限制下，非法访问不会导致内存损坏，但是依然会不可避免得导致QP进入错误状态而无法工作，要修复QP需要通过Modify QP State的操作。但是从Fig.1中可以看到，这一操作的延迟相当高。因此，Patronus不选择修复QP，而是通过替换QP的方式隐藏错误。</p><p>Patronus准备了多个空闲的备用QP用于替换。每个客户端会被赋予一个虚拟的QPN，同时Patronus会维护一个虚拟QPN到真实QPN的映射表。当QP错误发生时，Patronus会透明地选择一个空闲QP替换，并且更改QPN映射表，由此使得错误被隐藏，系统可以继续运行。这种方式的实现得益于MW不需要和QP关联的特性，并且当QP没有被使用时，它不会占用RNIC的稀缺资源，备用QP仅需要一点点内存作为代价，这是值得的。</p><h2 id="其它实现细节">其它实现细节</h2><ul><li><p><strong>MW池</strong><br />尽管MW的绑定和解绑操作开销不高，但是它的创建仍然有较高的延迟（大约100微妙）。因此Patronus维护了一个MW池，避免该延迟出现在关键请求路径上。</p></li><li><p><strong>处理二次失效</strong><br />ABA问题可能会导致权限双重失效。具体而言，当过期的RPC尝试定位一个已经被重用的权限header时，就会出现ABA问题。为了解决这个问题，Patronus会在每个RPC内附加 <strong><em>Perm</em></strong> 的start time字段，管理进程会过滤掉所有start time不匹配的RPC。</p></li></ul><h1 id="用例和实验">用例和实验</h1><p>这个直接看论文吧。</p><h1 id="笔者的一些想法和疑问">笔者的一些想法和疑问</h1><ol type="1"><li><p>从<a href="#利用成对的相反操作">利用成对的相反操作</a>中用到了rebind操作和<a href="#非法访问隔离">非法访问隔离</a>的QP切换可以推测出来，文章使用的是Type 1的MW。Type 1 MW不需要和QP绑定，而是通过和PD关联，间接与QP关联。并且Type 1 MW支持直接换绑，绑定新的内存区域前不需要显示地解绑旧区域，换绑后旧的R_Key直接失效。此外，文中所说的<a href="#其它实现细节">MW池</a>的实现也得益于Type 1 MW支持零长度绑定。</p></li><li><p>内存区域的权限有最长租约的限制，这是否意味着这样的系统不适用于长期持续运行的进程使用，例如内存数据库？</p></li><li><p>合并成对bind和unbind的操作，以及延迟解绑，这两个优化是不是相互矛盾的存在？</p></li><li><p>为了实现内存连续将header和buffer合并，那么是不是就不存在header池了？</p></li></ol><p>总而言之，我个人认为这篇文章还是有很多没交代清楚的地方。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RDMA</tag>
      
      <tag>论文阅读</tag>
      
      <tag>Remote Memory</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo博客重搭建</title>
    <link href="/2023/05/05/build-blog/"/>
    <url>/2023/05/05/build-blog/</url>
    
    <content type="html"><![CDATA[<p>换了个服务器，又要把博客环境重新安装一遍，但是基本忘了怎么做了。为了避免以后出现同一状况，把整个流程记录一下。</p><p class="note note-warning"><font face="Song">这不是从头开始搭建Hexo博客，只是把存在github的博客内容和配置在一台新的服务器上拉下来重新搭建环境</font></p><span id="more"></span><h2 id="node.js安装">Node.js安装</h2><h3 id="安装nvm">安装nvm</h3><p class="note note-warning"><font face="Song">安装之前先把原有的node删了</font></p><p>为了以后管理方便，我个人选择而且推荐先安装nvm用于node的版本管理。先去Github的<a href="https://github.com/nvm-sh/nvm">nvm仓库</a>上看看最新的release版本号，然后通过下面的命令得到安装脚本并且执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/(替换为release版本号)/install.sh | bash<br><span class="hljs-comment"># 比如说我目前就要执行的是</span><br>$ curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bash<br></code></pre></td></tr></table></figure><p>安装脚本会尝试自动把nvm配置添加到配置文件里，完成安装以后，重启终端或者执行命令重新加载配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">source</span> ~/.bashrc  <span class="hljs-comment"># 根据自己不同的sh来调整，bash的话就是~/.bashrc，一般都是这个</span><br></code></pre></td></tr></table></figure><p>然后验证一下nvm安装是否成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ nvm -v<br>0.39.3  <span class="hljs-comment"># 有版本号输出就是成功</span><br></code></pre></td></tr></table></figure><h3 id="安装npm">安装npm</h3><p>在此之前建议给nvm换源，不然有可能因为网络原因进行不下去，在<code>~/.bashrc</code>文件尾部添加下面镜像配置语句</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node<br></code></pre></td></tr></table></figure><p>然后执行下面命令，看到有各种<code>vxx.xx.x</code>之类的版本号输出就可以了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ nvm ls-remote<br></code></pre></td></tr></table></figure><p>去<a href="https://hexo.io/zh-cn/docs/index.html">Hexo文档</a>查看目前hexo需要的Node.js版本支持，相应通过下面命令安装并切换使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ nvm install v18.16.0<br>$ nvm use v18.16.0<br>$ nvm list  <span class="hljs-comment"># 上面的安装成功提示其实很明显了，不过也可以通过下面两个命令来验证一下  </span><br>$ npm -v<br></code></pre></td></tr></table></figure><h2 id="安装环境">安装环境</h2><p>其实很简单，就一条命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ npm install --force<br></code></pre></td></tr></table></figure><p>它会根据记录过的配置，下载好对应的package。</p><p>因为要渲染数学公式，还要额外安装<a href="https://github.com/jgm/pandoc">pandoc</a></p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">$ sudo apt <span class="hljs-keyword">install</span> pandoc<br></code></pre></td></tr></table></figure><p>到这里就结束了，可以继续快乐写博客了。</p>]]></content>
    
    
    <categories>
      
      <category>杂货</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博客</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读 | Fisc：A Large-scale Cloud-native-oriented File System</title>
    <link href="/2023/03/15/readpaper-Fisc/"/>
    <url>/2023/03/15/readpaper-Fisc/</url>
    
    <content type="html"><![CDATA[<p>这篇文章发表于刚刚结束的FAST'23，是阿里云在本次会议中入选的4篇文章之一。文章介绍了他们面向云原生的大规模文件系统Fisc的实现，主要描述了客户端功能的硬件卸载和存储感知的分布式网关带来的性能提高，是一篇工程性较强的文章。</p><span id="more"></span><p><em>Paper Link</em>：<a href="https://www.usenix.org/conference/fast23/presentation/li-qiang-fisc">https://www.usenix.org/conference/fast23/presentation/li-qiang-fisc</a></p><h1 id="背景动机">1 背景&amp;动机</h1><p>当下云原生技术已经发展到了一个相对成熟的阶段，普遍的虚拟化方式已经从虚拟机变成了容器，提供给租户的抽象也从资源（CPU和内存）变成了服务（例如数据库和对象存储服务），大量数据分析、机器学习还有事务工作流等等之类的应用已经被部署在了公有云上。但是现有的分布式文件系统（DFS）并不适用于多租户云原生应用，主要的原因有两个：</p><figure><img src="Fig1-hdfs_client_consumption.jpg" alt="" /><figcaption>Fig1. HDFS客户端在不同带宽下的CPU消耗</figcaption></figure><ul><li><p>其一，<strong>传统DFS的客户端大多是重量级的</strong>，诸如存储协议、网络相关功能和安全相关功能都被放置在了客户端中，导致每个容器内的客户端都要保留许多独占资源，单台服务器只能同时承载少量容器。各个容器内的客户端对于资源的多路复用程度较低，导致资源使用效率低下。Fig.1展示了HDFS客户端在不同带宽下的CPU使用情况，可以看到在200MB/s带宽下的Write就大约消耗了1.1个CPU，考虑到一般模式下每个容器分配2个CPU，有超过50%的CPU资源用于I/O中。</p></li><li><p>其二，<strong>集中式网关无法满足云原生应用对性能、可用性和负载均衡的需求</strong>。主要限制有以下几点：（1）通过网关会有次优的毫秒级延迟；（2）网关无法感知文件语义和存储协议，从而无法进行数据的局部优化和快速故障处理；（3）在不对客户端进行侵入式更改的情况下，无法兼容RDMA等高性能网络堆栈；（4）由于基于网络连接数和基于文件数的负载均衡存在误差；（5）让集中式网关的吞吐量与数千节点的大型文件系统集群相匹配，这会导致高昂的成本。</p></li></ul><h1 id="fisc总览">2 Fisc总览</h1><h2 id="设计原理">2.1 设计原理</h2><p>Fisc的设计原理可以从三方面概况：</p><ol type="1"><li><p><strong>聚合FS客户端的资源</strong>。从本质上讲，资源聚合本身就是云原生的本质。不同于传统的资源密集型FS客户端，Fisc将存储协议和网络相关的功能卸载到物理域（与之对应的是客户端所处的虚拟域，也即容器）上，例如计算端和存储段的DPU，实现资源聚合和客户端的轻量化。</p></li><li><p><strong>分布式存储感知网关</strong>。Fisc使用了具备存储感知能力的分布式网关，以此建立了计算端和其对应存储节点的直连“高速路（highway）”。这使得虚拟域和物理域可以通过高性能网络协议进行连接，也可以充分利用存储语义以提高可用性和文件访问请求的局部性，同时保证了各个存储节点的负载均衡。</p></li><li><p><strong>软硬件协同设计</strong>。Fisc还将新兴的DPU部署在物理服务器上，通过精心的软硬件协同设计，实现从虚拟域用户容器到物理域FS的安全高效的透传。更进一步，Fisc还在DPU中引入高速通道（fast path）来加速I/O处理。</p></li></ol><h2 id="架构">2.2 架构</h2><figure><img src="Fig2-Fisc_architecture.jpg" alt="" /><figcaption>Fig2. Fisc架构</figcaption></figure><p>Fig.2展示了Fisc的整体架构。Fisc由<strong>控制层面</strong>（control plane）和<strong>数据层面</strong>（data plane）组成。</p><p>控制层面提供了开放的APIs给租户创建Fisc FS实例、挂载到虚拟机/容器，以及分配virtio设备加速虚拟域到物理域的透传。数据层面则由接口层、分布式存储感知网关（SaDGW）和持久化层构成。轻量级客户端放置在前端给应用提供FS服务接口；SaDGW在中间层，包含计算端DPU中的Fisc agent和存储节点中的Fisc proxy，以及存储集群中的一组Fisc proxy master。Fisc proxy master负责管理Fisc agent和Fisc proxy；Pangu则在后端作为持久化层，负载处理请求和持久化数据。（阿里云在FAST'23还发表了一篇详细介绍Pangu2.0的文章：<a href="https://www.usenix.org/conference/fast23/presentation/li-qiang-deployed"><strong><em>More Than Capacity: Performance-Oriented Evolution of Pangu in Alibaba</em></strong></a>）</p><h2 id="fisc工作流">2.3 Fisc工作流</h2><p>控制层面上，当租户调用API创建一个Fisc实例，Fisc控制层面会将实例映射到后端PanguFS，并把租户信息和挂载点推送给Fisc proxy masters。当租户将挂载点附给虚拟机/容器时，Fisc proxy masters会将挂载点和Fisc proxy的映射推送给其所处物理机的Fisc agent。最后，控制层会将一个virtio-Fisc设备分配给虚拟机/容器。</p><p>数据层面上，给定一个元数据操作请求，它通过virtio-Fisc设备到达Fisc agent。Fisc agent根据挂载点和Fisc proxy的映射，随机选择一个Fisc proxy。如果是一个文件的打开操作，则将使用其file handle和Fisc proxy位置来构造与打开文件相关联的路由条目。之后，后续对该文件的读写请求将根据路由条目进行路由。</p><h1 id="设计与实现">3 设计与实现</h1><p>本节将详细描述Fisc各部分机制的设计与实现。</p><h2 id="轻量级fisc客户端">3.1 轻量级Fisc客户端</h2><h3 id="功能卸载与资源聚合">功能卸载与资源聚合</h3><p>典型的重量级FS客户端提供有四类功能：（1）文件接口和相关数据结构；（2）存储协议，例如副本可靠性、数据一致性和故障处理；（3）安全和授权；（4）网络协议。文章发现，在云原生场景下，用户往往只关心第（1）类功能，其余的功能对用户来说是透明的。因此，将其余三类功能从客户端内移出并聚合，卸载到硬件上，可以实现很大程度的资源聚合。</p><ul><li><p><strong>将网络相关功能卸载到Fisc agent</strong><br />考虑到在近期，基于DPU的高性能网络栈（Luna/Solar和Nitro SRD）取得了极大成功，Fisc选择将网络相关的功能卸载到了物理域上的Fisc agent。具体而言，Fisc agent扩展了Luna/Solar网络栈，将同一台物理机上的客户端的网络连接聚合。这大大节省了每个客户端预留给网络相关操作的CPU和内存资源。</p></li><li><p><strong>将安全相关功能卸载到Fisc agent</strong><br />Fisc采用了早期检查（early-checking）的设计，当Fisc agent接收到来自Fisc client的检查时，就进行安全检查。不同于在网关上检查的方法，这种设计防止了恶意流量消耗后端存储集群的资源。</p></li><li><p><strong>将存储协议功能卸载到Fisc proxy</strong><br />Fisc将存储协议功能卸载到了位于存储集群的Fisc proxy上，而非Fisc client，主要有三点原因。第一，计算端DPU所持有的资源有限，在将资源花费在网络功能、安全功能和virtio-Fisc设备的裸机虚拟化以后，DPU没有足够的资源继续支持复杂的存储协议了。第二，将存储协议功能卸载到存储集群，有助于将计算端和存储集群之间的存储流量移动到存储集群内的后端网络，从而节省了计算-存储分离体系结构中的稀缺网络资源。第三，这样可以在存储集群中采用面向存储的优化和硬件辅助加速，以提高系统整体性能和降低成本。</p></li></ul><h3 id="简洁性和兼容性">简洁性和兼容性</h3><p>为了简化Fisc client的开发，Fisc使用了RPC的方式实现了Fisc的APIs。在此之上，Fisc引入类似Protocol Buffers的机制来保持Fisc client在不同版本之间的兼容性。但是直接使用PB（反）序列化会引入额外的开销，浪费DPU的有限资源。因此最终，Fisc将Fisc APIs分类成了数据相关（e.g., read, write）和元数据相关（e.g., create, delete, open, close）两类。数据相关的APIs使用更为频繁，因此为它们精心设计了多个数据结构保持兼容性。而对于元数据相关的APIs，则直接使用PB进行（反）序列化。由此，Fisc在性能和兼容性上达成平衡。</p><h2 id="分布式存储感知网关sadgw">3.2 分布式存储感知网关（SaDGW）</h2><p>Fisc使用了SaDGW用于建立Fisc agent和Fisc proxy之间的直接连接。因此，Fisc得以在这些连接中使用高性能网络栈，并更进一步地利用存储语义建立文件粒度地存储感知路由。</p><h3 id="agents和proxies之间的直接高速通路">Agents和Proxies之间的直接高速通路</h3><figure><img src="Fig3-routing_process_of_Fisc.jpg" alt="" /><figcaption>Fig3. Fisc的路由过程</figcaption></figure><p>在DPU的支持下，Fisc得以建立Fisc agents和Fisc proxies之间的直接高速通路，而不再需要网络网关。在高速通路上，Fisc运用了高性能网络栈Luna/Solar，而非TCP/IP网络栈。此外，Fisc还使用了原生数据结构（Raw data structures）来消除Fisc agents和Fisc proxies之间（反）序列化的开销。</p><p>更重要的是，SaDGW引入了<strong>文件粒度的路由表</strong>，通过一种中心控制的机制来管理高速通路。如Fig.3所示，Fisc agent维护了一张文件粒度的路由表（Route table），上面记录了文件handle信息以及对应服务该文件的Fisc proxy地址。当文件初次被打开时，Fisc agent接收到来自Fisc client的文件打开请求，随后随机选择一个Fisc proxy发送该请求。当文件成功被打开后，一条包含文件handle、所选Fisc proxy位置和SLA相关信息的路由条目（entry）将跟随请求响应返回。随后，当I/O请求到达Fisc agent时，它会根据路由表查找相应的Fisc proxy地址并将请求传输过去。由于DPU资源有限，路由表采用LRU实现以控制路由表大小。</p><h3 id="存储感知的故障处理">存储感知的故障处理</h3><p>对于存储协议的故障处理主要有三方面要考虑：</p><ul><li><strong>重试超时（retry timeout）</strong>：Fisc agent重试失败请求的最大次数，和用户设置的请求超时和高速通路质量有关<br /></li><li><strong>重试目的地（retry destination）</strong>：路由表记录指定的Fisc proxy，一旦重试超时发生就会被新的proxy替换。<br /></li><li><strong>高速通路质量（highway quality）</strong>：Fisc proxy响应的平均延迟。</li></ul><p>因此，Fisc扩展了agent上的路由表，增加了三个表项：<strong>重试次数（retry times）、重试超时（retry timeout）、平均延迟（avg-latency）</strong>。以此实现存储感知的故障处理。</p><p>Fisc利用了多种机制来处理故障：</p><ul><li><strong>重试（retry）</strong>：当Fisc agent检测到一次失败的请求，它会重试多次直到获得成功的响应或是超过了用户设置的重试超时。通常用户会设置一个相对较大的请求超时，因此Fisc agent会按照经验初始化设置一个较小的请求超时来检测失败请求。当失败请求发生，agent会加倍请求超时并重试。这个机制可以处理暂时性的失败，例如网络抖动等等。<br /></li><li><strong>黑名单（Blacklist）</strong>：在检测到连续的请求失败或者请求某一个Fisc proxy有较大的平均延迟时，Fisc agent会将该proxy列入黑名单。一个后台线程会周期性地ping这些proxy，并将成功ping通的proxy移出黑名单。元数据操作请求在选择Fisc proxy时会排除黑名单中的proxy，数据操作请求则有下述重新打开机制。<br /></li><li><strong>重新打开（Reopen）</strong>：如果数据操作请求的目标proxy在黑名单内，Fisc agent会选择一个新的Fisc proxy来重新打开文件，并更新路由表记录。若不在黑名单内，对于失败的请求，Fisc agent会在保证仍有足够剩余时间的情况下重试请求。在余下的时间里，它会选择一个新的proxy重新打开文件，保证在规定时间内完成请求。</li></ul><h3 id="位置感知读取">位置感知读取</h3><p>当发起一个读取操作时，请求首先会被发送到Fisc proxy上，然后由它再发送到目标数据所在的Pangu块服务器（chunkserver）上。读响应则会携带数据，沿着相反路径发送回。这会造成读流量的放大，消耗额外带宽，将整个集群吞吐量减半。考虑到每个存储节点上都部署了一个Fisc proxy线程和一个Pangu chunkserver线程，Fisc设计了位置感知读取避免流量放大。</p><figure><img src="Fig4-design_of_locality-aware_read.jpg" alt="" /><figcaption>Fig4. 位置感知读取</figcaption></figure><p>Fisc在Fisc agent中维护了范围表（range table）。每当Fisc proxy响应Fisc agent的打开或者读取请求时，同时会返回最近可能会被读取的chunk信息（由Pangu的预测机制决定），每次预测的chunk被经验地设置为16。这些信息会被编码组织成范围-地址对（range-location pair），并插入范围表内。范围表的每一条记录对应一个文件，考虑到DPU有限的资源，每条记录最多维护64对范围-地址。对于64MB大小的chunk的情况下，范围表内每个文件的记录最多可以直接定位4GB的数据，这已经满足了绝大多数的文件。此外，每个文件对应范围表记录的索引作为一个只读hint存储在路由表记录内（后续详解）。</p><p>有了范围表的支持，当一个请求到达Fisc agent，它会查找文件的路由表记录并得到只读hint，进而查找相应范围表记录，得到匹配的范围-地址对。若成功命中，请求会被直接送往目标的存储结点。在某些情况下，读取请求的范围大于命中对的范围，考虑到DPU内有限的CPU资源，Fisc并不将请求划分，避免了分割、组合和针对性的故障处理等复杂操作。当Fisc proxy接受到读取请求，它将调用Pangu客户端完成操作。在此情况下，目标proxy和目标Pangu客户端处于同一个物理节点上，它们便可以使用共享内存完成通信，而非通过网络。这样，读取请求和响应只经过了一个网络，提高了这个存储集群的读吞吐量。</p><h2 id="dpu支持下的软硬件协同设计">3.3 DPU支持下的软硬件协同设计</h2><h3 id="基于dpu的virtio-fisc设备">基于DPU的Virtio-Fisc设备</h3><p>Virtio-Fisc设备是一个遵从virtio标准的PCIe设备，主要由两部分构成，前端位于虚拟机/容器，后端位于DPU内。Fisc client通过前端将请求放入virtio硬件队列（virtio hardware queue），随后运行在DPU处理器上的Fisc agent将请求从硬件队列取出并处理。Fisc agent将请求发送Fisc proxy，再将接收到的响应放入硬件队列中，由前端Fisc client所处理。Fisc使用了两代Virtio-Fisc设备：</p><ol type="1"><li><strong>基于virtio-block的Virtio-Fisc设备</strong>。该类型的virtio-Fisc设备兼容大多数主要的OS，不必修改就可以被多数虚拟机/容器所使用。前端与标准virtio-block设备相同，使用virtio-block接口，并且实现了一个轻量的通信库，为Fisc client提供了block的读写操作。然而后端有很大不同，硬件队列中的请求是由Fisc agent处理，而非传统的virtio-block软件。<br /></li><li><strong>定制化设计的Virtio-Fisc设备</strong>。Fisc设计引入了这种设备以消除virtio-block的限制。例如，virtio-block的队列在大多数OS中深度限制在了128，这对Fisc的非阻塞请求是不够的。这种virtio设备更像是一个NIC设备。Fisc更进一步地在RPC层级利用该设备，使得它更适用于如FaaS的云原生服务。它利用virtio队列为RPC请求传递命令并接收响应。</li></ol><h3 id="快速路径">快速路径</h3><figure><img src="Fig5-design_of_fast_path.jpg" alt="" /><figcaption>Fig5. 快速路径</figcaption></figure><p>Fisc在计算端DPU内的FPGA中维护了路由表的缓存，从而得到了处理文件请求的快速路径。如Fig.5所示，文件handle和网络连接之间的映射被缓存进了FPGA中。当请求携带着文件handle到达定制化virtio-Fisc设备的FPGA时，FPGA解析文件handle并查找缓存的路由表。若命中，该请求会被直接打包成网络包发往目标网络连接；否则，请求会被送入位于CPU内的Fisc agent进行处理。缓存的记录由Fisc agent控制和更新，以减轻FPGA缓存实现的复杂性。为了控制网络传输带宽，每个连接的传输窗口也由Fisc agent在缓存的记录中设置和更新。</p><h3 id="资源优化">资源优化</h3><p>为了尽可能节省DPU上的有限资源，Fisc分别对其CPU、内存和网络做出了优化。</p><ul><li><p><strong>CPU优化</strong><br />针对CPU的优化主要有两个方面：<strong>批操作（Batch operation）</strong>和<strong>手动PB（反）序列化</strong>。批操作指的是Fisc会将多个请求集中到一个请求当中，以共享Fisc client和Fisc agent之间的virtio协议处理。手动PB（反）序列化是指，Fisc针对特定数据类型使用了定制化的PB（反）序列换方法，这比PB编译器生成的方法更加高效。</p></li><li><p><strong>内存优化</strong><br />Fisc agent主要的内存消耗在于路由表和范围表，为了节省内存，Fisc压缩了表记录所需要的内存。对于存储节点小于一百万的集群，Fisc使用20bit来表示IP地址，而非32bit。</p><p>更进一步，Fisc把范围表传给并存储在Fisc client，而无需在DPU中存储大量的地址。这样，当Fisc client发起请求时，它可以感知到目标chunk的范围并找到相应地址，将其作为hint伴随请求一起发送。接着Fisc agent首先根据路由表检查文件handle和租户信息，对于通过检查的请求，再根据伴随的hint发送请求。考虑到安全性，范围表在传递给Fisc client时使用了一个索引进行编码，用户无法解析其含义。为了避免应用恶意修改hint，Fisc agent和Fisc proxy都会检查索引，如果检查未通过，Fisc agent会在一段时间内禁用该用户的局部读机制。</p></li><li><p><strong>网络优化</strong><br />Fisc仔细处理直接高速通路的连接数量。第一，Fisc使用了共享连接机制（shared-connection mechanism）来减少Fisc agent和Fisc proxy之间的连接数量。第二，Fisc定期解除空闲连接以回收网络资源。第三，相较于同地域的带宽，跨地域的Tbps级带宽显得较窄，因此Fisc agent只连接不同地域的部分Fisc proxy。</p></li></ul><h2 id="大规模部署">3.4 大规模部署</h2><h3 id="vrpc">vRPC</h3><figure><img src="Fig6-abstracted_vRPC.jpg" alt="" /><figcaption>Fig6. vRPC</figcaption></figure><p>如Fig.6所示，Fisc抽象了一个vRPC服务。vRPC和传统的RPC很类似，由Fisc client通过vRPC stub调用，并被Fisc proxy的vRPC server处理。它的具体实现细节对云原生应用开发者来说是透明的，但事实上与传统RPC有区别。首先，在高效的virtio设备的支持下，它提供了从虚拟域到物理域的安全透传。其次，它可以在Fisc agent内被重试，并使用高性能网络栈，这对Fisc client来说仍然是透明地。第三，它为服务提供了一个使用适配器的机会，该适配器可以被集成到Fisc agent中来提高服务可用性。</p><h3 id="负载均衡">负载均衡</h3><p>Fisc引入了两种机制来实现存储集群内上千Fisc proxy的负载均衡。</p><ul><li><strong>文件粒度的调度</strong>。传统的负载均衡依赖于基于网络连接的网关调度，侧重于对各proxy的网络连接数量的平衡。然而网络连接的数量与文件的数量之间存在差距，连接数平衡并不意味着每个proxy的文件数量是平衡的。因此，Fisc提出了文件粒度的调度实现负载均衡。Fisc agent根据文件名和其它信息的哈希值将每个文件随机转发到Fisc proxy，实现文件在Fisc proxy之间均匀分布。由于Pangu将文件chunks均匀地分布到数据服务器上，通过位置感知读取，使得Fisc proxy的读请求也均匀平衡。<br /></li><li><strong>中心控制的重调度</strong>。Fisc proxy master会定期收集每个proxy的负载情况，并调度转移部分文件，将它们从高负载的Fisc proxy转移到低负载之处。同时Fisc proxy master还会将负载信息推送给Fisc agent，Fisc agent会相应提高低负载proxy的哈希权重，降低高负载proxy的哈希权重。</li></ul><h3 id="端到端的qos">端到端的QoS</h3><p>Fisc支持在线实时应用和离线批处理应用的混合文件访问，分别被赋予高优先级和低优先级。</p><p>Virtio-Fisc设备、NIC以及网络都采用了基于硬件的QoS机制。Virtio-Fisc设备和NIC充分利用其高/低优先级队列。Fisc通过网络库在IP数据包头设置DSCP值以利用网络交换机的优先级队列。</p><p>Fisc client、Fisc agent和Fisc proxy则采用了基于软件的QoS机制，使用了混合线程模型，分别对高/低优先级请求使用独占线程。使用混合线程模型是为了避免队头阻塞（head-of-line blocking）问题，Fisc不对大请求进行划分，因此如果高/低优先级请求放入同一队列，可能会出现HOL阻塞问题。另一原因是，缺乏用于英特尔CPU的NIC缓存隔离能力。如果DPDK的轮询线程停止轮询网络包，NIC的缓冲区可能会被低优先级请求的网络包填满。因此，如果要在同一线程处理高/低优先级的网络包，NIC的低优先级队列需要保持轮询，否则会影响高优先级流量。然而，线程中对低优先级请求的不断轮询会导致难以保证高优先级请求的满足。</p><h1 id="结论">4 结论</h1><p>文章提出了一种面向云原生的大规模文件系统Fisc，采用两层聚合机制实现容器之间对文件客户端资源的多路复用，并采用存储感知的分布式网关提高I/O请求的性能、可用性和负载均衡。Fisc还采用了带有DPU的Virtio-Fisc设备，以实现用户的虚拟域到物理域的高性能安全透传。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文件系统</tag>
      
      <tag>论文阅读</tag>
      
      <tag>分布式系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>🎃 万圣节！</title>
    <link href="/2022/10/31/happy-halloween-2022/"/>
    <url>/2022/10/31/happy-halloween-2022/</url>
    
    <content type="html"><![CDATA[<p><img src="github-halloween.jpg" alt="一年一度的万圣节彩蛋" /><br /><strong>万圣节快乐 👻🍬！</strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>生活</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读 | KL算法：An Efficient Heuristic Procedure for Partitioning Graphs</title>
    <link href="/2022/10/31/readpaper-an-efficient-heuristic-procedure-for-partitioning-graphs/"/>
    <url>/2022/10/31/readpaper-an-efficient-heuristic-procedure-for-partitioning-graphs/</url>
    
    <content type="html"><![CDATA[<p>今天要读的论文是大名鼎鼎的图划分算法——KL算法的原文：<strong><em>An Efficient Heuristic Procedure for Partitioning Graphs</em></strong></p><span id="more"></span><p><em>Paper Link</em>：<a href="https://ieeexplore.ieee.org/abstract/document/6771089">https://ieeexplore.ieee.org/abstract/document/6771089</a></p><h1 id="引言">引言</h1><h2 id="问题是什么">问题是什么</h2><figure><img src="Fig1.jpg" alt="" /><figcaption>Fig1. 问题的定义</figcaption></figure><p>本文所提出的是一个图划分算法。给定一个图，它的边带有权重。将的节点划分为数个子集，每个子集内包含的节点的权重之和不超过给定的最大值，同时要求划分后各子集之间的边权重之和最小。<br />更具体的，从数学形式上给出定义：</p><figure><img src="Fig2.jpg" alt="" /><figcaption>Fig2. 数学形式定义</figcaption></figure><div class="note note-info">            <p>令<span class="math inline">\(G\)</span>为一个有<span class="math inline">\(n\)</span>个节点的图，其中第<span class="math inline">\(i\)</span>个节点的权重为<span class="math inline">\(w_i(w_i &gt; 0, i = 1, ... , n)\)</span>。令<span class="math inline">\(p\)</span>为一个正数，对于所有的<span class="math inline">\(i=1, ..., n\)</span>，有<span class="math inline">\(0 &lt; w_i \leq p\)</span>。令<span class="math inline">\(C = (c_{ij})\)</span>，其中<span class="math inline">\(i, j = 1, ..., n\)</span>，表示图<span class="math inline">\(G\)</span>的带权邻接矩阵。<br />令<span class="math inline">\(k\)</span>为一个正整数。一个对图<span class="math inline">\(G\)</span>的<span class="math inline">\(\pmb{k}\)</span><strong>路划分</strong>是<span class="math inline">\(G\)</span>的一组非空且两两不相交的子集<span class="math inline">\(v_1, ..., v_k\)</span>，且有<span class="math inline">\(\bigcup_{i=1}^{k}{v_i} = G\)</span>。一个可接受的划分需要所有子集内的节点权重之和小于<span class="math inline">\(p\)</span>，即： <span class="math display">\[\lvert{v_i}\rvert \leq p \]</span> 其中<span class="math inline">\(\lvert x \rvert\)</span>表示集合<span class="math inline">\(x\)</span>的大小，等于<span class="math inline">\(x\)</span>的所有元素大小的和。一个划分的<strong>成本（cost）</strong> 指的是<span class="math inline">\(c_{ij}\)</span>的和，其中<span class="math inline">\(i\)</span>和<span class="math inline">\(j\)</span>属于不同的子集。因此，成本是划分中所有外部成本的和，本文问题是要在满足上述要求的情况下，找到对图<span class="math inline">\(G\)</span>成本最低的最优划分方案。</p>          </div><p>这个问题在许多显示场景下都有体现，例如将众多电子元件布置在印刷电路卡上，每个卡能容纳的电子元件有限，且卡与卡之间的连接成本较卡内连接要高，要尽可能减少电路卡之间的连接。还有一个场景是程序的分页。</p><p>本文所要解决的问题就是找到<strong>一种能够满足条件且成本最小化的划分方法</strong>。事实上，这个问题等价于另外三个问题：（1）由于总的边权重的值不变，最小化外部成本相当于最大化内部成本；（2）通过改变<span class="math inline">\(c_{ij}\)</span>的符号，还可以实现最大化外部成本，同时也是最小化内部成本。</p><h2 id="问题的难点">问题的难点</h2><p>通常碰到这类问题，暴力穷举自然而然地就出现在我们的脑子里。但是考虑一个有<span class="math inline">\(n\)</span>个节点，且每个节点权重为1的图<span class="math inline">\(G\)</span>，将其划分为<span class="math inline">\(k\)</span>个集合，每个集合大小为<span class="math inline">\(p\)</span>（这里假设了<span class="math inline">\(kp=n\)</span>）。在这样简明的情况下，包含的情况数为： <span class="math display">\[\frac{1}{k!}\left(\begin{matrix} n \\ p \end{matrix}\right)\left(\begin{matrix} n-p \\ p \end{matrix}\right)...\left(\begin{matrix} 2p \\ p \end{matrix}\right)\left(\begin{matrix} p \\ p \end{matrix}\right)\]</span> 进行穷举的复杂度高的难以接受。</p><p>从形式上看，这个问题也可以作为整数线性规划问题来解决，但这需要大量的约束方程来表达分区的均匀性，难度非常高。</p><p>似乎任何一个寻找最优解的方法都需要大量的计算，那么放弃确切的最优解，转而以较小运算量得到一个良好解的启发式算法似乎是更好的选择。为这类问题开发启发式算法的首要目标是找到一个功能强大，而且速度快到足以能运用在实际场景下的过程。时间复杂度不仅要考虑限制在指数级下，最要好限制在平方量级之内。</p><h2 id="几个失败的尝试">几个失败的尝试</h2><ul><li><strong>随机算法</strong>：随机地生成解决方案，保留生成过程中的最好结果。时间复杂度<span class="math inline">\(O(n)\)</span>，相当快，但由于最优解和接近最优解的解决方案很少，随机到该解决方案的概率很低，常常不能令人满意。</li><li><strong>最大流最小割算法（Max Flow-Min Cut）</strong>：最大流最小割算法能够实现找到最小成本的无约束2路划分，但该算法没有限制结果子集的大小，而且难以扩展算法实现这一点。若要实现限制需要后处理，但若子集大小差异较大，则该算法不具备任何优点。</li><li><strong>聚类算法</strong>：基于给定的成本矩阵识别自然聚类（natural matrix），但该方法也无法限制结果子集的大小。</li><li><strong>λ-Opting</strong></li></ul><h1 id="路均匀划分">2路均匀划分</h1><p>最简单且最具代表性的划分问题莫过于<strong>2路均匀划分</strong>了，即将给定包含了<span class="math inline">\(2n\)</span>个节点的图划分为两个分别包含了<span class="math inline">\(n\)</span>个节点的子集，且使成本最小。解决这个问题将为更一般的图划分问题提供了基础。</p><h2 id="基本思路">基本思路</h2><p>给定图<span class="math inline">\(S\)</span>，假定<span class="math inline">\(A^{*}\)</span>和<span class="math inline">\(B^{*}\)</span>是最佳的2路划分。设<span class="math inline">\(A\)</span>和<span class="math inline">\(B\)</span>是一对任意的2路划分。那么很显然存在<span class="math inline">\(X\subset A\)</span>，<span class="math inline">\(Y\subset B\)</span>且<span class="math inline">\(\lvert{X}\rvert=\lvert{Y}\rvert\leq\frac{n}{2}\)</span>使得<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>交换后产生<span class="math inline">\(A^{*}\)</span>和<span class="math inline">\(B^{*}\)</span>。</p><figure><img src="Fig3.jpg" alt="" /><figcaption>Fig3. 得到最优解</figcaption></figure><p>因此，为了实现目标，我们可以从任意的2路均匀划分开始，依据当前状态通过一定的算法从<span class="math inline">\(A\)</span>，<span class="math inline">\(B\)</span>中选出<span class="math inline">\(X\)</span>，<span class="math inline">\(Y\)</span>并交换，以降低外部成本。迭代交换步骤直到不可再继续降低外部成本时，我们就得到了一个局部最优解。我们在后续会表明，这个局部最优解有很大概率是全局最优解。我们可以选取多个初始划分，重复多次上述过程，得到多个局部最优解以比较。</p><p>那么如何决定交换的集合<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>呢？我们先给出一些定义：<br /><div class="note note-info">            <ul><li>对于任意<span class="math inline">\({a}\in{A}\)</span>，其外部成本<span class="math inline">\({E_a}=\sum_{ y\in{B} }c_{ay}\)</span>，内部成本<span class="math inline">\({I_a}=\sum_{ x\in{A} }c_{ax}\)</span>。对任意<span class="math inline">\({b}\in{B}\)</span>，同理定义<span class="math inline">\({E_b}\)</span>和<span class="math inline">\({I_b}\)</span>。</li><li>对所有<span class="math inline">\({z}\in{S}\)</span>，有<span class="math inline">\(D_{z}=E_{z}-I{z}\)</span>，<span class="math inline">\(D_{z}\)</span>为该节点的外部成本与内部成本之差</li></ul>          </div></p><p>以上述定义为基础，我们能给出如下定理： <div class="note note-info">            <p><strong>定理1</strong>：对于任意的<span class="math inline">\({a}\in{A}\)</span>, <span class="math inline">\({b}\in{B}\)</span>。若<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>交换，那么总体的外部成本减少量为<span class="math inline">\(D_a+D_b-2c_{ab}\)</span>。</p><p><strong>证明</strong>：令<span class="math inline">\(T\)</span>为<span class="math inline">\(A\)</span>和<span class="math inline">\(B\)</span>之间除了<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>以外的的划分成本，则 <span class="math display">\[T=z+E_a+E_b-c_{ab}\]</span> 交换<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>，得到新的成本<span class="math inline">\(T&#39;\)</span>，则 <span class="math display">\[T&#39;=z+I_a+I_b+c_{ab}\]</span> 因此划分成本的减少量为 <span class="math display">\[T-T&#39;=D_a+D_b-2c_{ab}\]</span></p>          </div></p><p>定理1就可以成为我们选择<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>的依据。</p><h2 id="流程">流程</h2><p>本节阐述进行2路划分的算法流程：<br /><img src="Fig4.jpg" alt="Fig4. Phase 1 Optimal Partition" /><br /><div class="note note-info">            <ol type="1"><li>对<span class="math inline">\(S\)</span>内的每个节点计算其外部成本与内部成本之差，即<span class="math inline">\(D\)</span></li><li>选择<span class="math inline">\({a_i}\in{A}, {b_i}\in{B}\)</span>使得下式最大，则交换<span class="math inline">\({a_i}\)</span>和<span class="math inline">\({b_i}\)</span>可以获得最大的划分成本减少量。将选出的<span class="math inline">\({a_i}\)</span>和<span class="math inline">\({b_i}\)</span>称作<span class="math inline">\(a&#39;_{1}\)</span>和<span class="math inline">\(b&#39;_{1}\)</span>，并暂时搁置 <span class="math display">\[{g_1} = { D_{a_i} } + { D_{b_i} } - 2{ c_{ {a_i}{b_i} } }\]</span></li><li>对<span class="math inline">\(A-\{a_i\}\)</span>和<span class="math inline">\(B-\{b_i\}\)</span>的所有结点重新计算<span class="math inline">\(D\)</span>，计算式如下（这是假设了<span class="math inline">\(a_i\)</span>和<span class="math inline">\(b_i\)</span>已经作了交换，证明比较简单，不再说明，实在不清楚可以翻阅原文）： <span class="math display">\[D&#39;_x = D_x + 2c_{ x{a_i} } - 2c_{ x{b_i} } \quad \quad x \in A-\{a_i\}\]</span> <span class="math display">\[D&#39;_y = D_y + 2c_{ y{b_i} } - 2c_{ y{a_i} } \quad \quad x \in B-\{b_i\}\]</span></li><li>重复步骤2、3，继续挑选。要注意，每次选择出一对<span class="math inline">\(a&#39;\)</span>和<span class="math inline">\(b&#39;\)</span>，都需要将他们剔除，不再参与后续的选择。这样进行直到对整个<span class="math inline">\(S\)</span>内的所有节点都完成选择后，得到<span class="math inline">\(a&#39;_1\)</span>和<span class="math inline">\(b&#39;_1\)</span>、...、<span class="math inline">\(a&#39;_n\)</span>和<span class="math inline">\(b&#39;_n\)</span>的节点对，与之对应的有<span class="math inline">\(g_1\)</span>、...、<span class="math inline">\(g_n\)</span>。</li><li><span class="math inline">\(g_1\)</span>、...、<span class="math inline">\(g_n\)</span>不一定全都是正数，选择一个值<span class="math inline">\(k\)</span>，使得<span class="math inline">\(\sum_{i=1}^{k}{g_i} = G\)</span>最大。此时，若<span class="math inline">\(G&gt;0\)</span>，交换<span class="math inline">\(X = \{ a&#39;_1, ..., a&#39;_k\}\)</span>和<span class="math inline">\(Y = \{ b&#39;_1, ..., b&#39;_k \}\)</span>可以使划分成本减小<span class="math inline">\(G\)</span>。</li><li>此时得到一个新的划分，随后重新回到步骤1进行下一轮交换。重复这个过程直到<span class="math inline">\(G=0\)</span>，此时便得到了一个局部最优划分。</li></ol>          </div></p><p>上述算法流程可以从一个初始划分找到它的局部最优化分，我们称之为<strong>Phase 1 Optimal Partition</strong>。我们可以选择多从几个随机初始划分得到它们的Phase 1 Optimal Partition，或者进一步地优化Phase 1 Optimal Partition。</p><h2 id="方法的有效性">方法的有效性</h2><p>Phase 1 Optimal Partition有几个特点：</p><ol type="1"><li>寻常的方法是要交换<span class="math inline">\(A\)</span>和<span class="math inline">\(B\)</span>中的<span class="math inline">\(λ\)</span>对顶点，这个<span class="math inline">\(λ\)</span>是预先确定的数值。这会导致<span class="math inline">\(λ\)</span>过小时效果不佳，但若增大<span class="math inline">\(λ\)</span>会导致计算量急剧上升。而Phase 1 Optimal Partition的<span class="math inline">\(λ\)</span>是动态变化的，尽可能地选择<span class="math inline">\(λ\)</span>使得交换带来的提升足够大，同时计算速度也足够快。</li><li>前面有提到，并非每个<span class="math inline">\(g_i\)</span>都是正数，但算法流程不会在遇到负的<span class="math inline">\(g_i\)</span>时就终止。这就是说，Phase 1 Optimal Partition能找到一对交换集合，交换集合中的几个元素可能会导致划分成本的增大，但交换整个集合能够带来足够大的净收益。</li></ol><p>我们知道Phase 1 Optimal Partition找到的是一个局部最优解，而为了探究局部最优解有多大概率为全局最优解，作者也进行了实验。文章在包括0-1矩阵、均匀分布的矩阵在内的多种矩阵上进行了实验，得到的结果比较相似。在<span class="math inline">\(30×30\)</span>的矩阵上平均概率约为<span class="math inline">\(0.5\)</span>，在<span class="math inline">\(60×60\)</span>的矩阵上平均概率约为<span class="math inline">\(0.2 \sim 0.3\)</span>，在<span class="math inline">\(120×120\)</span>的矩阵上平均概率约为<span class="math inline">\(0.05 \sim 0.1\)</span>。可以总结出一个大约的经验公式： <span class="math display">\[p(n)=2^{\frac{-n}{30}}\]</span></p><h2 id="运行时间分析">运行时间分析</h2><p>本节对方法的运行时间进行分析。我们对算法的各个步骤进行考察，分析每个过程的时间复杂度。要注意这里分析的只是对一次<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>选定所需的时间（称之为1个<strong>pass</strong>），而不是从初始划分到局部最优解所需的时间。</p><ol type="1"><li><p>第一次对所有节点的<span class="math inline">\(D\)</span>值计算时，由于要遍历每一个节点到其余所有节点的边权重，因此该过程的时间复杂度为<span class="math inline">\(O(n^2)\)</span>。</p></li><li><p>对于第<span class="math inline">\(i\)</span>次更新D值，所需要的时间为<span class="math inline">\(n-i-1\)</span>，因此整个流程中更新<span class="math inline">\(D\)</span>值需要的总时间为 <span class="math display">\[(n-1)+(n-2)+...+1\]</span> 可以看出这部分的时间复杂度也是<span class="math inline">\(O(n^2)\)</span><br /></p></li><li><p>对<span class="math inline">\(a_i, b_i\)</span>对的选择是运行时间主要的组成部分。作者在每轮pass选择前，都会先对完成更新的<span class="math inline">\(D\)</span>值进行排序，使得有 <span class="math display">\[D_{a_1} \ge D_{a_2} \ge ... \ge D_{a_m} \\ D_{b_1} \ge D_{b_2} \ge ... \ge D_{b_m}\]</span> 再按降序挑选节点。这样可以大幅度减少挑选时间，因为当选择到<span class="math inline">\({a_i}\)</span>和<span class="math inline">\({b_j}\)</span>时，若<span class="math inline">\(D_{a_i}+D_{b_j} \leq g_{max}\)</span>时，则对于所有<span class="math inline">\(k \ge i, l \ge j\)</span>，都不可能有<span class="math inline">\({ D_{a_k} } + { D_{b_l} } - 2{ c_{ {a_k}{b_l} } } \ge g_{max}\)</span>（前提是<span class="math inline">\(c_{ij} \ge 0\)</span>）。那么本轮对节点的遍历就可以提前终止了，由此可以节省大量的时间。由此，这部分主要的时间是由排序时间构成的： <span class="math display">\[n \log n + (n-1) \log (n-1) + ... + 2 \log 2\]</span> 时间复杂度为<span class="math inline">\(O(n^2 \log n)\)</span></p><p>当然我们可以牺牲一定的准确度，不用排序，使用更快的策略选择出节点点对。例如在更新<span class="math inline">\(D\)</span>值时记录下拥有最大<span class="math inline">\(D_a\)</span>和<span class="math inline">\(D_b\)</span>的两个节点，直接作为本轮pass所选择的交换节点对。这个策略对于有稀疏邻接矩阵的图来说非常有效。可以在此基础上再做小小的扩展，把记录拥有第二大、第三大<span class="math inline">\(D_a\)</span>和<span class="math inline">\(D_b\)</span>也记录下来进行比较，那么就可以以较高的效率和准确率选择本轮需要的交换节点对。</p></li></ol><p>综合以上分析，若在选择节点对使用排序策略，那么时间复杂度为<span class="math inline">\(O(n^2 \log n)\)</span>；若使用快速扫描策略，则时间复杂度为<span class="math inline">\(O(n^2)\)</span>。作为比较，穷举所有可能的交换集合所需要的时间为<span class="math inline">\(O(n^{\frac{3}{2}}4^n)\)</span>。实验中，文章方法实际测得时间复杂度大约为<span class="math inline">\(O(n^{2.4})\)</span></p><h2 id="优化phase-1-optimal-partition">优化Phase 1 Optimal Partition</h2><p>我们知道Phase 1 Optimal Partition得到的结果是一个局部最优解，而非全局最优解。那么本节来讨论一下如何优化，使其得到的解有更高的概率成为全局最优解。在讲述之前需要强调，本节所提到的优化方法完全是基于实验发现，不具备完整的理论依据。</p><p>作者在实验中发现，当Phase 1 Optimal Partition的结果不是全局最优解时，往往有<span class="math inline">\(\lvert X \rvert=\lvert Y \rvert \approx \frac{n}{2}\)</span>。这大致暗示了如果找到的<span class="math inline">\(\lvert X \rvert\)</span>和<span class="math inline">\(\lvert Y \rvert\)</span>明显小于<span class="math inline">\(\frac{n}{2}\)</span>，则很大概率说明找到了全局最优解。</p><p>作者给出了一个启发式的方法，可以在对整个<span class="math inline">\(S\)</span>进行Phase 1 Optimal Partition之前，对初始划分<span class="math inline">\(A\)</span>和<span class="math inline">\(B\)</span>分别做一次Phase 1 Optimal Partition，得到<span class="math inline">\(A \rightarrow\{A_1, A_2\},\quad B \rightarrow\{B_1, B_2\}\)</span>。随后重新组合得到<span class="math inline">\(A_0={A_1}\cup{B_1},\quad B_0={A_2}\cup{B_2}\)</span>，作为新的初始划分再进行Phase 1 Optimal Partition。很显然这个方法会引入额外的运行时间，但作者实验证明了这是值得的。</p><h2 id="划分不同大小的集合">划分不同大小的集合</h2><p>上述的Phase 1 Optimal Partition始终是将一个图<span class="math inline">\(S\)</span>划分为两个相同大小的集合<span class="math inline">\((2×\frac{n}{2}=n)\)</span>，但事实上很容易将方法拓展到划分不同大小集合<span class="math inline">\((n_1+n_2=n)\)</span>。</p><p>不妨设<span class="math inline">\(n_1&lt;n_2\)</span>，我们只需要先向<span class="math inline">\(S\)</span>中添加<span class="math inline">\((2×n_2-n)\)</span>个“哑节点”，即没有任何边与之关联的节点。在后续的划分过程中，我们限定每轮交换的节点对数不能超过<span class="math inline">\(n_1\)</span>。在Phase 1 Optimal Partition过程中，“哑节点”会被按需分配给两个划分子集，完成后去除“哑节点”，即可得到划分<span class="math inline">\(A\)</span>和<span class="math inline">\(B\)</span>。</p><h2 id="不同权重的图节点">不同权重的图节点</h2><p>前面讨论的过程限制了每个节点的权重为1。我们可以将一个权重<span class="math inline">\(m&gt;1\)</span>的节点转化为由<span class="math inline">\(m\)</span>个节点组成的集群，集群内部的每个节点间由极大权重的边互相关联，这样就可以放宽限制，使得有任意权重节点的图适用于Phase 1 Optimal Partition。但要注意到，随着各个节点的权重增大，Phase 1 Optimal Partition所要的时间也随之增大。</p><h1 id="多路划分">多路划分</h1><p>上一章讨论了k路划分最具代表性的特殊情况——2路均匀划分，以及如何将其推广至划分不定大小集合和拥有不同权重图节点的情况。本章将继续拓展，讨论如何实现<span class="math inline">\(k\)</span>路划分。</p><h2 id="将问题缩小到2路划分">将问题缩小到2路划分</h2><p>实现多路划分的基本思想是将一个图<span class="math inline">\(S\)</span>随机初始划分为<span class="math inline">\(k\)</span>个大小为<span class="math inline">\(n\)</span>的子集，并且对所有子集两两成对，重复将2路划分应用于这些子集对上。当然这样的解决方法当然不是最优的，因为可能存在三个或三个以上子集之间的复杂交换以达成全局最优解。但在本文中没有实现的合理方法。</p><p>那么按照上述思路，一共有<span class="math inline">\(\left(\begin{matrix}k \\ 2 \end{matrix}\right)\)</span>对子集需要进行2路划分，而且一个pass通常是不够的，因为对某一对子集进行优化往往会破坏另一对子集之间成本的最优性。但实验发现事实上需要的pass数并不大，在大部分情况下，2轮pass即可完成95%以上的优化，而剩余更多的迭代所能给予的成本减少量非常少。</p><h2 id="初始划分">初始划分</h2><p>因为实现多路划分是将2路划分的思想应用于初始多路划分中，初始划分的重要性也就不言而喻了。找到一个好的初始划分不仅能减少系统成对优化的工作量，还能使达到最优解决方案的概率提升。作者给出了两个形成初始划分的方法：</p><ol type="1"><li>给定一个图<span class="math inline">\(S\)</span>，为了形成一个<span class="math inline">\(k\)</span>路初始划分，先形成一个<span class="math inline">\(r\)</span>路划分。对<span class="math inline">\(r\)</span>路划分的每一个子集再做<span class="math inline">\(s\)</span>路划分，以此类推直到形成<span class="math inline">\(k\)</span>路划分（<span class="math inline">\(k=rs...\)</span>）。注意每次划分都是有优化过程的。但是这种方法有缺陷：在首次<span class="math inline">\(r\)</span>路划分会使各个子集的内部成本尽可能的高，这与各个子集后续的<span class="math inline">\(s\)</span>路划分产生了冲突。这样经历几个层次的划分，可能导致一个相对较差的结果。</li><li>给定一个图<span class="math inline">\(S\)</span>，它具有<span class="math inline">\(kn\)</span>个节点。我们可以使用<a href="#划分不同大小的集合">划分不同大小集合</a>里的方法将它们划分为两个子集，其中一个包含<span class="math inline">\(n\)</span>个节点，另一个包含<span class="math inline">\((k-1)n\)</span>个节点。然后按照同样的方式继续对<span class="math inline">\((k-1)n\)</span>个节点的子集继续划分，以此类推直到形成<span class="math inline">\(k\)</span>个子集。</li></ol><p>无论是完全随机生成初始划分，还是按照方法生成良好初始划分，后续都跟随着成对优化过程。平均而言，良好初始划分不太可能导致比随机初始划分更差的结果。需要额外计算量的良好初始划分，对系统运行时间和最终结果的影响是否合理，这取决于所研究的邻接矩阵类型。</p><h2 id="不限制子集数量">不限制子集数量</h2><p>前面所讨论的方法，都有一个限制：最终形成的子集数量为<span class="math inline">\(k\)</span>个。<a href="#划分不同大小的集合">上一章</a>，我们为了把2路划分方法推广至具有划分不同大小集合的情况，引入了“哑节点”。这可以看作是一种松弛方法，允许通过扩展以获得较低成本的结果。</p><p>我们在此要放开限制，即不限制子集的数量（大于等于<span class="math inline">\(k\)</span>），且每个子集内节点数最多为<span class="math inline">\(n\)</span>个。这通常可以带来更低成本的划分结果。具体方法如下：</p><ol type="1"><li>对一个图<span class="math inline">\(S\)</span>，其内部节点数为<span class="math inline">\(kn\)</span>，要求划分使得每个子集内节点数不得超过<span class="math inline">\(n\)</span>个。首先不引入松弛，按照本章所提到的方法找到最优的划分方式，将其划分为<span class="math inline">\(k\)</span>个子集。</li><li>引入<span class="math inline">\(n\)</span>个“哑节点”，构成一个子集。再次对所有子集进行两两交换，得到最佳<span class="math inline">\((k+1)\)</span>路划分。</li><li>若不存在某个子集内节点全为“哑节点”，重复步骤2，继续添加<span class="math inline">\(n\)</span>个“哑节点”并交换优化。直到最终出现某个子集内节点全为“哑节点”时，结束。</li><li>去除最终结果每个子集内的“哑节点”，即可得到无子集数限制的最优多路划分。</li></ol>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RocksDB | Put流程</title>
    <link href="/2022/10/21/rocksdb-write-process/"/>
    <url>/2022/10/21/rocksdb-write-process/</url>
    
    <content type="html"><![CDATA[<p>今天这篇文章从源码自顶向下地梳理一下RocksDB的写入流程。需要强调的是，RocksDB的写入流程非常复杂，本文的主要目的是记录从用户调用<code>Put</code>到完成写入过程中数据流动和调用关系，因此忽略了许多机制，仅保留了主干过程。</p><span id="more"></span><h2 id="用户接口">用户接口</h2><p>首先当然是从用户调用的接口开始探索。文档里给出了RocksDB的写入调用形式： <figure class="highlight c++"><figcaption><span>用户调用示例</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs C++">rocksdb::DB* db;<br>rocksdb::Options options;<br>options.create_if_missing = <span class="hljs-literal">true</span>;<br>rocksdb::Status status = rocksdb::DB::<span class="hljs-built_in">Open</span>(options, <span class="hljs-string">&quot;/tmp/testdb&quot;</span>, &amp;db);<br><span class="hljs-built_in">assert</span>(status.<span class="hljs-built_in">ok</span>());<br><br>std::string key, value;<br>rocksdb::Status s = db-&gt;<span class="hljs-built_in">Put</span>(rocksdb::<span class="hljs-built_in">WriteOptions</span>(), key, value);<br>s = db-&gt;<span class="hljs-built_in">Delete</span>(rocksdb::<span class="hljs-built_in">WriteOptions</span>(), key);<br></code></pre></td></tr></table></figure> 可以看到用户通过<code>rocksdb::DB</code>的<code>Put</code>方法写入，<code>Delete</code>方法删除。我们暂且忽略<code>Delete</code>，追查下去看看<code>Put</code>究竟做了什么。</p><h2 id="db和dbimpl的put方法"><code>DB</code>和<code>DBImpl</code>的Put方法</h2><p><code>rocksdb::DB</code>类（由于RocksDB统一使用了<code>rocksdb</code>的命名空间，接下来的描述将不再加上<code>rocksdb::</code>）的声明被放在了<code>/include/db.h</code>里，其中关于<code>Put</code>方法的声明如下： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DB</span> &#123;<br>  ...<br><br>  <span class="hljs-comment">// Set the database entry for &quot;key&quot; to &quot;value&quot;.</span><br>  <span class="hljs-comment">// If &quot;key&quot; already exists, it will be overwritten.</span><br>  <span class="hljs-comment">// Returns OK on success, and a non-OK status on error.</span><br>  <span class="hljs-comment">// Note: consider setting options.sync = true.</span><br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> Status <span class="hljs-title">Put</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; options,</span></span><br><span class="hljs-params"><span class="hljs-function">                     ColumnFamilyHandle* column_family, <span class="hljs-type">const</span> Slice&amp; key,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">const</span> Slice&amp; value)</span> </span>= <span class="hljs-number">0</span>;<br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> Status <span class="hljs-title">Put</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; options,</span></span><br><span class="hljs-params"><span class="hljs-function">                     ColumnFamilyHandle* column_family, <span class="hljs-type">const</span> Slice&amp; key,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">const</span> Slice&amp; ts, <span class="hljs-type">const</span> Slice&amp; value)</span> </span>= <span class="hljs-number">0</span>;<br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> Status <span class="hljs-title">Put</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; options, <span class="hljs-type">const</span> Slice&amp; key,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">const</span> Slice&amp; value)</span> </span>&#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">Put</span>(options, <span class="hljs-built_in">DefaultColumnFamily</span>(), key, value);<br>  &#125;<br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> Status <span class="hljs-title">Put</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; options, <span class="hljs-type">const</span> Slice&amp; key,</span></span><br><span class="hljs-params"><span class="hljs-function">                     <span class="hljs-type">const</span> Slice&amp; ts, <span class="hljs-type">const</span> Slice&amp; value)</span> </span>&#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">Put</span>(options, <span class="hljs-built_in">DefaultColumnFamily</span>(), key, ts, value);<br>  &#125;<br>  <br>  <span class="hljs-comment">// 需要说明的是，这里的Slice是RocksDB对封装的一种字符串，</span><br>  <span class="hljs-comment">// 在本文中把它看作普通的字符串即可。</span><br>  ...<br>&#125;<br></code></pre></td></tr></table></figure> <code>Put</code>方法一共有四个重载。第一个需要提供的参数：写入设置引用<code>const WriteOptions&amp;</code>、列族handle指针<code>ColumnFamilyHandle*</code>以及需要存储的键和值<code>const Slice&amp;</code>。第二个在第一个的基础上添加了时间戳<code>const Slice&amp;</code>。第三个和第四个不过是用户省略列族handle指针，由其提供默认列族，调用回第一个和第二个<code>Put</code>方法。值得注意的是，前两个<code>Put</code>方法是纯虚函数，也就是说还有一个子类是以<code>DB</code>为基类构建的，是真正供以实例化的类。</p><p>那么这个类在哪呢？<code>/db/db_impl.h</code>里声明了<code>DB</code>的实现类<code>DBImpl</code>： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DBImpl</span> : <span class="hljs-keyword">public</span> DB &#123;<br>  ...<br>  <span class="hljs-keyword">using</span> DB::Put;<br>  <span class="hljs-function">Status <span class="hljs-title">Put</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; options, ColumnFamilyHandle* column_family,</span></span><br><span class="hljs-params"><span class="hljs-function">             <span class="hljs-type">const</span> Slice&amp; key, <span class="hljs-type">const</span> Slice&amp; value)</span> <span class="hljs-keyword">override</span></span>;<br>  <span class="hljs-function">Status <span class="hljs-title">Put</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; options, ColumnFamilyHandle* column_family,</span></span><br><span class="hljs-params"><span class="hljs-function">             <span class="hljs-type">const</span> Slice&amp; key, <span class="hljs-type">const</span> Slice&amp; ts, <span class="hljs-type">const</span> Slice&amp; value)</span> <span class="hljs-keyword">override</span></span>;<br>  ...<br>&#125;<br></code></pre></td></tr></table></figure> <code>DBImpl</code>暴露了父类<code>DB</code>的四个<code>Put</code>方法，并声明了两个相同的带列族参数的<code>Put</code>方法（即和<code>DB</code>前两个<code>Put</code>完全相同）。首先来看看<code>DBImpl::Put</code>的定义，RocksDB在<code>/db/db_impl_write.cc</code>对它们进行了实现： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// DBImpl的Put方法</span><br><span class="hljs-function">Status <span class="hljs-title">DBImpl::Put</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; o, ColumnFamilyHandle* column_family,</span></span><br><span class="hljs-params"><span class="hljs-function">                   <span class="hljs-type">const</span> Slice&amp; key, <span class="hljs-type">const</span> Slice&amp; val)</span> </span>&#123;<br>  <span class="hljs-type">const</span> Status s = <span class="hljs-built_in">FailIfCfHasTs</span>(column_family);<br>  <span class="hljs-keyword">if</span> (!s.<span class="hljs-built_in">ok</span>()) &#123;<br>    <span class="hljs-keyword">return</span> s;<br>  &#125;<br>  <span class="hljs-keyword">return</span> DB::<span class="hljs-built_in">Put</span>(o, column_family, key, val);<br>&#125;<br><br><span class="hljs-function">Status <span class="hljs-title">DBImpl::Put</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; o, ColumnFamilyHandle* column_family,</span></span><br><span class="hljs-params"><span class="hljs-function">                   <span class="hljs-type">const</span> Slice&amp; key, <span class="hljs-type">const</span> Slice&amp; ts, <span class="hljs-type">const</span> Slice&amp; val)</span> </span>&#123;<br>  <span class="hljs-type">const</span> Status s = <span class="hljs-built_in">FailIfTsMismatchCf</span>(column_family, ts, <span class="hljs-comment">/*ts_for_read=*/</span><span class="hljs-literal">false</span>);<br>  <span class="hljs-keyword">if</span> (!s.<span class="hljs-built_in">ok</span>()) &#123;<br>    <span class="hljs-keyword">return</span> s;<br>  &#125;<br>  <span class="hljs-keyword">return</span> DB::<span class="hljs-built_in">Put</span>(o, column_family, key, ts, val);<br>&#125;<br></code></pre></td></tr></table></figure> 很明显，<code>DBImpl::Put</code>也只是在对列族和时间戳作了合法性检查之后再调用回前两个<code>DB::Put</code>执行真正的写入工作。所以，为了继续探究写流程，只要沿着前两个<code>DB::Put</code>的实现继续深入就好了。对<code>DB::Put</code>的实现同样在<code>/db/db_impl_write.cc</code>中，定义如下： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">Status <span class="hljs-title">DB::Put</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; opt, ColumnFamilyHandle* column_family,</span></span><br><span class="hljs-params"><span class="hljs-function">               <span class="hljs-type">const</span> Slice&amp; key, <span class="hljs-type">const</span> Slice&amp; value)</span> </span>&#123;<br>  <span class="hljs-comment">// Pre-allocate size of write batch conservatively.</span><br>  <span class="hljs-comment">// 8 bytes are taken by header, 4 bytes for count, 1 byte for type,</span><br>  <span class="hljs-comment">// and we allocate 11 extra bytes for key length, as well as value length.</span><br>  <span class="hljs-function">WriteBatch <span class="hljs-title">batch</span><span class="hljs-params">(key.size() + value.size() + <span class="hljs-number">24</span>, <span class="hljs-number">0</span> <span class="hljs-comment">/* max_bytes */</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                   opt.protection_bytes_per_key, <span class="hljs-number">0</span> <span class="hljs-comment">/* default_cf_ts_sz */</span>)</span></span>;<br>  Status s = batch.<span class="hljs-built_in">Put</span>(column_family, key, value);<br>  <span class="hljs-keyword">if</span> (!s.<span class="hljs-built_in">ok</span>()) &#123;<br>    <span class="hljs-keyword">return</span> s;<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">Write</span>(opt, &amp;batch);<br>&#125;<br><br><span class="hljs-function">Status <span class="hljs-title">DB::Put</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; opt, ColumnFamilyHandle* column_family,</span></span><br><span class="hljs-params"><span class="hljs-function">               <span class="hljs-type">const</span> Slice&amp; key, <span class="hljs-type">const</span> Slice&amp; ts, <span class="hljs-type">const</span> Slice&amp; value)</span> </span>&#123;<br>  ColumnFamilyHandle* default_cf = <span class="hljs-built_in">DefaultColumnFamily</span>();<br>  <span class="hljs-built_in">assert</span>(default_cf);<br>  <span class="hljs-type">const</span> Comparator* <span class="hljs-type">const</span> default_cf_ucmp = default_cf-&gt;<span class="hljs-built_in">GetComparator</span>();<br>  <span class="hljs-built_in">assert</span>(default_cf_ucmp);<br>  <span class="hljs-function">WriteBatch <span class="hljs-title">batch</span><span class="hljs-params">(<span class="hljs-number">0</span> <span class="hljs-comment">/* reserved_bytes */</span>, <span class="hljs-number">0</span> <span class="hljs-comment">/* max_bytes */</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                   opt.protection_bytes_per_key,</span></span><br><span class="hljs-params"><span class="hljs-function">                   default_cf_ucmp-&gt;timestamp_size())</span></span>;<br>  Status s = batch.<span class="hljs-built_in">Put</span>(column_family, key, ts, value);<br>  <span class="hljs-keyword">if</span> (!s.<span class="hljs-built_in">ok</span>()) &#123;<br>    <span class="hljs-keyword">return</span> s;<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">Write</span>(opt, &amp;batch);<br>&#125;<br></code></pre></td></tr></table></figure> <strong>在真正进行写入工作时，<code>Put</code>还是先用<code>WriteBatch</code>对其进行了封装，再调用<code>Write</code>写入</strong>。和平常用户使用<code>WriteBatch</code>进行批量原子更新是一样的，只不过这个batch中只有一个Put操作。所以接下来，我们就要看看<code>Write</code>是怎样把<code>WriteBatch</code>写入的。</p><h2 id="writebatch和write"><code>WriteBatch</code>和<code>Write</code></h2><p>简单起见，从这一章开始只对不带时间戳的写流程继续追查下去（更多是我还没完全理解RocksDB中时间戳的概念，或许是和Bigtable中的是一致的？）。也就是从这一个方法开始： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">Status <span class="hljs-title">DB::Put</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; opt, ColumnFamilyHandle* column_family,</span></span><br><span class="hljs-params"><span class="hljs-function">               <span class="hljs-type">const</span> Slice&amp; key, <span class="hljs-type">const</span> Slice&amp; value)</span> </span>&#123;<br>  <span class="hljs-comment">// Pre-allocate size of write batch conservatively.</span><br>  <span class="hljs-comment">// 8 bytes are taken by header, 4 bytes for count, 1 byte for type,</span><br>  <span class="hljs-comment">// and we allocate 11 extra bytes for key length, as well as value length.</span><br>  <span class="hljs-function">WriteBatch <span class="hljs-title">batch</span><span class="hljs-params">(key.size() + value.size() + <span class="hljs-number">24</span>, <span class="hljs-number">0</span> <span class="hljs-comment">/* max_bytes */</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                   opt.protection_bytes_per_key, <span class="hljs-number">0</span> <span class="hljs-comment">/* default_cf_ts_sz */</span>)</span></span>;<br>  Status s = batch.<span class="hljs-built_in">Put</span>(column_family, key, value);<br>  <span class="hljs-keyword">if</span> (!s.<span class="hljs-built_in">ok</span>()) &#123;<br>    <span class="hljs-keyword">return</span> s;<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">Write</span>(opt, &amp;batch);<br>&#125;<br></code></pre></td></tr></table></figure> 这里的逻辑非常简单: 1. 创建了一个<code>WriteBatch</code> 2. <code>WriteBatch</code>调用<code>Put</code>记录操作 3. 调用<code>Write</code>把<code>WriteBatch</code>更新写入数据库</p><h3 id="writebatch的定义"><code>WriteBatch</code>的定义</h3><p>鉴于本文目的在于尽可能简单地梳理一遍写流程，源码仅挑关键的部分展示和解释。关于<code>WriteBatch</code>的声明在<code>include/rocksdb/write_batch.h</code>： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">WriteBatch</span> : <span class="hljs-keyword">public</span> WriteBatchBase &#123;<br>  ......<br><br>  <span class="hljs-keyword">protected</span>:<br>    std::string rep_;<br>&#125;<br></code></pre></td></tr></table></figure> <code>WriteBatch</code>继承于基类<code>WriteBatchBase</code>，基类是一个完全由虚函数构成的接口类。<code>rep_</code>是<code>WriteBatch</code>最重要的部分，它是一个字符串，按一定的格式记录了所要进行所有操作，记录格式如下： <figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">WriteBatch:</span>:rep_ :=<br><span class="hljs-symbol">   sequence:</span> fixed64<br><span class="hljs-symbol">   count:</span> fixed32<br><span class="hljs-symbol">   data:</span> record[count]<br>record :=<br>   kTypeValue varstring varstring<br>   kTypeDeletion varstring<br>   kTypeSingleDeletion varstring<br>   kTypeRangeDeletion varstring varstring<br>   kTypeMerge varstring varstring<br>   kTypeColumnFamilyValue varint32 varstring varstring<br>   kTypeColumnFamilyDeletion varint32 varstring<br>   kTypeColumnFamilySingleDeletion varint32 varstring<br>   kTypeColumnFamilyRangeDeletion varint32 varstring varstring<br>   kTypeColumnFamilyMerge varint32 varstring varstring<br>   kTypeBeginPrepareXID<br>   kTypeEndPrepareXID varstring<br>   kTypeCommitXID varstring<br>   kTypeCommitXIDAndTimestamp varstring varstring<br>   kTypeRollbackXID varstring<br>   kTypeBeginPersistedPrepareXID<br>   kTypeBeginUnprepareXID<br>   kTypeWideColumnEntity varstring varstring<br>   kTypeColumnFamilyWideColumnEntity varint32 varstring varstring<br>   kTypeNoop<br>varstring :=<br><span class="hljs-symbol">   len:</span> varint32<br><span class="hljs-symbol">   data:</span> uint8[len]<br></code></pre></td></tr></table></figure> <img src="/img/post_img/rocksdb-write-process/fig1.png#pic_center" /></p><p><code>rep_</code>的开头放置<code>fixed64</code>类型的序列号，第二位是<code>fixed32</code>类型的当前记录数，随后是各条操作记录。可以看到每条记录都是以<code>操作类型 + 操作内容</code>的形式构成的，且为了更契合Rocksdb的需求，同时为了节省空间，采用了一种变长字符串<code>varstring</code>的编码方法。关于<code>rep_</code>内各种数据类型的编解码实现在<code>util/coding.h</code>和<code>util/coding.cc</code>内，在本文不做分析。</p><h3 id="writebatch调用put"><code>WriteBatch</code>调用<code>Put</code></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">Status <span class="hljs-title">WriteBatch::Put</span><span class="hljs-params">(ColumnFamilyHandle* column_family, <span class="hljs-type">const</span> Slice&amp; key,</span></span><br><span class="hljs-params"><span class="hljs-function">                       <span class="hljs-type">const</span> Slice&amp; value)</span> </span>&#123;<br>  <span class="hljs-type">size_t</span> ts_sz = <span class="hljs-number">0</span>;<br>  <span class="hljs-type">uint32_t</span> cf_id = <span class="hljs-number">0</span>;<br>  Status s;<br><br>  <span class="hljs-comment">// 利用ColumnFamilyHandle，获取CF的id</span><br>  std::<span class="hljs-built_in">tie</span>(s, cf_id, ts_sz) =<br>      WriteBatchInternal::<span class="hljs-built_in">GetColumnFamilyIdAndTimestampSize</span>(<span class="hljs-keyword">this</span>, column_family);<br><br>  <span class="hljs-keyword">if</span> (!s.<span class="hljs-built_in">ok</span>()) &#123;<br>    <span class="hljs-keyword">return</span> s;<br>  &#125;<br><br>  <span class="hljs-comment">// 调用WriteBatchInternal::Put开始写入操作记录</span><br>  <span class="hljs-keyword">if</span> (<span class="hljs-number">0</span> == ts_sz) &#123;<br>    <span class="hljs-keyword">return</span> WriteBatchInternal::<span class="hljs-built_in">Put</span>(<span class="hljs-keyword">this</span>, cf_id, key, value);<br>  &#125;<br><br>  needs_in_place_update_ts_ = <span class="hljs-literal">true</span>;<br>  has_key_with_ts_ = <span class="hljs-literal">true</span>;<br>  <span class="hljs-function">std::string <span class="hljs-title">dummy_ts</span><span class="hljs-params">(ts_sz, <span class="hljs-string">&#x27;\0&#x27;</span>)</span></span>;<br>  std::array&lt;Slice, 2&gt; key_with_ts&#123;&#123;key, dummy_ts&#125;&#125;;<br>  <span class="hljs-keyword">return</span> WriteBatchInternal::<span class="hljs-built_in">Put</span>(<span class="hljs-keyword">this</span>, cf_id, <span class="hljs-built_in">SliceParts</span>(key_with_ts.<span class="hljs-built_in">data</span>(), <span class="hljs-number">2</span>),<br>                                 <span class="hljs-built_in">SliceParts</span>(&amp;value, <span class="hljs-number">1</span>));<br>&#125;<br></code></pre></td></tr></table></figure><p><code>WatchBatchInternal</code>是辅助<code>WatchBatch</code>的工具类，里面定义了一系列辅助方法。<code>WriteBatch::Put</code>先根据列族的Handle获取了列族的Id，随后再调用了<code>WatchBatchInternal::Put</code>，送入当前<code>WatchBatch</code>指针、列族Id、key和value，开始记录操作。 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">Status <span class="hljs-title">WriteBatchInternal::Put</span><span class="hljs-params">(WriteBatch* b, <span class="hljs-type">uint32_t</span> column_family_id,</span></span><br><span class="hljs-params"><span class="hljs-function">                               <span class="hljs-type">const</span> SliceParts&amp; key, <span class="hljs-type">const</span> SliceParts&amp; value)</span> </span>&#123;<br>  Status s = <span class="hljs-built_in">CheckSlicePartsLength</span>(key, value);<br>  <span class="hljs-keyword">if</span> (!s.<span class="hljs-built_in">ok</span>()) &#123;<br>    <span class="hljs-keyword">return</span> s;<br>  &#125;<br><br>  <span class="hljs-comment">// 创建一个保存点，保存当前状态</span><br>  <span class="hljs-function">LocalSavePoint <span class="hljs-title">save</span><span class="hljs-params">(b)</span></span>;<br><br>  <span class="hljs-comment">// 设置WatchBatch-&gt;rep_里的count</span><br>  WriteBatchInternal::<span class="hljs-built_in">SetCount</span>(b, WriteBatchInternal::<span class="hljs-built_in">Count</span>(b) + <span class="hljs-number">1</span>);<br><br>  <span class="hljs-comment">// 开始记录操作，首先写入操作类型，根据是否为目标列族是否为默认列族设定kTypeValue或kTypeColumnFamilyValue</span><br>  <span class="hljs-keyword">if</span> (column_family_id == <span class="hljs-number">0</span>) &#123;<br>    b-&gt;rep_.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">char</span>&gt;(kTypeValue));<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    b-&gt;rep_.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">char</span>&gt;(kTypeColumnFamilyValue));<br>    <span class="hljs-built_in">PutVarint32</span>(&amp;b-&gt;rep_, column_family_id);<br>  &#125;<br>  <span class="hljs-comment">// 分别写入key和value</span><br>  <span class="hljs-built_in">PutLengthPrefixedSliceParts</span>(&amp;b-&gt;rep_, key);<br>  <span class="hljs-built_in">PutLengthPrefixedSliceParts</span>(&amp;b-&gt;rep_, value);<br>  <span class="hljs-comment">// 修改WatchBatch的flag，添加HAS_PUT标志表示该batch中有Put操作</span><br>  b-&gt;content_flags_.<span class="hljs-built_in">store</span>(<br>      b-&gt;content_flags_.<span class="hljs-built_in">load</span>(std::memory_order_relaxed) | ContentFlags::HAS_PUT,<br>      std::memory_order_relaxed);<br>  <span class="hljs-keyword">if</span> (b-&gt;prot_info_ != <span class="hljs-literal">nullptr</span>) &#123;<br>    <span class="hljs-comment">// See comment in first `WriteBatchInternal::Put()` overload concerning the</span><br>    <span class="hljs-comment">// `ValueType` argument passed to `ProtectKVO()`.</span><br>    b-&gt;prot_info_-&gt;entries_.<span class="hljs-built_in">emplace_back</span>(<span class="hljs-built_in">ProtectionInfo64</span>()<br>                                             .<span class="hljs-built_in">ProtectKVO</span>(key, value, kTypeValue)<br>                                             .<span class="hljs-built_in">ProtectC</span>(column_family_id));<br>  &#125;<br><br>  <span class="hljs-comment">// 提交并解锁WatchBatch</span><br>  <span class="hljs-keyword">return</span> save.<span class="hljs-built_in">commit</span>();<br>&#125;<br></code></pre></td></tr></table></figure> 如上注释，<code>WriteBatchInternal::Put()</code>会先创建一个保存点，用于保存当前batch的情况。紧接着会对<code>rep_</code>的count部分增加计数1，随后添加<code>Put</code>记录。最后<code>save.commit()</code>会判断<code>rep_</code>是否超出了容许的最大范围，若超出则会回退至记录前的状态，并返回一个<code>Status::MemoryLimit()</code>信号，而非正常的<code>Status::OK()</code>。至此，便<code>WriteBatch</code>完成了对<code>Put</code>操作的记录。接下来就由<code>DB::Put</code>内的<code>Write(opt, &amp;batch);</code>语句开始将batch写入数据库。</p><h3 id="调用write把writebatch更新写入数据库">调用<code>Write</code>把<code>WriteBatch</code>更新写入数据库</h3><p>在实际使用过程中，由于我们操作的是<code>DBImpl</code>对象，所以实际上会使用到<code>DBImpl::Write()</code>，它被定义在了<code>db/db_impl/db_impl_write.cc</code>里： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">Status <span class="hljs-title">DBImpl::Write</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; write_options, WriteBatch* my_batch)</span> </span>&#123;<br>  Status s;<br>  <span class="hljs-keyword">if</span> (write_options.protection_bytes_per_key &gt; <span class="hljs-number">0</span>) &#123;<br>    s = WriteBatchInternal::<span class="hljs-built_in">UpdateProtectionInfo</span>(<br>        my_batch, write_options.protection_bytes_per_key);<br>  &#125;<br>  <span class="hljs-keyword">if</span> (s.<span class="hljs-built_in">ok</span>()) &#123;<br>    s = <span class="hljs-built_in">WriteImpl</span>(write_options, my_batch, <span class="hljs-comment">/*callback=*/</span><span class="hljs-literal">nullptr</span>,<br>                  <span class="hljs-comment">/*log_used=*/</span><span class="hljs-literal">nullptr</span>);<br>  &#125;<br>  <span class="hljs-keyword">return</span> s;<br>&#125;<br></code></pre></td></tr></table></figure> 可以看到它还会再进一步调用<code>DBImpl::WriteImpl()</code>。<code>DBImpl::WriteImpl()</code>代码量非常多，将近500行，包含了许多预处理和不同的写入分支。这个过程中大致可以概括成三个分支：(1)只写入到WAL，会跳转<code>WriteImplWALOnly()</code>；(2)Pipeline写入，会跳转<code>PipelinedWriteImpl()</code>；(3)非Pipeline写入，继续执行。关注非Pipeline写入，又分为两种情况：是否能够对Memtables多线程并发写入（通过option配置）。在这里我们继续沿着默认的单线程写入，则其关键代码如下： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">Status <span class="hljs-title">DBImpl::WriteImpl</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteOptions&amp; write_options,</span></span><br><span class="hljs-params"><span class="hljs-function">                         WriteBatch* my_batch, WriteCallback* callback,</span></span><br><span class="hljs-params"><span class="hljs-function">                         <span class="hljs-type">uint64_t</span>* log_used, <span class="hljs-type">uint64_t</span> log_ref,</span></span><br><span class="hljs-params"><span class="hljs-function">                         <span class="hljs-type">bool</span> disable_memtable, <span class="hljs-type">uint64_t</span>* seq_used,</span></span><br><span class="hljs-params"><span class="hljs-function">                         <span class="hljs-type">size_t</span> batch_cnt,</span></span><br><span class="hljs-params"><span class="hljs-function">                         PreReleaseCallback* pre_release_callback,</span></span><br><span class="hljs-params"><span class="hljs-function">                         PostMemTableCallback* post_memtable_callback)</span> </span>&#123;<br>  ...<br>  <span class="hljs-comment">// 对传入的WriteBatch构建Writer，并将其加入write_thread</span><br>  <span class="hljs-function">WriteThread::Writer <span class="hljs-title">w</span><span class="hljs-params">(write_options, my_batch, callback, log_ref,</span></span><br><span class="hljs-params"><span class="hljs-function">                        disable_memtable, batch_cnt, pre_release_callback,</span></span><br><span class="hljs-params"><span class="hljs-function">                        post_memtable_callback)</span></span>;<br>  write_thread_.<span class="hljs-built_in">JoinBatchGroup</span>(&amp;w);<br>  ...<br>  &#123;<br>    ...<br>    <span class="hljs-comment">// 在写入前作检查和预处理</span><br>    status = <span class="hljs-built_in">PreprocessWrite</span>(write_options, &amp;log_context, &amp;write_context);<br>    ...<br>  &#125;<br>  ...<br>  <span class="hljs-keyword">if</span> (status.<span class="hljs-built_in">ok</span>()) &#123;<br>    <span class="hljs-built_in">PERF_TIMER_GUARD</span>(write_memtable_time);<br>    <span class="hljs-keyword">if</span> (!parallel) &#123;<br>      <span class="hljs-comment">// 非并发插入数据</span><br>      w.status = WriteBatchInternal::<span class="hljs-built_in">InsertInto</span>(<br>          write_group, current_sequence, column_family_memtables_.<span class="hljs-built_in">get</span>(),<br>          &amp;flush_scheduler_, &amp;trim_history_scheduler_,<br>          write_options.ignore_missing_column_families,<br>          <span class="hljs-number">0</span> <span class="hljs-comment">/*recovery_log_number*/</span>, <span class="hljs-keyword">this</span>, parallel, seq_per_batch_,<br>          batch_per_txn_);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      ...<br>    &#125;<br>  ...<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure> 这里根据传入的batch对象构建了一个<code>WriteThread::Writer</code>对象，并通过<code>JoinBatchGroup()</code>将其加入到一个Group中，随后会进行WAL的写入。接着<code>PreprocessWrite()</code>会在写入前进行检查和预处理，并可能触发Flush操作。完成上述工作后，<code>WriteBatchInternal::InsertInto()</code>会展开真正的写入工作。以上所都是写入流程中的关键操作，但碍于篇幅，本文将仅继续对<code>WriteBatchInternal::InsertInto()</code>进行深入。</p><h2 id="watchbatch记录写入数据库"><code>WatchBatch</code>记录写入数据库</h2><p>从<code>WriteBatchInternal::InsertInto()</code>开始，才可以算是<code>Put</code>写入真正开始执行的地方。<code>WriteBatchInternal::InsertInto()</code>的实现放在了<code>db/write_batch.cc</code>： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">Status <span class="hljs-title">WriteBatchInternal::InsertInto</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">    WriteThread::Writer* writer, SequenceNumber sequence,</span></span><br><span class="hljs-params"><span class="hljs-function">    ColumnFamilyMemTables* memtables, FlushScheduler* flush_scheduler,</span></span><br><span class="hljs-params"><span class="hljs-function">    TrimHistoryScheduler* trim_history_scheduler,</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">bool</span> ignore_missing_column_families, <span class="hljs-type">uint64_t</span> log_number, DB* db,</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">bool</span> concurrent_memtable_writes, <span class="hljs-type">bool</span> seq_per_batch, <span class="hljs-type">size_t</span> batch_cnt,</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">bool</span> batch_per_txn, <span class="hljs-type">bool</span> hint_per_batch)</span> </span>&#123;<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> NDEBUG</span><br>  (<span class="hljs-type">void</span>)batch_cnt;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>  <span class="hljs-built_in">assert</span>(writer-&gt;<span class="hljs-built_in">ShouldWriteToMemtable</span>());<br>  <span class="hljs-comment">// 构建MemTableInserter</span><br>  <span class="hljs-function">MemTableInserter <span class="hljs-title">inserter</span><span class="hljs-params">(sequence, memtables, flush_scheduler,</span></span><br><span class="hljs-params"><span class="hljs-function">                            trim_history_scheduler,</span></span><br><span class="hljs-params"><span class="hljs-function">                            ignore_missing_column_families, log_number, db,</span></span><br><span class="hljs-params"><span class="hljs-function">                            concurrent_memtable_writes, <span class="hljs-literal">nullptr</span> <span class="hljs-comment">/* prot_info */</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                            <span class="hljs-literal">nullptr</span> <span class="hljs-comment">/*has_valid_writes*/</span>, seq_per_batch,</span></span><br><span class="hljs-params"><span class="hljs-function">                            batch_per_txn, hint_per_batch)</span></span>;<br>  <span class="hljs-comment">// 设置LSN</span><br>  <span class="hljs-built_in">SetSequence</span>(writer-&gt;batch, sequence);<br>  inserter.<span class="hljs-built_in">set_log_number_ref</span>(writer-&gt;log_ref);<br>  inserter.<span class="hljs-built_in">set_prot_info</span>(writer-&gt;batch-&gt;prot_info_.<span class="hljs-built_in">get</span>());<br>  <span class="hljs-comment">// 开始写入</span><br>  Status s = writer-&gt;batch-&gt;<span class="hljs-built_in">Iterate</span>(&amp;inserter);<br>  <span class="hljs-built_in">assert</span>(!seq_per_batch || batch_cnt != <span class="hljs-number">0</span>);<br>  <span class="hljs-built_in">assert</span>(!seq_per_batch || inserter.<span class="hljs-built_in">sequence</span>() - sequence == batch_cnt);<br>  <span class="hljs-keyword">if</span> (concurrent_memtable_writes) &#123;<br>    inserter.<span class="hljs-built_in">PostProcess</span>();<br>  &#125;<br>  <span class="hljs-keyword">return</span> s;<br>&#125;<br></code></pre></td></tr></table></figure> 函数里根据传入的<code>writer</code>和所有其他信息构建了一个<code>MemTableInserter</code>，并对<code>writer-&gt;batch</code>设置了序列号LSN，最后调用<code>writer-&gt;batch-&gt;Iterate()</code>传入之前构建的<code>inserter</code>开始写入。<code>Iterate()</code>实现如下： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">Status <span class="hljs-title">WriteBatch::Iterate</span><span class="hljs-params">(Handler* handler)</span> <span class="hljs-type">const</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (rep_.<span class="hljs-built_in">size</span>() &lt; WriteBatchInternal::kHeader) &#123;<br>    <span class="hljs-keyword">return</span> Status::<span class="hljs-built_in">Corruption</span>(<span class="hljs-string">&quot;malformed WriteBatch (too small)&quot;</span>);<br>  &#125;<br><br>  <span class="hljs-keyword">return</span> WriteBatchInternal::<span class="hljs-built_in">Iterate</span>(<span class="hljs-keyword">this</span>, handler, WriteBatchInternal::kHeader,<br>                                     rep_.<span class="hljs-built_in">size</span>());<br>&#125;<br><br><span class="hljs-function">Status <span class="hljs-title">WriteBatchInternal::Iterate</span><span class="hljs-params">(<span class="hljs-type">const</span> WriteBatch* wb,</span></span><br><span class="hljs-params"><span class="hljs-function">                                   WriteBatch::Handler* handler, <span class="hljs-type">size_t</span> begin,</span></span><br><span class="hljs-params"><span class="hljs-function">                                   <span class="hljs-type">size_t</span> end)</span> </span>&#123;<br>  ...<br>  <span class="hljs-comment">// 循环不断读取操作记录并执行</span><br>  <span class="hljs-keyword">while</span> (((s.<span class="hljs-built_in">ok</span>() &amp;&amp; !input.<span class="hljs-built_in">empty</span>()) || <span class="hljs-built_in">UNLIKELY</span>(s.<span class="hljs-built_in">IsTryAgain</span>()))) &#123;<br>    ...<br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">LIKELY</span>(!s.<span class="hljs-built_in">IsTryAgain</span>())) &#123;<br>      last_was_try_again = <span class="hljs-literal">false</span>;<br>      tag = <span class="hljs-number">0</span>;<br>      column_family = <span class="hljs-number">0</span>;  <span class="hljs-comment">// default</span><br><br>      <span class="hljs-comment">// 从WriteBatch的rep_中解码读取当前的一条记录</span><br>      s = <span class="hljs-built_in">ReadRecordFromWriteBatch</span>(&amp;input, &amp;tag, &amp;column_family, &amp;key, &amp;value,<br>                                   &amp;blob, &amp;xid);<br>      <span class="hljs-keyword">if</span> (!s.<span class="hljs-built_in">ok</span>()) &#123;<br>        <span class="hljs-keyword">return</span> s;<br>      &#125;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      ...<br>    &#125;<br><br>    <span class="hljs-keyword">switch</span> (tag) &#123;<br>      <span class="hljs-keyword">case</span> kTypeColumnFamilyValue:<br>      <span class="hljs-keyword">case</span> kTypeValue:<br>        <span class="hljs-built_in">assert</span>(wb-&gt;content_flags_.<span class="hljs-built_in">load</span>(std::memory_order_relaxed) &amp;<br>               (ContentFlags::DEFERRED | ContentFlags::HAS_PUT));<br>        <span class="hljs-comment">// 写入数据库</span><br>        s = handler-&gt;<span class="hljs-built_in">PutCF</span>(column_family, key, value);<br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">LIKELY</span>(s.<span class="hljs-built_in">ok</span>())) &#123;<br>          empty_batch = <span class="hljs-literal">false</span>;<br>          found++;<br>        &#125;<br>        <span class="hljs-keyword">break</span>;<br>      <span class="hljs-keyword">case</span> ...:<br>        ...<br>    &#125;<br>  &#125;<br><br>  <span class="hljs-keyword">if</span> (!s.<span class="hljs-built_in">ok</span>()) &#123;<br>    <span class="hljs-keyword">return</span> s;<br>  &#125;<br>  <span class="hljs-keyword">if</span> (handler_continue &amp;&amp; whole_batch &amp;&amp;<br>      found != WriteBatchInternal::<span class="hljs-built_in">Count</span>(wb)) &#123;<br>    <span class="hljs-keyword">return</span> Status::<span class="hljs-built_in">Corruption</span>(<span class="hljs-string">&quot;WriteBatch has wrong count&quot;</span>);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-keyword">return</span> Status::<span class="hljs-built_in">OK</span>();<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure> <code>Iterate()</code>会进行循环处理，在每次循环中通过<code>ReadRecordFromWriteBatch()</code>解码并读取<code>WriteBatch::rep_</code>中最前面的操作记录，获得操作类型<code>tag</code>、列族<code>column_family</code>以及数据<code>key</code>和<code>value</code>等信息。随后进入switch块，利用<code>tag</code>判断进入不同的分支。对于<code>Put</code>操作，会调用<code>MemTableInserter</code>的<code>PutCF()</code>，送入参数列族和键值对: <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">Status <span class="hljs-title">PutCF</span><span class="hljs-params">(<span class="hljs-type">uint32_t</span> column_family_id, <span class="hljs-type">const</span> Slice&amp; key,</span></span><br><span class="hljs-params"><span class="hljs-function">               <span class="hljs-type">const</span> Slice&amp; value)</span> <span class="hljs-keyword">override</span> </span>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>* kv_prot_info = <span class="hljs-built_in">NextProtectionInfo</span>();<br>    Status ret_status;<br>    <span class="hljs-keyword">if</span> (kv_prot_info != <span class="hljs-literal">nullptr</span>) &#123;<br>      <span class="hljs-comment">// Memtable needs seqno, doesn&#x27;t need CF ID</span><br>      <span class="hljs-keyword">auto</span> mem_kv_prot_info =<br>          kv_prot_info-&gt;<span class="hljs-built_in">StripC</span>(column_family_id).<span class="hljs-built_in">ProtectS</span>(sequence_);<br>      ret_status = <span class="hljs-built_in">PutCFImpl</span>(column_family_id, key, value, kTypeValue,<br>                             &amp;mem_kv_prot_info);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      ret_status = <span class="hljs-built_in">PutCFImpl</span>(column_family_id, key, value, kTypeValue,<br>                             <span class="hljs-literal">nullptr</span> <span class="hljs-comment">/* kv_prot_info */</span>);<br>    &#125;<br>    <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> this assumes that if TryAgain status is returned to the caller,</span><br>    <span class="hljs-comment">// the operation is actually tried again. The proper way to do this is to</span><br>    <span class="hljs-comment">// pass a `try_again` parameter to the operation itself and decrement</span><br>    <span class="hljs-comment">// prot_info_idx_ based on that</span><br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">UNLIKELY</span>(ret_status.<span class="hljs-built_in">IsTryAgain</span>())) &#123;<br>      <span class="hljs-built_in">DecrementProtectionInfoIdxForTryAgain</span>();<br>    &#125;<br>    <span class="hljs-keyword">return</span> ret_status;<br>  &#125;<br></code></pre></td></tr></table></figure> 可以看到，在其中再调用<code>PutCFImpl()</code>，其实现关键源码如下： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">Status <span class="hljs-title">PutCFImpl</span><span class="hljs-params">(<span class="hljs-type">uint32_t</span> column_family_id, <span class="hljs-type">const</span> Slice&amp; key,</span></span><br><span class="hljs-params"><span class="hljs-function">                   <span class="hljs-type">const</span> Slice&amp; value, ValueType value_type,</span></span><br><span class="hljs-params"><span class="hljs-function">                   <span class="hljs-type">const</span> ProtectionInfoKVOS64* kv_prot_info)</span> </span>&#123;<br>    ···<br>    Status ret_status;<br>    <span class="hljs-comment">// 通过column_family_id找到列族ColumnFamilyData</span><br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">UNLIKELY</span>(!<span class="hljs-built_in">SeekToColumnFamily</span>(column_family_id, &amp;ret_status))) &#123;<br>      ...<br>      <span class="hljs-keyword">return</span> ret_status;<br>    &#125;<br>    <span class="hljs-built_in">assert</span>(ret_status.<span class="hljs-built_in">ok</span>());<br>    <br>    <span class="hljs-comment">// 获取当前列族的MemTable</span><br>    MemTable* mem = cf_mems_-&gt;<span class="hljs-built_in">GetMemTable</span>();<br>    <span class="hljs-keyword">auto</span>* moptions = mem-&gt;<span class="hljs-built_in">GetImmutableMemTableOptions</span>();<br>    <span class="hljs-comment">// inplace_update_support is inconsistent with snapshots, and therefore with</span><br>    <span class="hljs-comment">// any kind of transactions including the ones that use seq_per_batch</span><br>    <span class="hljs-built_in">assert</span>(!seq_per_batch_ || !moptions-&gt;inplace_update_support);<br>    <span class="hljs-keyword">if</span> (!moptions-&gt;inplace_update_support) &#123;<br>      <span class="hljs-comment">// 对MemTable写入数据</span><br>      ret_status =<br>          mem-&gt;<span class="hljs-built_in">Add</span>(sequence_, value_type, key, value, kv_prot_info,<br>                   concurrent_memtable_writes_, <span class="hljs-built_in">get_post_process_info</span>(mem),<br>                   hint_per_batch_ ? &amp;<span class="hljs-built_in">GetHintMap</span>()[mem] : <span class="hljs-literal">nullptr</span>);<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (moptions-&gt;inplace_callback == <span class="hljs-literal">nullptr</span> ||<br>               value_type != kTypeValue) &#123;<br>      ...<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      ...<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">UNLIKELY</span>(ret_status.<span class="hljs-built_in">IsTryAgain</span>())) &#123;<br>      <span class="hljs-built_in">assert</span>(seq_per_batch_);<br>      <span class="hljs-type">const</span> <span class="hljs-type">bool</span> kBatchBoundary = <span class="hljs-literal">true</span>;<br>      <span class="hljs-built_in">MaybeAdvanceSeq</span>(kBatchBoundary);<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ret_status.<span class="hljs-built_in">ok</span>()) &#123;<br>      <span class="hljs-built_in">MaybeAdvanceSeq</span>();<br>      <span class="hljs-built_in">CheckMemtableFull</span>();  <span class="hljs-comment">// 检查MemTable是否已满</span><br>    &#125;<br>    <span class="hljs-comment">// optimize for non-recovery mode</span><br>    <span class="hljs-comment">// If `ret_status` is `TryAgain` then the next (successful) try will add</span><br>    <span class="hljs-comment">// the key to the rebuilding transaction object. If `ret_status` is</span><br>    <span class="hljs-comment">// another non-OK `Status`, then the `rebuilding_trx_` will be thrown</span><br>    <span class="hljs-comment">// away. So we only need to add to it when `ret_status.ok()`.</span><br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">UNLIKELY</span>(ret_status.<span class="hljs-built_in">ok</span>() &amp;&amp; rebuilding_trx_ != <span class="hljs-literal">nullptr</span>)) &#123;<br>      <span class="hljs-built_in">assert</span>(!write_after_commit_);<br>      <span class="hljs-comment">// TODO(ajkr): propagate `ProtectionInfoKVOS64`.</span><br>      ret_status = WriteBatchInternal::<span class="hljs-built_in">Put</span>(rebuilding_trx_, column_family_id,<br>                                           key, value);<br>    &#125;<br>    <span class="hljs-keyword">return</span> ret_status;<br>  &#125;<br></code></pre></td></tr></table></figure> <code>PutCFImpl()</code>中，<code>SeekToColumnFamily()</code>会根据<code>column_family_id</code>找到对应的列族对象，把指针赋予该<code>MemTableInserter</code>的<code>cf_mems_-&gt;current_</code>变量上，其中<code>cf_mems_</code>是<code>MemTableInserter</code>的一个<code>ColumnFamilyMemTablesImpl*</code>成员变量，<code>current_</code>则是<code>ColumnFamilyMemTablesImpl</code>的一个<code>ColumnFamilyData*</code>成员变量。<br />随后，<code>mem = cf_mems_-&gt;GetMemTable()</code>会得到列族的MemTable指针，再通过<code>mem-&gt;Add()</code>完成MemTable的写入工作。具体的写入逻辑不再深究，RocksDB为MemTable提供了多种不同的数据结构实现，每一种的写入逻辑都有不同，但都完成了封装提供<code>Add()</code>接口以供使用。<br />写入完成后，<code>MaybeAdvanceSeq()</code>和<code>CheckMemtableFull()</code>会进行收尾工作，增大序列号以及检查MemTable是否已满，若已满则会将其转化为ImmuMemTable，相关内容不在本文进行分析。</p><h2 id="结束">结束</h2><p>以上就是RocksDB在进行<code>Put</code>写入操作时的主要流程和调用关系，至此RocksDB就完成了一个<code>Put</code>写入。对于其他的操作也可以参考以上的流程进行逐步深入分析。<br /><strong>最后需要再次强调</strong>，RocksDB真正的写入流程非常复杂，本文仅仅是以<code>Put</code>操作写入到MemTable为目的对源代码进行追踪，因此分析过程中对许多重要操作一笔带过而对简单的流程分析显得有些啰嗦，例如<code>WriteImpl()</code>中不同的分支、<code>PreprocessWrite()</code>可能触发的Flush操作，以及<code>CheckMemtableFull()</code>对MemTable状态的检查，还有过程中许多重要数据结构的相互引用关系，本文都没有作分析。因此，读者可以把本文视为一篇对RocksDB的分析入门引导，目的在于为读者以及自己今后对其它部分的分析提供一份路线图，帮助理解各种事件发生的时间点，而不是对RocksDB核心技术源码的分析。</p>]]></content>
    
    
    <categories>
      
      <category>RocksDB源码阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>rocksdb</tag>
      
      <tag>源码剖析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HelloWorld!</title>
    <link href="/2022/10/09/HelloWorld/"/>
    <url>/2022/10/09/HelloWorld/</url>
    
    <content type="html"><![CDATA[<p><strong>Hello, world! Hello, blog!</strong></p><p>终于有了自己的博客，从今天起会在这里不定时发布一些内容，可能是技术文章，可能是胡思乱想，也可能是我的生活。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Helloworld</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
